\documentclass[12pt]{report}
%alt: [12pt, twocolumn, landscape]

\input{latex/Packages}
\input{latex/Config}
\input{latex/Macros}

%******************************************************************************
% Prelude
%******************************************************************************

%------------------------------------------------------------------------------
%history: 
%------------------------------------------------------------------------------

%thx to LP, I changed for the better a few things:
% - found deadcode?
% - found duplicated code?
 

%thx to codemap/codegraph/scheck (but ocaml does a better job than C here):
% - TODO use cg to to look at backward deps (but ocamlc already enforces layers)
%   (harder to understand non layered code)
% - TODO use scheck to remove deadcode (but ocamlc now is better at this)
%   (harder to understand big files)
% - TODO use cg to reduce number of globals by moving them closer to the
%   relevant file (or even function), better cluster the code
%   (harder to understand non functional code using lots of globals)

%thx to this manual, better understand mk/make:

%history LP-ization:
% - skeleton, mostly copy paste of Make.nw structure
% - put all content of files in the Extra section, via 'lpizer'
%   which also now split in chunks!
%    * function, type, exception, constant
%    * [[xxx]] other fields
% - read Extra section, identify concepts, first TOC
% - distribute parts of the Extra section in the main file
% - understand main(), LP split main, improve TOC
% - understand main functions, LP split, cluster, improve TOC
% - LP split the structures
% - aspectify advanced features! remove useless features, error, debug, secu
% - TODO add figures
% - TODO add explanations

\begin{document}
%******************************************************************************
% Title
%******************************************************************************
\title{
{\Huge 
Principia Softwarica: The Build System [[mk]]
}\\
OCaml edition\\
{version 0.1}
}


\author{
Yoann Padioleau\\
\texttt{yoann.padioleau@gmail.com}\\
\\
with code from\\
Andrew Hume and Yoann Padioleau
}


\maketitle 

%\onecolumn
\hrule
\begin{quote}
Copyright \copyright{} 2025 Yoann Padioleau \\
Permission is granted to copy, distribute and/or modify this document,
except all the source code it contains, under the terms of the GNU Free
Documentation License, Version 1.3.
\end{quote}
\hrule
%\twocolumn

\begingroup
\hypersetup{linkcolor=blue}
% need to s/onecolumn/twocolumn in report.cls :) for \tableofcontents
\tableofcontents
\endgroup

%******************************************************************************
\chapter{Introduction}
%******************************************************************************

#include "Intro.nw"

%\chapter{Overview}
% now in Intro.nw too

\section{Code organization}

%dup: Assembler.nw
Table~\ref{tab:code-orga} presents short descriptions
of the source files of [[mk]], together with
the main entities (e.g., types, functions, globals) the file defines,
and the corresponding chapters in this document in which the code
contained in the file is primarily discussed.
\t so? what this table is useful for/


\begin{table*}[tbh!]
\begin{center}
\begin{tabular}{lcllr}
\toprule
{\bf Function}                            & {\bf Ch.}                     & {\bf File}     & {\bf Entities}                                        & {\bf LOC} \\
\otoprule
parsing data structures             & \ref{chap:core-ds}            & [[Ast.ml]]       & [<word>] [<Ast.rule>] [<instr>] & 119 \\
variables management               & \ref{chap:core-ds}            & [[Env.ml]]      & [<Env.t>] [<add_var()>] [<mk_vars>]  & 135 \\
rules data structures               & \ref{chap:core-ds}            & [[Rules.ml]]      & [<Rules.rule>] [<rules>] [<Rules.rule_exec>] & 47 \\
graph of dependencies               & \ref{chap:core-ds}            & [[Graph.ml]]      & [<node>] [<arc>] [<build_state>] & 448 \\
file time                           & \ref{chap:core-ds}            & [[File.ml]]      & [<timeof()>] & 25 \\
job data structure                  & \ref{chap:core-ds}            & [[Job.ml]]      & [<Job.t>] & 23 \\

\midrule
entry point                               & \ref{chap:main}               & [[Main.ml]]     &     & 18 \\
main functions                            & \ref{chap:main}               & [[CLI.ml]]     & [<main()>] [<build_targets()>] [<build_target()>]  & 368 \\

\midrule
parser entry point                        & \ref{chap:parsing}            & [[Parse.ml]]      & [<parse()>]      & 41 \\
lexer/grammar globals                     & \ref{chap:parsing}            & [[Globals.ml]]      & [<Globals.file>] [<Globals.line>]  & 14 \\
lexer                                     & \ref{chap:parsing}            & [[Lexer.mll]]      & [<Lexer.token()>] [<Lexer.recipe()>] & 276 \\ % [<Lexer.state>] 
grammar                                    & \ref{chap:parsing}            & [[Parser.mly]]    & [<Parser.token>] [<Parser.instrs()>]    & 192 \\ % [<Parser.program()>]  [<Parser.error()>]  

\midrule
expanding variables                       & \ref{chap:eval}            & [[Eval.ml]]      & [<eval()>] [<eval_words()>]      & 305 \\

\midrule
building the graph           & \ref{chap:graph}              & [[Graph.ml]]    & [<build_graph()>] [<apply_rules()>]          & 448 \\ %  [<check_cycle()>] check_ambiguous vacuous
pattern matching         & \ref{chap:graph}              & [[Percent.ml]]    & [<match_()>] [<subst()>]                               & 113 \\

\midrule
finding outdated files     & \ref{chap:finding-outdated}   & [[Outofdate.ml]]       & [<work()>] [<outofdate()>] [<dorecipe()>]      & 179 \\

\midrule
scheduling jobs                           & \ref{chap:scheduling}         & [[Scheduler.ml]]      & [<run()>] [<sched()>] [<waitup()>]       & 229 \\
executing jobs                           & \ref{chap:scheduling}         & [[Shell.ml]]      & [<exec_recipe()>] [<exec_shell()>]  & 277 \\ % [<Shell.t>] [<rc>] [<sh>]

\midrule
shell environment                         & \ref{chap:shellenv}           & [[Shellenv.ml]]      & [<Shellenv.t>] [<initenv()>] & 20 \\

\midrule
Debugging flags                   & \ref{chap:debugging-support}           & [[Flags.ml]]      & [<explain_mode>] [<dry_mode>] & 35 \\

\otoprule
Total                                     &                               &                &                                                       & 3300 \\
\bottomrule
\end{tabular}
\end{center}
\caption{Chapters and associated [[mk]] source files.}
\label{tab:code-orga}
\end{table*}


\section{Software architecture}
\label{sec:soft-archi}

%dup: Assembler.nw
Figure~\ref{fig:controlflow} describes the main control flow of [[mk]], whereas
Figure~\ref{fig:dataflow} describes the main data flow of [[mk]].
%
The main steps of the building pipeline of [[mk]] are as follows:


\begin{enumerate}
\item {\em Parse} the [[mkfile]] (via [<parse()>]) to generate
a convenient data structure representing the content of an [[mkfile]]:
an Abstract Syntax Tree (AST).
\n chapter 5

\item {\em Evaluate} the AST (via [<eval()>]) to process
the include instructions, variables, and backquotes and to extract
the rules and meta rules in the [[mkfile]] and its included files.
\n chapter 6
%ocaml: new and better separation of concerns with parsing

\item {\em Build} the graph of dependencies (via [<build_graph()>])
for a specific target given the rules extracted previously.
\n chapter 7

\item {\em Find} outdated files in the graph (via [<work()>]).
\n chapter 8

\item {\em Schedule} jobs (via [<sched()>]) that will run the shell
recipes (via [<exec_recipe()>]) to update the outdated files.
\n chapter 9
\n chapter 10 = To {\em interact} environment

\end{enumerate}


\begin{figure}[!tbp]\centering
\resizebox{0.7\textwidth}{!}{%
\input{control_flow}
}
\caption{Control flow diagram of [[mk]].}\label{fig:controlflow}
\end{figure}

\begin{figure}[!tbp]\centering
\begin{verbatim}
                             main target 
                           /              \
                          /- simple rules -\
mkfile -> tokens -> AST  -                  > graph -> jobs
                          \- meta rules   -/
                           \              /
                             environment

\end{verbatim}
\caption{Data flow diagram of [[mk]].}\label{fig:dataflow}
\end{figure}


%trans:
Starting from the top of Figure~\ref{fig:controlflow},
the function [<main()>],
after some basic command-line processing and initializations,
calls [<build_targets()>] which calls [<parse()>] with the file to {parse}
as an argument (by default [[mkfile]], unless you specified
another filename with the [[-f]] command-line flag).
%
[<parse()>] first calls the lexer (via [<Lexer.token()>]) to get
{tokens} which are then assembled into list of {instructions} by the {grammar}
(via [<Parser.instrs()>]) forming the {AST} of the [[mkfile]].
%
[<build_targets()>] then evaluates this AST (via [<eval()>]) to process
the include instructions (which trigger further calls to [<parse()>]),
variable definitions and uses, and backquotes.
Once all the files have been included and variable uses expanded, 
[<eval()>] then returns important data structures
such as [<Rules.rules.simples>] and [<Rules.rules.metas>],
which contain the lists of extracted {rules}.
%
[<eval()>] also modifies some target reference with the name of the 
first {target} found in the [[mkfile]], unless you gave
a specific target on the command line (e.g., with [[mk hello.5]]).
%
Finally, [<eval()>] returns an [<Env.t>] containing
the values for the {variables} defined in the [[mkfile]]
and in the enclosing {environment}.
\n also process inclusion, so recursive function


After the rules have been extracted, [<build_targets()>] calls [<build_target()>] 
(at the top right in Figure~\ref{fig:controlflow})
with the name of a target as an argument.
%(the name stored in target1 by default).
\n actually target1 is a list (said later)
%
[<build_target()>] then calls [<build_graph()>] to build the {graph of dependencies}
for this target given the rules and metarules extracted during parsing and
evaluation.
%dup: overview/principles/graph
This graph contains nodes and arcs, as explained 
in Section~\ref{sec:graph-principles}.
%dup:
The {nodes} correspond to concrete files
(e.g., [[hello.5]], [[hello.c]]),
\n unless virtual targets (said later)
and the arcs connect two nodes when a node depends on another node 
(e.g., [[hello.5]] is connected to [[hello.c]]).
%
Those arcs are also labeled with the rule containing the recipe
to generate the target node.
\l also modification time, and build status.

[<build_graph()>] works by first creating a node for the target parameter,
called the {root} of the graph, and by then
calling [<apply_rules()>] on this node.
\n actually apply_rules build the node
%
[<apply_rules()>] then finds a rule or meta rule with the node as a target,
\n can have ambiguity (said later)
and creates new nodes for all the prerequisites found in the rule. 
It then calls recursively [<apply_rules()>] on those new nodes.
\l at some point leaf cos existing file with no matching rule for target
%make:
Note that as opposed to Make,
in [[mk]] the graph of dependencies is computed statically once and for all
at the very beginning.
\t so? better?


[<build_target()>] then calls [<work()>] to find outdated files in the graph.
%
Starting from the root, [<work()>] performs a depth-first search
\l as explained in Section X
and goes down recursively in
the graph to find nodes corresponding to inexistent files, or
to files that are older than the files in the nodes they are connected to.
%
Once it found such a node,
[<work()>] calls [<dorecipe()>]
with the outdated node as a parameter. 
\t note that DFS, go deep first! even if node more recent than all
\t  connected nodes, those nodes may not be up to date, so call
\t  work on them first! and then compare the date. (or said before)
[<dorecipe()>] then finds the arc containing the master rule 
\l see Section X for master rule
with the recipe to regenerate the file in the node.
\l can have ambiguity, but always a master arc, a master rule (said later)
%
[<dorecipe()>] then calls [<run()>] 
(at the bottom of Figure~\ref{fig:controlflow})
to add in a queue the job to 
run the recipe. 
[<run()>] possibly calls [<sched()>] to schedule the job if there was
a free processor to run the job in parallel.
%
[<sched()>] then calls [<exec_recipe()>] to fork and execute in a shell the recipe.


[<build_target()>] calls [<work()>] in a loop, to schedule jobs in
parallel until the root node is up-to-date ([<Made>]). 
However, during those loops,
[<work()>] may not be able to schedule any job. Indeed, all the processors
may already be in use, or certain jobs may not be able to start until
other jobs are finished.
This is why [<build_target()>] also calls sometimes [<waitup()>] 
(at the right in Figure~\ref{fig:controlflow})
to wait for those jobs to finish.
Once a job is finished, [<waitup()>] calls [<update()>] to update 
the node in the graph associated with the job, and [<sched()>] 
to schedule another job.
\t as I said, ends when root node is up-to-date and no more process 
\t  to wait for.





\section{Book structure}

%trans: %dup: Assembler.nw
You now have enough background to understand the source code of [[mk]].
%toc:
The rest of the book is organized as follows.
%
I will start by describing the core data structures of [[mk]]
in Chapter~\ref{chap:core-ds}. 
%
Then, I will use a top-down approach, starting with Chapter~\ref{chap:main}
with the description of [<main()>] and the initialization of [[mk]].
%
The following chapters will describe
the main components of the building pipeline:
Chapter~\ref{chap:parsing} will present the code to parse an [[mkfile]],
Chapter~\ref{chap:eval} the code to evaluate the parsed AST,
Chapter~\ref{chap:graph} the code to build the graph of dependencies,
Chapter~\ref{chap:finding-outdated} the code to find outdated files in the graph,
Chapter~\ref{chap:scheduling} the code to schedule jobs, and finally
Chapter~\ref{chap:shellenv} the code to communicate with the shell through
the environment.
%
In Chapter~\ref{chap:debugging-support}, I will present code to help you
debug and profile your [[mkfile]].
%
Chapter~\ref{chap:advanced} presents advanced
features of [[mk]] that I did not present before to simplify the explanations
(e.g., {rule attributes}).
%
Finally, Chapter~\ref{chap:conclusion} concludes
and gives pointers to other books in the \principia series.

%toc:
Some appendices present the code of non-functional properties:
code to help debug [[mk]] itself in Appendix~\ref{chap:debugging-appendix} and
code to profile [[mk]] itself in Appendix~\ref{chap:profiling-appendix}.
%
Finally, Appendix~\ref{chap:examples} presents examples of [[mkfile]]s.


%******************************************************************************
\chapter{Core Data Structures}
%******************************************************************************
\label{chap:core-ds}

\begin{verse}
\begin{flushright}
  {\it Show me your code and conceal your data structures, and I shall
    continue to be mystified. Show me your data structures, and I
    won't usually need your code; it'll be obvious.\\
    ~\\
    Fred Brooks}
\end{flushright}
\end{verse}

%toc: parsed -> "evaluated" -> executed

\section{Parsed structures}
%alt: AST

\subsection{Words}

<<type [[Ast.words]]>>=
(* Words are separated by spaces. See also Env.values *)
type words = word list
@
% words! core datatype of mk (and rc), list of things (files, objects, flags)

<<type [[Ast.word]]>>=
(* The elements below are not separated by any separator; they are direct
 * concatenations of elements (hence the need for ${name} below).
 * The list must contain at least one element.
 * ex: '%.c' -> W [Percent; String ".c"]
 *)
type word = W of word_element list
@

<<type [[Ast.word_element]]>>=
  and word_element =
    | String of string (* except the empty string *)
    | Percent
    (* evaluated in eval.ml just after parsing *)
    | Var of var
    <<[[Ast.word_element]] cases>>
@

% vars, feature 1 of DSL!

<<type [[Ast.var]]>>=
and var = 
 (* $name or ${name} (the string does not contain the $ or {}) *)
| SimpleVar of string
<<[[Ast.var]] cases>>
@

\subsection{Rules}

<<type [[Ast.rule]]>>=
(* See also Rules.rule and Rules.rule_exec *)
type rule = {
  targets: words;
  prereqs: words;
  recipe: recipe option;
  <<[[Ast.rule]] other fields>>
}
@
% can have multiple targets, see previous chapter, but most often just one target
% one prereq

<<type [[Ast.recipe]]>>=
(* (the strings do not contain the leading space nor trailing newline) *)
type recipe = R of string list
@
% note that not words here! We don't care whether use $Var
% we just leverage existing env var mechanism! better than make!

\subsection{Instructions}
%alt: Parsed [[mkfile]]Instructions

<<type [[Ast.instrs]]>>=
type instrs = instr list
@
% remove? kept for deriving show?

<<type [[Ast.instr]]>>=
type instr = {
  instr: instr_kind;
  loc: loc;
}
@

<<type [[Ast.instr_kind]]>>=
  and instr_kind =
    | Rule of rule
    (* should resolve to a single filename less: could enforce of word? *)
    | Include of words
    (* stricter: no dynamic def like X=AVAR  $X=42 ... $AVAR, 
     * so 'string' below, not 'word' *)
    | Definition of string * words
    <<[[Ast.instr_kind]] cases>>
@
%$
%alt: move later Include? move Definition in separate section?



<<type [[Ast.loc]]>>=
(* for error reporting *)
type loc = {
  file: Fpath.t; (* an mkfile *)
  line: int;
}
@
% see chapter X for error management?


%TODO: example of dump of simple mkfile, one var def, one include, one rule, one meta
% and reference -dump_ast that way?

\section{Evaluated structures}

%trans: parsed, now evaluated/interpreted

\subsection{Environment}
%alt: evaluated variables

<<type [[Env.t]]>>=
type t = {
  (* use Env.add_var to add a var (to check if it's ok) *)
  vars         : (string, values) Hashtbl.t;
  <<[[Env.t]] fields>>
}
@
%alt: varname type? like in rc?

<<type [[Env.values]]>>=
(* Content of variables (after full expansion and backquote resolution).
 * It should not contain any empty strings (but it can contain empty lists).
 *)
type values = string list
@
% like in rc, core datatype is a list of words, but here after full expansion!
%less: rename just value? more consistent with rc and
% reads better to see varname, value

<<signature [[Env.add_var]]>>=
val add_var : t -> string -> values -> unit
@

<<function [[Env.add_var]]>>=
let add_var env s xs = 
  match () with
  <<[[Env.add_var()]] ignore def if overriden on the command-line>>
  <<[[Env.add_var()]] forbid redefinition in strict mode>>
  | _ ->
    Hashtbl.replace env.vars s xs
@


<<signature [[Env.check_values]]>>=
val check_values : values -> unit
@
<<function [[Env.check_values]]>>=
(* invariant *)
let check_values xs = 
  xs |> List.iter (fun s ->
    if s = ""
    then raise (Impossible (spf "empty string in values"))
  )
@


<<[[Env.t]] fields>>=
internal_vars: (string, values) Hashtbl.t;
@

<<constant [[Env.mk_vars]]>>=
let mk_vars = [
  "target";
  "prereq";
  "stem";

  (* todo: alltargets, newprereq ... *)
]
@
%alt: split and move stem later ?


\subsection{Patterns}
%alt: evaluated patterns

% patterns, feature 2 of DSL
% seen % and Percent before

<<type [[Percent.pattern]]>>=
(* The list must contain at least one element *)
type pattern = P of pattern_elem list
@

<<type [[Percent.pattern_elem]]>>=
and pattern_elem =
  | PStr of string
  | PPercent
@
% parsed pattern, so string here, not word!

<<signature [[Percent.check_pattern]]>>=
val check_pattern : pattern -> unit
@
<<function [[Percent.check_pattern]]>>=
let check_pattern (P xs) =
  if xs = []
  then raise (Impossible (spf "empty pattern"));
  xs |> List.iter (function
    | PPercent -> ()
    | PStr "" -> raise (Impossible (spf "empty string element in pattern"));
    | PStr _ -> ()
  )
@
%less: could also check can have only one PPercent

\subsection{Simple and meta rules}

% already seen parsed rule, but now after 'eval'uation of vars and "parsing"
% of patterns

<<type [[Rules.rule]]>>=
type 'a rule = {
  targets: 'a list;
  prereqs: 'a list;
  recipe: Ast.recipe option;
  <<[[Rules.rule]] other fields>>
  loc: Ast.loc;
}
@
% Diff with AST.rule?? Evaluated!

<<type [[Rules.rules]]>>=
type rules = {
  (* use Hashtbl.find_all because a target can be associated to many rules *)
  simples: (string, string rule) Hashtbl.t;
  metas:  (Percent.pattern rule) list;
}
@

%TODO: dump, same of before but evaluated. -dump_xxx for that?

\section{Graph of dependencies}

%trans: parsed, evaluated, now applied to concrete filesystem
% kinda "instance" of rules

<<type [[Graph.node]]>>=
type node = {
  (* usually a filename *)
  name: string;

  (* mutable because this field can be adjusted later in check_ambiguous
   * and vacuous.
   * Note that this field was called 'prereqs' before, but virtual rules
   * without any prereq still have an arc (with an empty dest,
   * and a recipe), so 'arcs' is a better field name.
   *)
  mutable arcs: arc list;
  <<[[Graph.node]] other fields>>
}
@

<<type [[Graph.arc]]>>=
  and arc = {
    (* note that because the graph of dependencies is a DAG, multiple
     * arcs may point to the same node. 
     *)
    dest: node option;
    <<[[Graph.arc]] other fields>>
  }
@
%TODO: when None?? useful?

<<[[Graph.arc]] other fields>>=
(* what we need from the rule to execute a recipe (and report errors) *)
rule: Rules.rule_exec;
@
% a kinda link to the rule that is responsible for the arc
% ex: TODO

<<type [[Rules.rule_exec]]>>=
type rule_exec = {
  recipe2: Ast.recipe option;
  <<[[Rules.rule_exec]] other fields>>
  loc2: Ast.loc;
}
@
% just enough info for executing the rule, so really what we need is the recipe!
% can be None here? what if None? what do we execute??

% use 2 because ocaml fields must be unique for inference to work
% (or need modern ocaml and more type annotations)


<<[[Rules.rule_exec]] other fields>>=
stem: string option;
@
% for meta rules! so recipe can use $stem




<<[[Graph.node]] other fields>>=
(* None for inexistent files (and virtual targets).
 * mutable because it will be updated once the target is generated
 * (or when we discover a target is a virtual node).
 *)
mutable time: float option;
@

<<[[Graph.node]] other fields>>=
mutable state: build_state;
@

<<type [[Graph.build_state]]>>=
  and build_state = 
    | NotMade
    | BeingMade
    | Made
@
% see explanation in principles section before \ref{}

<<type [[Graph.t]]>>=
type t = node (* the root *)
@

<<constant [[Graph.hnodes]]>>=
(* The graph is a DAG; some arcs may point to previously created nodes.
 * This is why we store in this hash all the created nodes.
 * 
 * Moreover, later in dorecipe() when we run a job, we want to build
 * the list of all target nodes concerned by a rule and this requires
 * again given a target name to find the corresponding node in the graph.
 *)
let hnodes = Hashtbl.create 101
@






<<function [[Graph.new_node]]>>=
let new_node (target : string) =
  let time = File.timeof (Fpath.v target) in
  let node = {
    name = target;
    arcs = [];
    state = NotMade;
    time = time;

    visited = false;
    is_virtual = false;
    probable = time <> None;
  }
  in
  Logs.debug (fun m -> m "newnode(%s), time = %s" target 
                (File.str_of_time node.time));
  Hashtbl.add hnodes target node;
  node
@
% default to NotMade!


<<signature [[File.timeof]]>>=
(* returns None if file does not exist or can't be stat'ed for some reasons *)
val timeof : Fpath.t -> float option
@

<<function [[File.timeof]]>>=
(* opti? time cache, and flag to skip cache if want refresh *)
let timeof file =
  try 
    (* bugfix: use stat, not lstat, to get the time of what is pointed
     * by the symlink, not the symlink
     *)
    let stat = Unix.stat !!file in
    Some (stat.Unix.st_mtime)
  with Unix.Unix_error (_, _, _) -> None
@
% note use of !! because Fpath.t vs string for filename, See lib_core/Fpath_.ml

\ifallcode
<<signature [[File.str_of_time]]>>=
val str_of_time : float option -> string
@
<<function [[File.str_of_time]]>>=
let str_of_time timeopt =
  match timeopt with
  | None -> "0"
  | Some t -> spf "%.1f" t
@
\fi

%TODO: ex of dump_graph, still on same example

\section{Jobs}

<<type [[Job.t]]>>=
type t = {
  rule: Rules.rule_exec;
  env: Env.t;

  (* nodes mk needs to update once the job is done *)
  target_nodes: Graph.node list;

  <<[[Job.t]] other fields>>
}
@
%$

<<[[Job.t]] other fields>>=
(* less: newprereqs, targets *)
main_target: string;
@
% this is the Graph.name
% this is $target?

<<[[Job.t]] other fields>>=
(* values for special mk variables such as $target, $prereq, etc.
 * (note that $stem is in rule_exec)
 *)
all_targets: Env.values;
all_prereqs: Env.values;
@
%TODO: all_targets vs main_target?


<<constant [[Scheduler.jobs]]>>=
let jobs = Queue.create ()
@

<<signature [[Scheduler.nrunning]]>>=
val nrunning : int ref
@

%TODO: actually it is a global! 
<<constant [[Scheduler.nrunning]]>>=
let nrunning = ref 0
@


%TODO: ex of dump_jobs, still on same example


%******************************************************************************
\chapter{[[Main.main()]]}
%******************************************************************************
\label{chap:main}


<<type [[CLI.caps]]>>=
(* Need:
 *  - fork/exec/wait: obviously as we run shell commands
 *  - env: for Env.initenv() so mk recipe can access env variables.
 *    Also MKSHELL in Shell.ml and NPROC in Scheduler.ml
 *  - argv: for setting MKFLAGS also in Env.initenv()
 *  - open_in: for parsing the mkfile (and included files)
 *)
type caps = < Cap.forkew; Cap.env; Cap.argv; Cap.open_in >
@
%TODO: delete chdir and -debugger?

<<signature [[CLI.main]]>>=
(* entry point (can also raise Exit.ExitCode) *)
val main: <caps; Cap.stdout; ..> ->
  string array -> Exit.t
@

<<toplevel [[Main._1]]>>=
let _ = 
  Cap.main (fun (caps : Cap.all_caps) ->
     let argv = CapSys.argv caps in
     Exit.exit caps 
        (Exit.catch (fun () -> 
            CLI.main caps argv))
  )
@


\section{[[main()]] skeleton}


<<function [[CLI.main]]>>=
let main (caps: <caps; Cap.stdout; ..>) (argv : string array) : Exit.t =
  let infile  = ref "mkfile" in
  let targets = ref [] in
  let vars = ref [] in
  <<[[CLI.main()]] debugging initializations>>

  let options = [
    <<[[CLI.main()]] [[options]] elements>>
  ] |> Arg.align
  in
  (* old: was Arg.parse but we want explicit argv control *)
  (try
    Arg.parse_argv argv options (fun t -> 
    match t with
    <<[[CLI.main()]] modify [[vars]] when definition-like argument>>
    | _ -> targets := t :: !targets
    ) usage;
  with
  | Arg.Bad msg -> UConsole.eprint msg; raise (Exit.ExitCode 2)
  | Arg.Help msg -> UConsole.print msg; raise (Exit.ExitCode 0)
  );
  <<[[CLI.main()]] logging initializations>>
  <<[[CLI.main()]] CLI action processing>>

  (* Let's go! *)
  try 
    build_targets (caps :> caps ) (Fpath.v !infile) targets !vars;
    Exit.OK
  with exn ->
    <<[[CLI.main()]] when [[exn]] thrown in [[build_targets()]]>>
@
%$
%TODO: use !targets too, remove some use of ref


  
<<constant [[CLI.usage]]>>=
let usage =
  "usage: mk [-f file] [options] [targets ...]"
@

<<[[CLI.main()]] [[options]] elements>>=
(* less: maybe should do a chdir (Dirname infile) *)
"-f", Arg.Set_string infile,
" <file> use file instead of mkfile";
@


<<signature [[CLI.build_targets]]>>=
val build_targets : <caps; ..> ->
  Fpath.t -> string list ref -> (string*string) list -> unit
@
% string list ref for targets, why? TODO: remove, so simpler code

<<signature [[CLI.build_target]]>>=
(* main algorithm *)
val build_target : <caps; ..> ->
  Env.t -> Rules.rules -> string (* target *) -> unit                                                       
@
% rename mk? to match better the C code? this function is the essence of mk


<<[[CLI.main()]] when [[Failure]] [[exn]] thrown in [[build_targets()]]>>=
(* lots of the mk errors are reported using failwith (e.g., "don't know
 * how to make xxx")
 *)
| Failure s -> 
   (* useful to indicate that error comes from mk, not subprocess *)
   Logs.err (fun m -> m "mk: %s" s);
   (* need to wait for other children before exiting, otherwise
    * could get corrupted incomplete object files.
    *)
   while !Scheduler.nrunning > 0 do
       try 
         (* todo: if dump_jobs, print pid we wait and its recipe *)
         CapUnix.wait caps () |> ignore;
         decr Scheduler.nrunning
       with Unix.Unix_error (error, _str1, _str2) ->
         failwith (spf "%s" (Unix.error_message error))
   done;
   Exit.Code 1
@
% why not Scheduler.waitup ()?
%alt: Move in Process management, Exit section later?

%\section{[[mk -]]{\em flag} arguments processing}
%ocaml: no needed section

\section{[[mk ]]{\em var}[[=]]{\em values} arguments processing}
\label{sec:vardef-command-line}


<<[[CLI.main()]] modify [[vars]] when definition-like argument>>=
  | _ when t =~ "^\\(.*\\)=\\(.*\\)$" ->
    let (var, value) = Regexp_.matched2 t in
    vars := (var, value)::!vars;
@

<<[[CLI.build_targets()]] initialize [[env]] using [[vars]]>>=
vars |> List.iter (fun (var, value) ->
 (* stricter: we do not allow list of strings for value for command-line
  * vars, but anyway I'm not sure how they could be parsed by Arg
  *)
  Env.add_var env var [value];
  Hashtbl.add env.Env.vars_commandline var true;
);
@
    
<<[[Env.t]] fields>>=
(* those vars can not be overriden by the mkfile *)
vars_commandline: string Hashtbl_.set;
@
% it's a hashset really, different from other

<<[[Env.add_var()]] ignore def if overriden on the command-line>>=
| _ when Hashtbl.mem env.vars_commandline s ->
  (* we do not override those vars *)
  Logs.info (fun m -> m "ignoring definition of %s specified on the command-line" s);
  ()
@
% so added above, but when parsing the file and call to Env.add_var
% with same var it will be overriden!

%\section{[[mk ]] remaining arguments processing}
%ocaml: section not needed anymore

%\section{Using the [[mkfile]] or [[mk -f]]{\em file}}
%ocaml: section not needed anymore



\section{Building the target(s)}

<<function [[CLI.build_targets]]>>=
let build_targets (caps : <caps; .. >) (infile : Fpath.t) (targets : string list ref) (vars : (string*string) list) : unit =

    (* initialisation *)
    let env = Env.initenv caps in
    <<[[CLI.build_targets()]] initialize [[env]] using [[vars]]>>
    <<[[CLI.build_targets()]] if debugger set>>

    (* parsing *)
    let instrs = FS.with_open_in caps Parse.parse infile in
    <<[[CLI.build_targets()]] possibly dump the AST>>

    (* evaluating (can modify targets with first targets in file if none provided) *)
    let rules, env = Eval.eval caps env targets instrs in
    <<[[CLI.build_targets()]] possibly dump the environment>>
    
    <<[[CLI.build_targets()]] sanity check [[targets]]>>
    (* less: build shellenv here ?*)
    !targets |> List.rev |> List.iter (fun target ->
      build_target caps env rules target
    )
@
% could build in parallel targets? why not build_graph here?
% at least internally it will build in parallel
%TODO: make eval return also name of first targets, so need less refs

%trans: Parse.parse, Eval.eval!
<<signature [[Parse.parse]]>>=
(* !internally modifies Globals.line and Globals.file! *)
val parse : Chan.i -> Ast.instr list
@

<<signature [[Eval.eval]]>>=
(* Evaluate the variables and backquotes in the mkfile (hence Cap.exec),
 * process the included files (hence Cap.open_in), index the rules, and return
 * the final environment (actually modify by side effect the environment).
 * 
 * Also sets the parameter to contain the first (simple) target found
 * in the file if it was not set already.
 * 
 * Note that eval() will call parse() internally as well as eval() itself
 * recursively to process '<file' instructions.
 *)
val eval :
  < Shell.caps ; Cap.open_in; .. > ->
  Env.t ->
  string list ref ->
  Ast.instr list ->
  Rules.rules * Env.t
@


% include has been expanded, vars too, only get simple/meta rules
<<function [[CLI.build_target]]>>=
let build_target (caps : <caps; ..>) (env : Env.t) (rules : Rules.rules) (target : string) : unit =
   let root = Graph.build_graph target rules in
   <<[[CLI.build_target()]] possibly dump the graph>>
   
   let ever_did = ref false in
   while root.G.state = G.NotMade do
     let did = ref false in

     (* may call internally Scheduler.run to schedule jobs and may
      * raise some Failure (e.g., "don't know how to make xxx")
      *)
     Outofdate.work caps env root did;

     if !did 
     then ever_did := true
     else 
       (* no work possible, let's wait for a job process to finish *)
       if !Scheduler.nrunning > 0
       then Scheduler.waitup caps ()
       (* else: impossible? *)
   done;
   <<[[CLI.build_target()]] wait after loop for possible remaining jobs>>
 
   if not !ever_did
   then print_string (spf "mk: '%s' is already up to date\n" root.G.name)
@
% while loop we described earlier in principle section for refined DFS
% algo ref{}

%trans: Graph.build_graph!

<<signature [[Graph.build_graph]]>>=
(* !will also modify hnode! *)
val build_graph : string (* target *) -> Rules.rules -> t
@


<<signature [[Outofdate.work]]>>=
(* work() may call internally Scheduler.run() to schedule jobs.
 * It will also modify by side effect the graph to set to 
 * Made or BeingMade some nodes.
 * May raise Failure ("don't know how to make xxx" | "no recipe to make xxx")
 *)
val work :
  < Shell.caps ; .. > ->
  Env.t ->
  Graph.node ->
  bool ref (* OUT parameter, did anything *) ->
  unit
@
%TODO: ugly Out param, better return a bool instead?

<<signature [[Scheduler.waitup]]>>=
val waitup : < Shell.caps ; Cap.env; .. > -> unit -> unit
@


<<[[CLI.build_target()]] wait after loop for possible remaining jobs>>=
(* bugfix: root can be BeingMade in which case we need to wait *)
while !Scheduler.nrunning > 0 do
  Scheduler.waitup caps ();
done;
@


<<[[CLI.build_targets()]] sanity check [[targets]]>>=
(* building *)
if !targets = []
then failwith "nothing to mk";
@


%trans: seen most important func, next chapters detail each component


%******************************************************************************
\chapter{Parsing the [[mkfile]]}
%******************************************************************************
\label{chap:parsing}

%toc: skeleton, lex, parse, eval next chapter
% Lex & Yacc requirement, see also \book{generators}

\section{[[parse()]] skeleton}
\label{sec:parse}

% parse and evaluate
<<function [[Parse.parse]]>>=
let parse (chan : Chan.i) : Ast.instr list =
    Globals.line := 1;
    Globals.file := Chan.origin chan;

    let lexbuf = Lexing.from_channel chan.Chan.ic in
    <<[[Parse.parse()]] nested [[lexfunc]] function>>
    try 
      Parser.program lexfunc lexbuf
    (* less: could track line of : and = *)
    with Parsing.Parse_error ->
      failwith (spf "%s:%d: Syntax error" !Globals.file !Globals.line)
@


<<constant [[Globals.file]]>>=
(* TODO: use Chan.origin? *)
let file = ref "<nofile>"
@
%$
<<constant [[Globals.line]]>>=
let line = ref 1
@

<<function [[Lexer.error]]>>=
let error s =
  failwith (spf "%s:%d: Lexical error, %s" !Globals.file !Globals.line s)
@

<<function [[Lexer.loc]]>>=
let loc () = 
  { Ast.file = Fpath.v !Globals.file; Ast.line = !Globals.line; }
@

<<function [[Parser.error_loc]]>>=
let error_loc (loc : Ast.loc) (s : string) =
  failwith (spf "%s:%d: Syntax error, %s" !!(loc.file) loc.line s)
@
<<function [[Parser.error]]>>=
let error s =
  error_loc { file = Fpath.v !Globals.file; line = !Globals.line } s
@

\section{Lexer}



\subsection{Overview}

<<Lexer.mll>>=
{
(* Copyright 2016 Yoann Padioleau, see copyright.txt *)
open Common
open Parser

(*****************************************************************************)
(* Prelude *)
(*****************************************************************************)
(* Limitations compared to mk:
 *  - does not handle unicode (use ulex?)
 *)
<<function [[Lexer.error]]>>
<<function [[Lexer.loc]]>>

<<type [[Lexer.state]]>>
<<global [[Lexer.state_]]>>

<<Lexer helpers>>
}
(*****************************************************************************)
(* Regexps aliases *)
(*****************************************************************************)
<<lexer regexp aliases>>

(*****************************************************************************)
(* Main rule *)
(*****************************************************************************)
<<rule [[Lexer.token]]>>

(*****************************************************************************)
(* Rule quote *)
(*****************************************************************************)
<<rule [[Lexer.quote]]>>

(*****************************************************************************)
(* Rule recipe *)
(*****************************************************************************)
<<rule [[Lexer.recipe]]>>

(*****************************************************************************)
(* Other Rules *)
(*****************************************************************************)
<<Lexer other rules>>
@


\ifallcode
<<Lexer helpers>>=
<<global [[Lexer.save_state__outside_brace]]>>
<<function [[Lexer.yyback]]>>
@
\fi

<<rule [[Lexer.token]]>>=
rule token = parse

  (* ----------------------------------------------------------------------- *)
  (* Spacing/comments *)
  (* ----------------------------------------------------------------------- *)
  <<[[Lexer.token()]] space cases>>
  <<[[Lexer.token()]] comment cases>>
      
  (* ----------------------------------------------------------------------- *)
  (* Symbols *)
  (* ----------------------------------------------------------------------- *)
  <<[[Lexer.token()]] symbol cases>>

  (* ----------------------------------------------------------------------- *)
  (* Variables *)
  (* ----------------------------------------------------------------------- *)
  <<[[Lexer.token()]] variable cases>>

  (* ----------------------------------------------------------------------- *)
  (* Quoted strings *)
  (* ----------------------------------------------------------------------- *)
  <<[[Lexer.token()]] quoted string cases>>

  (* ----------------------------------------------------------------------- *)
  (* Regular stuff *)
  (* ----------------------------------------------------------------------- *)
  <<[[Lexer.token()]] other cases>>

  (* ----------------------------------------------------------------------- *)
  | eof { EOF }
  | _ (*as c*)   { error (spf "unrecognized character: '%s'" (Lexing.lexeme lexbuf)) }
@
\swdefs{Lexer.token}

<<Parser tokens>>=
%token <string> TSpace
%token TNewline

%token <Ast.loc> TColon TEq TInf
%token TPercent

%token <string> TVar
%token <string> TQuoted
%token <string> TOther

%token <string> TLineRecipe
%token TEndRecipe

<<Parser extra tokens>>

%token EOF
@
\swdefs{Parser.token}



<<[[Lexer.token()]] other cases>>=
(* should be the union of the special characters mentioned before *)
| [^'\'' '`'  '$' '{' '}'  ':' '=' '<'  '%'   '\n' '\\' '#' ' ' '\t']+ 
    { TOther (Lexing.lexeme lexbuf) }
@
% so FOO=xxx => TOther "FOO"

<<[[Lexer.token()]] other cases>>=
(* todo? means we have to normalize a series of word elements *)
| '\\' { TOther "\\" }
@


%TODO: dump example of tokens (and -dump_tokens reference!)


\subsection{Lexer state}

<<type [[Lexer.state]]>>=
(* lexer state *)
type state = 
  | Start
  (* once we started to parse a rule, the next newline will start a recipe *)
  | AfterColon
  (* the lexing rules are different in a recipe; we do not parse rc's input *)
  | InRecipe
  <<[[Lexer.state]] other cases>>
@
%$

<<signature [[Lexer.state_]]>>=
val state_ : state ref
@

<<global [[Lexer.state_]]>>=
(* see also parse.ml and code using that global
 * ocaml-light: renamed to state_ cos conflict with state var used by ocamllex
 *)
let state_ = ref Start
@

<<[[Parse.parse()]] nested [[lexfunc]] function>>=
Lexer.state_ := Lexer.Start;
let lexfunc lexbuf =
  let tok =
    match !Lexer.state_ with
    | Lexer.Start 
    | Lexer.AfterColon 
    | Lexer.AfterEq 
    | Lexer.InBrace -> 
        Lexer.token lexbuf
    | Lexer.InRecipe -> 
        Lexer.recipe lexbuf
  in
  <<[[Parse.parse()]] [[lexfunc()]] possibly dump the token>>
  tok
in
@

<<signature [[Lexer.token]]>>=
val token: Lexing.lexbuf -> Parser.token
@

<<signature [[Lexer.recipe]]>>=
val recipe: Lexing.lexbuf -> Parser.token
@

\subsection{Comments and spaces}

<<lexer regexp aliases>>=
let space = [' ''\t']
@

<<[[Lexer.token()]] space cases>>=
(* in mk, spaces have a meaning *)
| space+        { TSpace (Lexing.lexeme lexbuf) }
@
% not skipped like in other language (including 'rc')


<<[[Lexer.token()]] comment cases>>=
(* comments *)
| '#' [^ '\n']* { token lexbuf }

(* escaped newline in comment (useful to handle) *)
| '#' [^ '\n']* '\\' '\n' 
    { incr Globals.line; 
      token lexbuf 
    }
@

\subsection{Newlines}

<<[[Lexer.token()]] space cases>>=
(* in mk, newline has a meaning *)
| '\n' { incr Globals.line;
         state_ := if !state_ = AfterColon then InRecipe else Start;
         TNewline }
@

<<[[Lexer.token()]] space cases>>=
(* escaped newline *)
| '\\' '\n'     { incr Globals.line; TSpace (Lexing.lexeme lexbuf) }
@



\subsection{Symbols}

<<[[Lexer.token()]] symbol cases>>=
| ':' { state_ := AfterColon; TColon (loc()) }
@

<<[[Lexer.token()]] symbol cases>>=
| '<'  { TInf (loc()) }
@
<<[[Lexer.token()]] symbol cases>>=
| '%'  { TPercent }
@


<<[[Lexer.token()]] symbol cases>>=
| '=' { if !state_ <> AfterEq
        (* todo? means we have to normalize a series of word elements *)
        then begin
          state_ := AfterEq;
          TEq (loc()) 
        end
        else TOther "=" 
     }
@

<<[[Lexer.state]] other cases>>=
(* once we started to parse an assign, the second = is like a string *)
| AfterEq
@


\subsection{Variables}

<<lexer regexp aliases>>=
let letter = ['a'-'z''A'-'Z''_']
let number = ['0'-'9']

(* stricter: WORDCHR = !utfrune("!\"#$%&'()*+,-./:;<=>?@[\\]^`{|}~", (r) *)
let ident = letter (letter | number)*
@


<<[[Lexer.token()]] variable cases>>=
(* stricter: force leading letter, so $0 is wrong (found bug in plan9/) *)
| '$'    (ident (*as s*))
    { let s = Lexing.lexeme lexbuf in TVar (String.sub s 1 (String.length s - 1)) }
@

<<[[Lexer.token()]] variable cases>>=
| '$''{' (ident (*as s*)) '}'
    { let s = Lexing.lexeme lexbuf in TVar (String.sub s 2 (String.length s - 3)) }
@
% explain why need {} because concatenated word elements $FOOxxx ?


\subsection{Quoted strings}

% if filenane have space, because space is used as separator, need
% escape mechanism or quoting mechanism

<<[[Lexer.token()]] quoted string cases>>=
| "'" { TQuoted (quote lexbuf) }
@
% will return TQuoted whose string does not contain enclosing quotes

% just single quote in mk (like in rc)

<<rule [[Lexer.quote]]>>=
(* opti? could use Buffer *)
and quote = parse
  | "'"                  { "" }
  (* escaped quote by writing a double quote *)
  | "''"                 { "'" ^ quote lexbuf }

  | '\\' '\n'            { incr Globals.line; " " ^ quote lexbuf }
  (* new: better error message instead of "missing closing '"  *)
  | '\n' { error "newline in quoted string" }

  | [^ '\\' '\'' '\n']+  { let x = Lexing.lexeme lexbuf in x ^ quote lexbuf }
  | '\\' { "\\" ^ quote lexbuf }

  (* new: instead of "missing closing '"  *)
  | eof  { error "end of file in quoted string" }
  | _    { error "missing closing '" }
@

\subsection{Recipe}

<<rule [[Lexer.recipe]]>>=
and recipe = parse
  | ('#'   [^'\n']*) (*as s*) '\n'?
      { let s = Lexing.lexeme lexbuf |> String.trim in
        incr Globals.line; TLineRecipe s }
  | space ([^'\n']* (*as s*)) '\n'?
      { let s = Lexing.lexeme lexbuf |> String.trim in
         incr Globals.line; TLineRecipe s }
  | [^ '#' ' ' '\t']    { state_ := Start; yyback 1 lexbuf; TEndRecipe }
  | eof                 { state_ := Start; yyback 1 lexbuf; TEndRecipe }
  | _ {error "unrecognized character in recipe" }
@
\swdefs{Lexer.recipe}

% When anything not indented, then stop of recipe

<<function [[Lexer.yyback]]>>=
(* pad: hack around ocamllex to emulate the yyless() of flex. The semantic
 * is not exactly the same than yyless(), so I use yyback() instead.
 * http://my.safaribooksonline.com/book/programming/flex/9780596805418/a-reference-for-flex-specifications/yyless
 *)
let yyback n lexbuf =
  lexbuf.Lexing.lex_curr_pos <- lexbuf.Lexing.lex_curr_pos - n;
  ()
  (* ocaml-light: lex_curr_p does not exist in ocaml-light, but
     TODO? anyway do we need this code?
  let currp = lexbuf.Lexing.lex_curr_p in
  lexbuf.Lexing.lex_curr_p <- { currp with
    Lexing.pos_cnum = currp.Lexing.pos_cnum - n;
  }
  *)
@



\section{Grammar}



\subsection{Overview}

<<Parser.mly>>=
%{
(* Copyright 2016 Yoann Padioleau, see copyright.txt *)
open Common
open Fpath_.Operators
open Ast

(*****************************************************************************)
(* Prelude *)
(*****************************************************************************)
(* Limitations compared to mk:
 *  - backquote only in words context, not at toplevel
 *    (you can not do  `echo '<foo.c'` and expect it to include foo.c)
 * todo:
 *  - good parsing error messages, right now hard.
 *    "missing include file name\n"    < no words.
 *    "multiple vars on left side of assignment\n"  words =
 *    "missing trailing :" (for rule attribute)
 *)

(*****************************************************************************)
(* Helpers *)
(*****************************************************************************)
<<function [[Parser.error_loc]]>>
<<function [[Parser.error]]>>
<<function [[Parser.attrs_of_string]]>>
%}

/*(*************************************************************************)*/
/*(*1 Tokens *)*/
/*(*************************************************************************)*/
<<Parser tokens>>

/*(*************************************************************************)*/
/*(*1 Rules type declaration *)*/
/*(*************************************************************************)*/
<<Parser entry points types>>
%%

<<grammar>>
@




<<grammar>>=
/*(*************************************************************************)*/
/*(*1 Program *)*/
/*(*************************************************************************)*/
<<rule [[Parser.program]]>>

/*(*************************************************************************)*/
/*(*1 Instr *)*/
/*(*************************************************************************)*/
<<rule [[Parser.instrs]]>>
<<rule [[Parser.instr]]>>

/*(* less: 
instr: error { }
  *)*/

/*(*************************************************************************)*/
/*(*1 Words *)*/
/*(*************************************************************************)*/
<<word rules>>

/*(*************************************************************************)*/
/*(*1 recipe *)*/
/*(*************************************************************************)*/
<<recipe rules>>

/*(*************************************************************************)*/
/*(*1 EBNF rules *)*/
/*(*************************************************************************)*/
<<ebnf rules>>
@


<<Parser entry points types>>=
%type <Ast.instr list> program
%start program
@

<<rule [[Parser.program]]>>=
program: instrs EOF { $1 }
@
\swdefs{Parser.program}

\subsection{Instructions (definitions, includes, and rules)}

<<rule [[Parser.instrs]]>>=
instrs: 
 | instr instrs  { $1 @ $2 }
 | /*(*empty*)*/ { [] }
@
\swdefs{Parser.instrs}
%alt: ebnf

<<rule [[Parser.instr]]>>=
instr:
 | TInf words TNewline 
    { [{ instr = Include $2; loc = $1 }] }
 /*(* stricter: no space after variable name, no private var syntax *)*/
 | TOther TEq words_opt TNewline        
    { [{ instr = Definition ($1, $3); loc = $2 }] }
 /*(* the rule! *)*/
 | words TColon words_opt TNewline recipe
    { [{ instr = Rule { targets=$1; prereqs=$3; attrs=[]; recipe=$5;}; loc = $2; }] }
 <<rule [[Parser.instr]] other cases>>
@ 


<<ebnf rules>>=
/*(* stricter: forbid just spaces; if have space, then must have a word *)*/
words_opt:
 | words          { $1 }
 | /*(*empty*)*/  { [] }
@


<<recipe rules>>=
recipe: recipe_lines_opt TEndRecipe 
 { if $1 = [] then None else Some (R $1) }

recipe_lines_opt:
 | /*(* empty *)*/              { [] }
 | TLineRecipe recipe_lines_opt { $1 :: $2 }
@
% move TENDRecipe up and remove intermediate recipe rule?
% hmm no cos called from Parse.ml, Lexer.recipe

<<rule [[Parser.instr]] other cases>>=
| TNewline             { [] }
| error TNewline { error "expected one of :<=\n" }
@


\subsection{Words}

<<word rules>>=
words: 
 /*(* remove leading spaces *)*/
 | spaces words_ { $2 }
 | words_        { $1 }
@

<<word rules>>=
/*(* the lexer agglomerates spaces in one TSpace token, but then the escaped
   * newline are not agglomerated so we may have multiple TSpace so
   * we should also normalize that.
   *)*/
spaces: 
 | TSpace { }
 | TSpace spaces { }
@
%alt: could be in ebnf rules, TSPace+

<<word rules>>=
words_:
 | word spaces words_ { (W $1) :: $3 }
 | word        { [W $1] }
 /*(* remove trailing spaces *)*/
 | word spaces { [W $1] }
@

\subsection{Word elements}

<<word rules>>=
/*(*less: normalize to concatenate possible TOther "xxx"::TOther "=" ? *)*/
word:
 | word_elem word { ($1::$2) }
 | word_elem      { [$1] }
@
%alt: ebnf rule

<<word rules>>=
word_elem:
 | TOther      { String $1 }
 | TQuoted     { String $1 }
 | TPercent    { Percent }
 | TVar        { Var (SimpleVar $1) }
 <<rule [[Parser.word_elem]] other cases>>
@


%******************************************************************************
\chapter{Evaluating the [[mkfile]]}
%******************************************************************************
\label{chap:eval}
%alt: Evaluating the rules?

% not really an interpreter, so "evaluating" a big exaggerated;
% just vars and include basically (and backquote extension in section X,
% which is why need complex caps)

\section{[[eval()]] skeleton}


<<function [[Eval.eval]]>>=
let eval (caps : < Cap.fork; Cap.exec; Cap.open_in; .. >) env targets_ref (xs : Ast.instr list) : Rules.rules * Env.t =
  let simples = Hashtbl.create 101 in
  let metas = ref [] in

  let rec instrs xs = 
    xs |> List.iter (fun instr ->
      let loc = instr.A.loc in
      match instr.A.instr with
      <<[[Eval.eval()]] match instruction kind cases>>
    )
  in
  instrs xs;
  { R. simples = simples; metas = !metas}, env
@
%$
% need rec instrs? because include!


<<function [[Eval.error]]>>=
let error (loc : Ast.loc) (s : string) =
  failwith (spf "%s:%d: Semantic error, %s" !!(loc.A.file) loc.A.line s)
@
%alt: (* TODO: use proper exn *) but conveninent to always use failwith
% for the simple error managemeint in Main.ml and Failure catch

<<function [[Eval.warning]]>>=
let warning (loc : Ast.loc) (s : string) : unit =
  Logs.warn (fun m -> m "warning: %s (at %s:%d)" s !!(loc.A.file) loc.A.line)
@


\section{Evaluating definitions}

<<[[Eval.eval()]] match instruction kind cases>>=
| A.Definition (s, ws) ->
  let xs = 
    match eval_words caps loc env ws with
    | Left xs -> xs
    (* stricter: no dynamic patterns *)
    | Right _ -> error loc "use quotes for variable definitions with %"
  in
  (try 
    Env.add_var env s xs
   with Env.Redefinition s ->
     error loc (spf "redefinition of %s" s)
  );
  Hashtbl.add env.E.vars_we_set s true;
@
% eval_words later

<<signature [[Eval.eval_words]]>>=
val eval_words : < Shell.caps; .. > -> Ast.loc -> Env.t ->
  Ast.words -> (string list, Percent.pattern list) Either.t
@

<<[[Env.t]] fields>>=
vars_we_set: string Hashtbl_.set;
@
% used in strict mode and in shprint
% hashset again
%TODO: rename, vars_set_in_file ? better to relate to vars_commandline?

\section{Evaluating includes}

<<[[Eval.eval()]] match instruction kind cases>>=
| A.Include ws ->
    let res = eval_words caps loc env ws in
    (match res with
    | Left [file] -> 
        if not (Sys.file_exists file)
        then warning loc (spf "skipping missing include file: %s" file)
        else
          let xs = FS.with_open_in caps Parse.parse (Fpath.v file) in
          (* recurse *)
          instrs xs
    (* new? what does mk does? *)
    | Left [] -> error loc "missing include file"
    (* stricter: force use quotes for filename with spaces or percent *)
    | Right _ | Left (_::_) -> 
        error loc "use quotes for filenames with spaces or %%"
    )
@
% call instrs here, hence need for rec earlier

% useful skipping when use .depend that are not there yet
% alt: failwith

\section{Evaluating rules}

<<[[Eval.eval()]] match instruction kind cases>>=
| A.Rule r -> 
    let targets = eval_words caps loc env r.A.targets in
    let prereqs = eval_words caps loc env r.A.prereqs in
    (match targets, prereqs with
    <<[[Eval.eval()]] when [[Rule r]] case, match [[targets]], [[prereqs]] cases>>
    )
@

<<[[Eval.eval()]] when [[Rule r]] case, match [[targets]], [[prereqs]] cases>>=
(* regular rules *)
| Left targets, Left prereqs ->
    let rfinal = { R.
                   targets = targets; 
                   prereqs = prereqs;
                   attrs = Set.of_list r.A.attrs;
                   recipe = r.A.recipe;
                   loc = loc;
                 } in

    targets |> List.iter (fun target ->
      (* less: could check if already there, in which case
       * need to Hashtbl.replace, not add.
       * todo: could have a :O: attribute clearly identifying
       * that you overwrite a previous rule!
       *)
      Hashtbl.add simples target rfinal
    );
    <<[[Eval.eval()]] adjusts [[targets_ref]] when first simple targets in mkfile>>
@

<<[[Eval.eval()]] adjusts [[targets_ref]] when first simple targets in mkfile>>=
if !targets_ref = [] 
then targets_ref := targets;
@
% adjust first targets!
%TODO: rewrite the code to still use ref but internal ref that is returned
% as part of eval

<<[[Eval.eval()]] when [[Rule r]] case, match [[targets]], [[prereqs]] cases>>=
(* meta rules *)
| Right targets, Right prereqs ->
    let rfinal = { R.
                   targets = targets; 
                   prereqs = prereqs;
                   attrs = Set.of_list r.A.attrs;
                   recipe = r.A.recipe;
                   loc = loc;
                 } in
    metas |> Stack_.push rfinal
@

<<[[Eval.eval()]] when [[Rule r]] case, match [[targets]], [[prereqs]] cases>>=
(* it is ok to have a % only for the target to allow
 * for instance rules such as %.o: $HFILES
 *)
| Right targets, Left prereqs ->
    let rfinal = { R.
                   targets = targets; 
                   prereqs = prereqs 
                     |> List.map (fun s -> P.P [P.PStr s]);
                   attrs = Set.of_list r.A.attrs;
                   recipe = r.A.recipe;
                   loc = loc;
                 } in
    metas |> Stack_.push rfinal
@
    
<<[[Eval.eval()]] when [[Rule r]] case, match [[targets]], [[prereqs]] cases>>=
| Left _, Right _ ->
    (* stricter: *)
    error loc "Forgot to use %% for the target"
@
        
\section{Evaluating words}

<<function [[Eval.eval_words]]>>=
let eval_words (caps :  < Cap.fork; Cap.exec; .. >) (loc : Ast.loc) (env : Env.t) (words : Ast.words) :
         (string list, Percent.pattern list) Either.t =
  
  let res = words |> List.map (eval_word caps loc env) in
  <<[[Eval.eval_words()]] nested function [[contain_percent]]>>
  if contain_percent res 
  (* a list of patterns *)
  then res |> List.map (function
    | Left xs -> xs |> List.map (fun s -> P.P [P.PStr s])
    | Right x -> [x]
  ) |> List.flatten |> (fun xs -> List.iter Percent.check_pattern xs; Right xs)
  (* a list of strings *)
  else res |> List.map (function
    | Left xs -> xs
    | Right (P.P xs) -> xs |> List.map (function 
        | P.PStr s -> s
        | P.PPercent -> raise (Impossible "contain_percent above is buggy then")
    ) |> (fun elems -> [elems |> String.concat ""])
  ) |> List.flatten |> (fun xs -> Env.check_values xs; Left xs)
@
% either simple rule, or meta rule if contains % or not

<<[[Eval.eval_words()]] nested function [[contain_percent]]>>=
let contain_percent xs = 
  xs |> List.exists (function
  | Left _ -> false
  | Right (P.P xs) -> List.mem P.PPercent xs
  )
in
@

<<function [[Eval.eval_word]]>>=
(* A word can become multiple strings!
 * opti? could use a Buffer 
 * invariant: 
 *  - the returned list of strings must not contain any empty string
 *  - less: the returned pattern must contain at least a PPercent
 *)
let rec eval_word (caps: < Cap.fork; Cap.exec; .. >) (loc: Ast.loc) (env : Env.t)  (wd : Ast.word) :
          (string list, Percent.pattern) Either.t =
  let (Ast.W word) = wd in
  let rec aux acc word_elements =
    match word_elements with
    | [] -> 
        if acc = []
        then Left []
        (* less: could look if any PPercent in acc and if not return a Left
         * TODO: should do that! bug otherwise? write test case?
         *)
        else Right (P.P (List.rev acc))
    | x::xs ->
      (match x with
      | A.String s -> aux ((P.PStr s)::acc) xs
      | A.Percent  -> aux (P.PPercent::acc) xs

      (* ocaml-light: | A.Var ((A.SimpleVar v | A.SubstVar (v, _, _)) as vkind) *)
      | A.Var ((A.SimpleVar _(*v*) | A.SubstVar (_(*v*), _, _)) as vkind)  ->
         let v =
           match vkind with
           | A.SimpleVar v -> v
           | A.SubstVar (v, _, _) -> v
         in
         let ys = 
           try 
             Hashtbl.find env.E.vars v 
           with Not_found ->
             <<[[Eval.eval_word()]] when [[Not_found]] exn thrown for var [[v]]>>
             []
         in
         <<[[Eval.eval_word()]] adjust [[ys]] for [[SubstVar]] case>>
         (match ys, acc, xs with
         <<[[Eval.eval_word]] when [[Var v]] case, matching [[ys, acc, xs]]>>
         )
      <<[[Eval.eval_word()]] match [[x]] other cases>>
      )
  in
  aux [] word
@

<<[[Eval.eval_word]] when [[Var v]] case, matching [[ys, acc, xs]]>>=
(* variable contains a single element (scalar) *)
| [str], acc, xs -> 
    aux ((P.PStr str)::acc) xs
@
<<[[Eval.eval_word]] when [[Var v]] case, matching [[ys, acc, xs]]>>=
(* variable contains many elements (array) *)
| _::_::_, [], [] -> 
    Left ys
@


<<[[Eval.eval_word]] when [[Var v]] case, matching [[ys, acc, xs]]>>=
(* variable does not contain anything *)
| [], [], []  -> 
    Left []
@

<<[[Eval.eval_word]] when [[Var v]] case, matching [[ys, acc, xs]]>>=
| [], acc, xs ->
    (* stricter: *)
    warning loc (spf "use of empty variable '%s' in scalar context" v);
    aux acc xs
@

<<[[Eval.eval_word]] when [[Var v]] case, matching [[ys, acc, xs]]>>=
| _::_::_, _acc, _xs ->
    (* stricter: *)
    error loc (spf "use of list variable '%s' in scalar context" v)
@


%******************************************************************************
\chapter{Building the Graph of Dependencies}
%******************************************************************************
\label{chap:graph}

%trans:
%toc:

<<function [[Graph.build_graph]]>>=
let build_graph target rules =
  let root = apply_rules target rules in
  <<[[Graph.build_graph()]] checks on the graph [[root]]>>
  <<[[Graph.build_graph()]] propagate attributes on the graph [[root]]>>
  root
@

\section{[[apply_rules()]] skeleton}

<<function [[Graph.apply_rules]]>>=
(* todo: infinite rule detection *)
let rec apply_rules target rules =
  Logs.debug (fun m -> m "apply_rules('%s')" target);

  (* the graph of dependency is a DAG, so we must look if node already there *)
  if Hashtbl.mem hnodes target
  then Hashtbl.find hnodes target
  else begin

    let node = new_node target in
    let arcs = ref [] in
  
    (* look for simple rules *)
    <<[[Graph.apply_rules()]] look for simple matching rules and update [[arcs]]>>

    (* look for meta rules *)
    <<[[Graph.apply_rules()]] look for meta matching rules and update [[arcs]]>>

    (* List.rev is optional. The order should not matter, but it can
     * be nice to have the same sequential order of exec as the one 
     * specified in the mkfile.
     *)
    node.arcs <- List.rev !arcs;
    node
  end
@
% rec, will recurse!



\section{Finding the simple rule(s) for a target}
\label{sec:finding-simple-rules}

<<[[Graph.apply_rules()]] look for simple matching rules and update [[arcs]]>>=
let rs = Hashtbl.find_all rules.R.simples target in
rs |> List.iter (fun r ->
  <<[[Graph.apply_rules()]] when found a simple rule for [[node]]>>

  let pre = r.R.prereqs in
  if pre = []
  then
    (* some tools (e.g., ocamldep) generate useless deps with no
     * recipe and no prereqs that we can safely skip (we could warn)
     *)
    if r.R.recipe = None
    then ()
    else arcs |> Stack_.push { dest = None; rule = rule_exec r }

  else pre |> List.iter (fun prereq ->
    (* recurse *)
    let dest = apply_rules prereq rules in
    arcs |> Stack_.push { dest = Some dest; rule = rule_exec r }
  )
);
@
% dest = None? what are those rules??

<<function [[Graph.rule_exec]]>>=
let rule_exec (r: string Rules.rule) : Rules.rule_exec =
  { R.recipe2 = r.R.recipe;
    R.loc2 = r.R.loc;
    R.attrs2 = r.R.attrs;

    R.stem = None;
    R.all_targets = r.R.targets;
    R.all_prereqs = r.R.prereqs;
  }
@
% stem = None here

<<[[Rules.rule_exec]] other fields>>=
all_targets: string list;
all_prereqs: string list;
@
% useful for?


\section{Finding matching metarules}

<<[[Graph.apply_rules()]] look for meta matching rules and update [[arcs]]>>=
let rs = rules.R.metas in
rs |> List.iter (fun r ->
  r.R.targets |> List.iter (fun target_pat ->
    (match Percent.match_ target_pat target with
    | None -> ()
    | Some stem ->
       (* less: if no recipe and no prereqs, skip, but weird rule no?
        * especially for a metarule, so maybe we should warn
        *)
       let pre = r.R.prereqs in
       if pre = []
       then arcs |> Stack_.push { dest = None; rule = rule_exec_meta r stem }
       else pre |> List.iter (fun prereq_pat ->
         let prereq = Percent.subst prereq_pat stem in
         (* recurse *)
         let dest = apply_rules prereq rules in
         arcs |> Stack_.push { dest = Some dest; rule=rule_exec_meta r stem }
      )
    )
  )
);
@

% Percent match, Percent subst

<<function [[Graph.rule_exec_meta]]>>=
let rule_exec_meta (r: Percent.pattern Rules.rule) (stem : string) : Rules.rule_exec =
  { R.recipe2 = r.R.recipe;
    R.loc2 = r.R.loc;
    R.attrs2 = r.R.attrs;

    R.stem = Some stem;
    R.all_targets = r.R.targets |> List.map (fun pat -> Percent.subst pat stem);
    R.all_prereqs = r.R.prereqs |> List.map (fun pat -> Percent.subst pat stem);
  }
@
% step this time!

\subsection{Matching a pattern: [[Percent.match_()]]}

<<signature [[Percent.match_]]>>=
(* return the possible stem *)
val match_ : pattern -> string -> string option
@

<<function [[Percent.match_]]>>=
(* ex: match_ [PStr "foo"; PPercent; PStr ".c"] "foobar.c" => Some "bar"
 * This is arguably (and sadly) more complicated than the C code.
 *)
let rec match_ (P pat) str =
  let len = String.length str in
  match pat with
  | [] -> raise PercentNotFound
  | x::xs ->
    (match x with
    | PStr s ->
        let len2 = String.length s in
        if len2 > len
        then None
        else
          if s <> (String.sub str 0 len2)
          then None
          else match_ (P xs) (String.sub str len2 (len - len2))
    | PPercent ->
        let str_pat_after = string_after_percent xs in
        let len_after = String.length str_pat_after in
        let len_matching_percent = len - len_after in
        if len_matching_percent < 0
        then None
        else
          let stem = String.sub str 0 len_matching_percent in
          if str_pat_after = String.sub str len_matching_percent 
            (len - len_matching_percent) && stem <> ""
          then Some stem
          else None
    )        
@

<<exception [[Percent.PercentNotFound]]>>=
exception PercentNotFound
@

<<function [[Percent.string_after_percent]]>>=
let rec string_after_percent xs =
  match xs with
  | [] -> ""
  | x::xs ->
    (match x with 
    | PStr s -> s ^ string_after_percent xs
    | PPercent -> raise TooManyPercents
    )
@

<<exception [[Percent.TooManyPercents]]>>=
exception TooManyPercents
@


\subsection{Substituting the stem: [[Percent.subst()]]}

<<signature [[Percent.subst]]>>=
val subst : pattern -> string (* stem *) -> string
@

<<function [[Percent.subst]]>>=
let subst (P pat) stem =
  pat |> List.map (function
    | PStr s -> s
    | PPercent -> stem
  ) |> String.concat ""
@
% simple




\section{Checking the graph and the rules}
\label{sec:check-graph}

<<[[Graph.build_graph()]] checks on the graph [[root]]>>=
check_cycle root;

(* must be before check_ambiguous! *)
<<[[Graph.build_graph()]] check vacuous nodes>>

check_ambiguous root;
@
% why must be before check_ambiguous?

\subsection{Cycle detection}
\label{sec:cycle-check}

% a DAG is ok, a full graph no.

<<signature [[Graph.check_cycle]]>>=
val check_cycle : t -> unit
@

<<[[Graph.node]] other fields>>=
(* used only for check_cycle for now *)
mutable visited: bool;
@

<<function [[Graph.check_cycle]]>>=
let check_cycle node =
  let rec aux trace node =
    (* stricter: mk also check if nodes has arcs, but looks wrong to me *)
    if node.visited
    then error_cycle node trace;

    node.visited <- true;
    node.arcs |> List.iter (fun arc ->
      arc.dest |> Option.iter (fun node2 -> 
        aux (node::trace) node2
      )
    );
    node.visited <- false;
  in
  aux [] node
@
% classic DFS


<<function [[Graph.error_cycle]]>>=
let error_cycle node trace =
  (* less: I could just display the loop instead of starting from root *)
  let str = 
    (node::trace) 
    |> List.rev 
    |> List.map (fun x -> 
      if x.name = node.name then spf "|%s|" x.name else x.name
     )
    |> String.concat "->"
  in
  failwith (spf "cycle in graph detected at target %s (trace = %s)"
              node.name str)
@
% restore visited? needed?

\subsection{Infinite rule detection}

%TODO: not implemented, quite tricky actually to understand too
% maybe could move in advanced topics chapter?

\subsection{Ambiguous rules detection}
\label{sec:ambiguous-checks}

<<signature [[Graph.check_ambiguous]]>>=
(* will also adjust the graph *)
val check_ambiguous : t -> unit
@

<<function [[Graph.check_ambiguous]]>>=
let rec check_ambiguous node =
  <<[[Graph.check_ambiguous()]] recurse on the arcs of the node>>

  let arcs_with_recipe = 
    node.arcs |> List.filter (fun arc -> R.has_recipe arc.rule) in
  (* opti? rule_exec is big now, so maybe need have a rule_exec id *)
  let groups_by_rule =
    arcs_with_recipe |> Assoc.group_by (fun arc -> arc.rule)
  in
  
  match List.length groups_by_rule with
  <<[[Graph.check_ambiguous()]] match length of [[groups_by_rule]] cases>>
@

<<[[Graph.check_ambiguous()]] match length of [[groups_by_rule]] cases>>=
| 1 -> ()
@

<<function [[Rules.has_recipe]]>>=
(* helpers *)
let has_recipe re =
  re.recipe2 <> None
@

<<function [[Graph.error_ambiguous]]>>=
let error_ambiguous node groups =
  let candidates = 
    groups |> List.map (fun (rule, arcs) -> 
      let loc = rule.R.loc2 in
      (* one arc representative is enough *)
      let arc = List.hd arcs in
      spf "\t%s <-(%s:%d)- %s" 
        node.name !!(loc.A.file) loc.A.line
        (match arc.dest with None -> "" | Some n -> n.name)
    )
  in
  failwith (spf "ambiguous recipes for %s: \n%s" 
              node.name  (candidates |> String.concat "\n"))
@

<<[[Graph.check_ambiguous()]] match length of [[groups_by_rule]] cases>>=
| 0 -> ()
  (* stricter? or report it later? *)
  (* failwith (spf "no recipe to make %s" node.name) *)
@



<<[[Graph.check_ambiguous()]] recurse on the arcs of the node>>=
node.arcs |> List.iter (fun arc ->
  (* less: opti: could use visited to avoid duplicate work in a DAG *)
  arc.dest |> Option.iter (fun node2 -> 
    (* recurse *)
    check_ambiguous node2
  );
);
@

\subsubsection{Specialized versus generic rules}
\label{sec:specialize-vs-generic}


<<[[Graph.check_ambiguous()]] match length of [[groups_by_rule]] cases>>=
| 2 | _ -> 
  (* feature: it's ok to have ambiguity between 1 simple rule and 1 meta rule.
   * The specialized simple rule has priority over the generic meta rule
   * (see specialize-vs-generic in Build.nw)
   *)
  let groups_with_simple_rule =
    groups_by_rule |> List_.exclude (fun (r, _) -> R.is_meta r) 
  in
  (match List.length groups_with_simple_rule with
  | 0 -> error_ambiguous node groups_by_rule
  <<[[Graph.check_ambiguous()]] when length [[groups_with_simple_rule]] is 1>>
  | 2 | _ -> error_ambiguous node groups_with_simple_rule
  )
@

<<function [[Rules.is_meta]]>>=
let is_meta re =
  re.stem <> None
@

<<[[Graph.check_ambiguous()]] when length [[groups_with_simple_rule]] is 1>>=
| 1 ->
  (* update graph *)
  node.arcs <- List_.exclude (fun arc -> R.is_meta arc.rule) node.arcs;
@


\subsection{Vacuous nodes removal}
\n def of vacuous =~ stupid


<<[[Graph.build_graph()]] check vacuous nodes>>=
root.probable <- true;
vacuous root |> ignore;
@

<<[[Graph.node]] other fields>>=
(* used for vacuous *)
mutable probable: bool;
@

<<[[Graph.apply_rules()]] when found a simple rule for [[node]]>>=
node.probable <- true;
@

<<function [[Graph.vacuous]]>>=
let rec vacuous node =
  let vacuous_node = ref (not node.probable) in
  
  node.arcs <- node.arcs |> List_.exclude (fun arc ->
    match arc.dest with
    | Some node2 -> 
        if vacuous node2 && R.is_meta arc.rule
        then begin
          Logs.warn (fun m -> m "vacuous arc detected: %s -> %s" 
                        node.name node2.name);
          true
        end else begin 
          vacuous_node := false; 
          false 
        end
    | None ->
        vacuous_node := false;
        false
  );
  if !vacuous_node
  then Logs.warn (fun m -> m "vacuous node detected: %s" node.name);
  !vacuous_node
@



%******************************************************************************
\chapter{Finding Outdated Files}
%******************************************************************************
\label{chap:finding-outdated}

% outdated mean either inexistent target or time older than
% its recently updated dependencies (e.g., .o vs .c)

\section{Exploring the graph: [[work()]]}

% main -> build_target -> <> -> outofdate; dorecipe
<<function [[Outofdate.work]]>>=
(* alt: we could return a job list, which would be cleaner, but it is
 * more efficient to run a job as soon as we find an opportunity.
 *)
let rec work (caps: < Cap.fork; Cap.exec; .. >) env node (did : bool ref) : unit =
  Logs.debug (fun m -> m "work(%s) time=%s" node.G.name (File.str_of_time node.G.time));

  if node.G.state = G.BeingMade
  then ()
  else 
    match node.G.arcs with
    (* a leaf *)
    | [] ->
        <<[[Outofdate.work()]] sanity check node time when leaf node>>
        (* less: why not call update here? *)
        node.G.state <- G.Made

    (* a node *)
    | xs ->
        let out_of_date = ref false in
        let ready = ref true in

        xs |> List.iter (fun arc ->
          match arc.G.dest with
          <<[[Outofdate.work()]] when iterating arc and matching [[arc.dest]] cases>>
        );
        if not !ready
        then ()
        else 
          if !out_of_date 
          then dorecipe caps env node did
          else node.G.state <- G.Made
@

<<[[Outofdate.work()]] sanity check node time when leaf node>>=
(* could be a virtual node, but weird to have a virtual node leaf *)
if node.G.time = None
then failwith (spf "don't know how to make '%s'" node.G.name);
@
% sometimes typo on filename in prereqs of a rule so file actually does not exist

<<[[Outofdate.work()]] when iterating arc and matching [[arc.dest]] cases>>=
| Some node2 ->
    (* TODO: why recurse if node is Made? *)
    (* recurse! *)
    work caps env node2 did;
    
    (match node2.G.state with
    | G.NotMade | G.BeingMade -> ready := false;
    | G.Made -> ()
    );

    if outofdate node arc
    then out_of_date := true
@

<<[[Outofdate.work()]] when iterating arc and matching [[arc.dest]] cases>>=
| None ->
    if node.G.time = None
    then out_of_date := true
@
% ???

<<function [[Outofdate.outofdate]]>>=
let outofdate node arc =
  match arc.G.dest with
  | None -> raise (Impossible "should not call outofdate on nodeless arcs")
  | Some node2 -> 
      (* I use the strictly < in the C version because on modern machines 
       * many files can be created in the same second. In OCaml,
       * the time is a float with higher precision so I can use back
       * the <=.
       *)
       (match node.G.time, node2.G.time with
       | Some t1, Some t2 -> t1 < t2
       (* in foo.exe: foo.o: foo.c, foo.exe and foo.o might not
        * exist and so have a time set to None. In that case,
        * I consider foo.exe also out of date as anyway foo.o
        * will be generated
        *)
       | _      , None    -> true
       | None   , Some _  -> true
       )
@

\section{Scheduling recipes: [[dorecipe()]]}
%alt: enqueuing recipes? or jobs?

% main -> build_target -> work -> <> ->
<<function [[Outofdate.dorecipe]]>>=
let dorecipe (caps : < Cap.fork; Cap.exec; .. >) env node (did : bool ref) : unit =
  if not (node.G.arcs |> List.exists (fun arc -> R.has_recipe arc.G.rule))
  then
    <<[[Outofdate.dorecipe()]] when no arcs with a recipe, if virtual node>>
    else failwith (spf "no recipe to make '%s'" node.G.name)
  else begin
    let master_arc = 
      try node.G.arcs |> List.find (fun arc -> R.has_recipe arc.G.rule)
      with Not_found -> raise (Impossible "List.exists above")
    in
    let master_rule = master_arc.G.rule in
    let all_targets = master_rule.R.all_targets in
    (* less: outofdate_targets (aka target) *)
    <<[[Outofdate.dorecipe()]] compute target [[nodes]]>>
    <<[[Outofdate.dorecipe()]] compute [[all_prereqs]]>>
    nodes |> List.iter (fun node -> node.G.state <- G.BeingMade);
    let job = { J. 
        rule = master_rule;
        env = env;
        main_target = node.G.name;
        target_nodes = nodes;
        all_targets = all_targets;
        all_prereqs = List.rev !all_prereqs;
    } in
    Scheduler.run caps job;
    did := true
  end
@
% why care about prereqs? for $prereqs!
% Could copy env? safer?

<<signature [[Scheduler.run]]>>=
(* need Cap.env for NPROC *)
val run : < Shell.caps ; Cap.env; .. > -> Job.t -> unit
@

<<[[Outofdate.dorecipe()]] compute target [[nodes]]>>=
let nodes =
  all_targets |> List.filter_map (fun target ->
    if Hashtbl.mem G.hnodes target
    then Some (Hashtbl.find G.hnodes target)
    (* TODO? failwith? when can this happen? *)
    else None
  )
in
@

<<[[Outofdate.dorecipe()]] compute [[all_prereqs]]>>=
(* less: newprereqs *)
let all_prereqs = ref [] in
(* bug: can not use Set for the accumulator below! Indeed, we want
 * the order for prereqs to be the original order in the mkfile.
 * If not, some command may not work if the order of the file
 * matters (e.g., with the ocaml linker the .cmo must be given
 * in a certain order)
 *)
let hdone_prereqs = Hashtbl.create 101 in
nodes |> List.iter (fun target ->
  target.G.arcs |> List.iter (fun arc ->
    arc.G.dest |> Option.iter (fun prereq ->
        <<[[Outofdate.dorecipe()]] when compute [[all_prereqs]] if explain mode>>
        if Hashtbl.mem hdone_prereqs prereq
        then ()
        else begin
          Hashtbl.add hdone_prereqs prereq true;
          Stack_.push prereq.G.name all_prereqs
        end
  )
));
@

<<function [[Outofdate.opt0]]>>=
let opt0 opttime =
  match opttime with
  | None -> 0.
  | Some x -> x
@



%******************************************************************************
\chapter{Scheduling Jobs}
%******************************************************************************
\label{chap:scheduling}


\section{Enqueuing jobs: [[run()]]}

% ... -> dorecipe -> <> -> sched
<<function [[Scheduler.run]]>>=
let run (caps : < Shell.caps; .. >) (job : Job.t) : unit =
  Queue.add job jobs;
  <<[[Scheduler.run]] possibly dump the job>>
  if !nrunning < nproclimit caps
  then sched caps ()
@
% note that this will return! it will not wait for the job
% to finish, so that work can find more work (which will 
% enqueue and also possibly schedule more work)

<<function [[Scheduler.nproclimit]]>>=
let nproclimit (caps: < Cap.env; ..>) =
  (try 
    let s = CapSys.getenv caps "NPROC" in
    int_of_string s
   with Not_found | _ -> 2
  )
@

\section{[[sched()]] skeleton}

% ... -> run | ??? -> <> -> ???
<<function [[Scheduler.sched]]>>=
let sched (caps : < Shell.caps; .. >) () =
  try 
    let job = Queue.take jobs in
    <<[[Scheduler.sched()]] possibly dump job>>
    let rule = job.J.rule in
    let recipe : string list = 
      match rule.R.recipe2 with 
      | Some (Ast.R x) -> x
      | None -> raise (Impossible "job without a recipe")
    in
    let env = adjust_env job in

    <<[[Scheduler.sched()]] guard to display the recipe>>
    then recipe |> List.iter (fun s -> shprint env s);

    <<[[Scheduler.sched()]] if dry mode>>
    else begin
      <<[[Scheduler.sched()]] let [[interactive]]>>
      (* This -e is super important! so that by default the recipe is run
       * so that any error in a simple command ran from the recipe, even inside
       * a for loop, will exit the whole recipe with the error.
       *)
      let pid = 
        Shell.exec_recipe caps (Env.shellenv_of_env env) ["-e"] recipe interactive
      in
      <<[[Scheduler.sched()]] possibly dump job after [[exec_recipe]]>>
      Hashtbl.add running pid job;
      incr nrunning
    end
    
  with Queue.Empty ->
    raise (Impossible "no jobs to schedule")
@
%TODO: move try/with inside let job

<<signature [[Shell.exec_recipe]]>>=
val exec_recipe :
  < caps; .. > ->
  Shellenv.t ->
  string list (* shell arguments (e.g., ["-e"]) *) ->
  string list (* shell stdin lines (the recipe) *) ->
  bool (* interactive *) ->
  int (* pid *)
@

<<constant [[Scheduler.running]]>>=
let running = Hashtbl.create 101
@

<<function [[Scheduler.adjust_env]]>>=
(* !modify by side effect job.env! *)
let adjust_env job =
  let env = job.J.env in

  (* less: should be all_target *)
  Hashtbl.replace env.E.internal_vars "target" [job.J.main_target];
  (* less: newprereqs *)
  Hashtbl.replace env.E.internal_vars "prereq" job.J.all_prereqs;
  job.J.rule.R.stem |> Option.iter (fun s ->
    Hashtbl.replace env.E.internal_vars "stem" [s];
  );

  env
@
% where is created env? Always from initial Env.initenv?
% no copy?

<<signature [[Env.shellenv_of_env]]>>=
val shellenv_of_env : t -> Shellenv.t
@

%alt: move later in Debugging section?
<<function [[Scheduler.shprint]]>>=
let shprint env s =
  let s = 
    s |> Str.global_substitute (Str.regexp "\\$\\([a-zA-Z][a-zA-Z0-9_]*\\)")
      (fun _wholestr ->
        let var = Str.matched_group 1 s in
        match () with
        | _ when Hashtbl.mem env.E.internal_vars var ->
            Hashtbl.find env.E.internal_vars var |> String.concat " "
        | _ when Hashtbl.mem env.E.vars_we_set var ->
            Hashtbl.find env.E.vars var |> String.concat " "
        | _ -> Str.matched_string s
      )
  in
  Logs.app (fun m -> m "|%s|" s)
@
%$

% when part of enclosing env then not printed, why?

\section{Executing Jobs: [[exec_recipe()]]}

<<type [[Shell.caps]]>>=
(* Need:
 *  - exec/fork/wait: obviously as we run a shell
 *  - env: for MKSHELL
 *)
type caps = < Cap.exec; Cap.fork; Cap.wait; Cap.env >
@

% ??? -> <>
% (double) fork pipe exec classic
<<function [[Shell.exec_recipe]]>>=
(* returns a pid *)
let exec_recipe (caps : < Cap.fork; Cap.exec; .. >) (shellenv : Shellenv.t) flags inputs (interactive : bool) : int =
  let pid = CapUnix.fork caps () in
  
  (* children case *)
  if pid = 0
  then
    <<[[Shell.exec_recipe]] when children case, if [[interactive]]>>
    else begin

    let (pipe_read, pipe_write) = Unix.pipe () in
    let pid2 = CapUnix.fork caps () in

    (* child 1, the shell interpeter, the process with pid returned by execsh *)
    if pid2 <> 0
    then begin
      Unix.dup2 pipe_read Unix.stdin;
      Unix.close pipe_read;
      Unix.close pipe_write;
      exec_shell caps shellenv flags []
      (* unreachable *)

    (* child 2, feeding the shell with inputs through a pipe *)
    end else begin
      Unix.close pipe_read;
      feed_shell_input inputs pipe_write;
      (* nosemgrep: do-not-use-exit (dont want to require caps for this one) *)
      exit 0;
    end
  end

  (* parent case *)
  else pid (* pid of child1 *)
@
% reorder if pid2 <>0 to pid2 = 0 to better match enclosing

<<signature [[Shell.exec_shell]]>>=
val exec_shell: <Cap.exec; Cap.env; ..> -> Shellenv.t -> string list -> string list ->
  unit
@


<<function [[Shell.feed_shell_input]]>>=
let feed_shell_input (inputs : string list) (pipe_write : Unix.file_descr) : unit =
  inputs |> List.iter (fun str ->
    let n = Unix.write pipe_write (Bytes.of_string str) 0 (String.length str) in
    if n < 0
    then failwith "Could not write in pipe to shell";
    let n = Unix.write pipe_write (Bytes.of_string "\n") 0 1 in
    if n < 0
    then failwith "Could not write in pipe to shell";
  );
  (* will flush *)
  Unix.close pipe_write
@


\section{Waiting for jobs to finish: [[waitup()]]}
\label{sec:waiting-processes}

% main -> build_target -> work(); <> -> ???
<<function [[Scheduler.waitup]]>>=
(* can call sched () hence the need for Shell.caps, not just Cap.wait *)
let waitup (caps : < Shell.caps; .. >) () =
  let (pid, ret) = 
    try 
      CapUnix.wait caps () 
    with Unix.Unix_error (error, str1, str2) ->
      failwith (spf "%s: %s (%s)" str1 (Unix.error_message error) str2)
  in
  let job = 
    try Hashtbl.find running pid
    with Not_found ->
      raise 
        (Impossible (spf "wait returned unexpected process with pid %d" pid))
  in
  <<[[Scheduler.waitup()]] possibly dump job>>
  Hashtbl.remove running pid;
  decr nrunning;

  match ret with
  <<[[Scheduler.waitup()]] matching [[ret]] cases>>
@

<<[[Scheduler.waitup()]] matching [[ret]] cases>>=
| Unix.WEXITED 0 ->
    job.J.target_nodes |> List.iter (fun node ->
      G.update node
    );
    (* similar code in run();
     * I added the test on jobs size though.
    *)
    if !nrunning < nproclimit caps && Queue.length jobs > 0
    then sched caps ()
@


<<signature [[Graph.update]]>>=
(* update time of node once the target node has been generated by a job *)
val update : node -> unit
@


<<function [[Graph.update]]>>=
(* update graph once a node has been built *)
let update node =
  node.state <- Made;
  Logs.debug (fun m -> m "update(): node %s time=%s" node.name 
                 (File.str_of_time node.time));
  
  <<[[Graph.update()]] if virtual node>>
  else begin
    let oldtime = node.time in
    node.time <- File.timeof (Fpath.v node.name);
    <<[[Graph.update()]] sanity check new [[node.time]]>>
  end
@

<<[[Graph.update()]] sanity check new [[node.time]]>>=
(* todo: actually can happen for rule like
 * x.tab.h: y.tab.h
 *   cmp -s x.tab.h y.tab.h || cp y.tab.h x.tab.h
 * (see plan9/shell/rc/mkfile).
 * In that case we should not failwith.
 * Because it is a rare case, maybe we should have a special
 * attribute for those rules, so not fail only when have this
 * attribute
 *)
if oldtime = node.time || node.time = None
then failwith (spf "recipe did not update %s, time =%s" node.name
                 (File.str_of_time node.time));
@


<<[[Scheduler.waitup()]] matching [[ret]] cases>>=
| Unix.WEXITED n ->
    <<[[Scheduler.waitup()]] job exited with error code [[n]], if [[Delete]] rule>>
    failwith (spf "error in child process, exit status = %d" n)
@



<<[[Scheduler.waitup()]] matching [[ret]] cases>>=
(* ocaml-light: Unix.WSIGNALED n | Unix.WSTOPPED n *)
| Unix.WSIGNALED n ->
    failwith (spf "child process killed/stopped by signal = %d" n)
| Unix.WSTOPPED n ->
    failwith (spf "child process killed/stopped by signal = %d" n)
@

%\section{Process management, [[Exit()]]}
% now done in Main.ml

\section{Notes (signals) management}

%TODO: not implemented



%******************************************************************************
\chapter{The Shell and its Environment}
%******************************************************************************
\label{chap:shellenv}
%alt: Interacting with the Shell

%trans: %toc:
% get env and use vars from enclosing env, and will prepare
% new env for child shell process executing recipe


%\section{[[Shellenv]] and [[shellenv]]}
%\label{sec:shellenv}

<<type [[Shellenv.t]]>>=
type t = (string * string list) list
@
%alt: move in Core DS chapter

\section{Initializing the shell environment: [[initenv()]]}

% main -> build_targets -> <>
<<signature [[Env.initenv]]>>=
(* Will read the OS environment variables (e.g., PATH, HOME, objtype).
 * Need also Cap.argv to set MKFLAGS
 *)
val initenv : < Cap.env ; Cap.argv; .. > -> t
@

<<function [[Env.initenv]]>>=
(* less: could take the readenv function as a parameter? *)
let initenv (caps : < Cap.env; Cap.argv; .. >) =
  let internals = 
    mk_vars |> List.map (fun k -> k,[]) |> Hashtbl_.of_list in
  let vars = 
    Shellenv.read_environment caps |> List_.exclude (fun (s, _) ->
      (* when you use mk recursively, the environment might contain
       * a $stem from a parent mk process.
       *)
      Hashtbl.mem internals s
    ) |> Hashtbl_.of_list
  in

  (* for recursive mk *)
  let mkflags = 
    CapSys.argv caps |> Array.fold_left (fun acc s ->
      if s =~ "^-" || s=~ ".*=.*"
      then s::acc
      else acc
    ) []
  in
  Hashtbl.add vars "MKFLAGS" (List.rev mkflags);

  (* less: extra checks and filtering on read_environment? *)
  { vars          = vars;
    internal_vars = internals;

    vars_we_set   = Hashtbl.create 101;
    vars_commandline   = Hashtbl.create 101;
  }
@
%$

<<function [[Env.shellenv_of_env]]>>=
let shellenv_of_env (env : t) : Shellenv.t =
  Hashtbl_.to_list env.internal_vars @
  Hashtbl_.to_list env.vars
@

<<signature [[Shellenv.read_environment]]>>=
val read_environment : < Cap.env ; .. > -> t
@

%\section{Importing the environment: [[readenv()]]}

<<function [[Shellenv.read_environment]]>>=
let read_environment (caps : < Cap.env; ..>) =
  CapUnix.environment caps () |> Array.to_list |> List.map (fun s ->
    if s =~ "\\([^=]+\\)=\\(.*\\)"
    then
      let (var, str) = Regexp_.matched2 s in
      var, Regexp_.split "[ \t]+" str
    else failwith (spf "wrong format for environment variable: %s" s)
  )
@


\section{Choice of shell and [[MKSHELL]]}
%alt: move in core DS?

<<type [[Shell.t]]>>=
type t = { 
  path: Fpath.t;
  name: string;
  flags: string list;
  (* environment word separator *)
  iws: string;
  debug_flags: unit -> string list;
  (* less: in theory the escaping and quoting rules are different between
   * shells, so this should be part of the interface.
   *)
}
@


<<constant [[Shell.sh]]>>=
let sh = {
  path = Fpath.v "/bin/sh";
  name = "sh";
  flags = [];
  iws = " ";
  debug_flags = (fun () -> []);
}
@

<<constant [[Shell.rc]]>>=
let rc = {
  path = Fpath.v "/usr/bin/rc";
  name = "rc";
  flags = ["-I"]; (* non-interactive so does not display a prompt *)
  iws = "\001";
  debug_flags = (fun () -> (* if !Flags.verbose then ["-v"] else [] *) []);
}
@


<<function [[Shell.shell_from_env_opt]]>>=
(* old: this is a toplevel entity, so the code below is executed even
 * before main, so you can not rely on the value in Flags as they have
 * not been set yet.
 * update: we now use capabilities so we could rely on Flags now
 * less: could use lazy to avoid recompute each time
 *)
let shell_from_env_opt (caps : < Cap.env; .. >) : t option = 
  try 
    Logs.info (fun m -> m "looking for $MKSHELL");
    let path = CapSys.getenv caps "MKSHELL" in
    match path with
    | s when s =~ ".*/rc$" -> Some { rc with path = Fpath.v path }
    | _ -> Some { sh with path = Fpath.v path }
  with Not_found -> None
@
%$

%\section{Adjusting the shell environment: [[buildenv()]]}
%\section{Exporting the shell environment: [[exportenv()]]}

\section{[[exec_shell()]]}
% finally

% ??? -> sched -> exec_recipe -> <>
<<function [[Shell.exec_shell]]>>=
let exec_shell (caps : < Cap.exec; Cap.env; ..>) shellenv flags extra_params =
  let shell = shell_from_env_opt caps ||| sh in
  let env = 
    shellenv 
    (* bug: I exclude empty variables
     * otherwise rc does strange things. Indeed, programs
     * such as ocamlc get confused by empty variables
     * used in shell commands such as ocamlc $FLAG where FLAG is empty.
     * I get the problem also with mk-plan9port.
     * Note however that there is no problem with mk-sh.byte, so
     * this is an rc issue.
     *)
    |> List_.exclude (fun (_s, xs) -> xs = [])
    |> List.map (fun (s, xs) -> spf "%s=%s" s (String.concat shell.iws xs))
  in
  let args = flags @ shell.flags @ shell.debug_flags() @extra_params in
  let shell_path = !!(shell.path) in
  Logs.info (fun m -> m "exec_shell: %s %s" shell_path (String.concat " " args));
  (try 
     (* to debug pass instead "/usr/bin/strace" 
        (Array.of_list ("strace"::shell.path::args)) *)
     CapUnix.execve caps
       (* bugfix: need to pass shell.name too! otherwise the first elt
        * in args (usually '-e') will be taken for the prog name and skipped
        * by the shell (and mk will not stop at the first error)
        *)
       shell_path (Array.of_list (shell.name::args))
       (Array.of_list env)
      |> ignore;
   with Unix.Unix_error (err, fm, argm) -> 
     if not (Sys.file_exists shell_path)
     then failwith (spf "could not find shell %s" shell_path)
     else failwith (spf "Could not execute a shell command: %s %s %s"
                      (Unix.error_message err) fm argm)
  );
  (* nosemgrep: do-not-use-exit (unreachable) *)
  exit (-2)
@
%$

%trans: and done! seen everything! from parsing to executing!

%******************************************************************************
\chapter{Debugging help for the [[mk]] User}
%******************************************************************************
\label{chap:debugging-support}

%TODO?  and Profiling Support
% debugging for the user here! See Debugging appendix
% for debugging developer of mk itself (e.g., internal dumpers)

% seen file/line fields in Rule, so can report error accurately.

%\section{Printing jobs: [[shprint()]]}
%\subsection{Expanding and printing variables}
%\subsection{Printing quoted strings}

\section{Logging: [[mk -v]]}
% see also Debugging chapter later

<<[[CLI.main()]] debugging initializations>>=
let level = ref (Some Logs.Warning) in
@

<<[[CLI.main()]] [[options]] elements>>=
(* TODO: move in a CLI_common.ml *)
"-v", Arg.Unit (fun () -> level := Some Logs.Info),
 " verbose mode";
@
<<[[CLI.main()]] [[options]] elements>>=
"-verbose", Arg.Unit (fun () -> level := Some Logs.Info),
" verbose mode";
@


<<[[CLI.main()]] logging initializations>>=
Logs_.setup !level ();
Logs.info (fun m -> m "ran from %s" (Sys.getcwd ()));
@
% will see with -v (or -debug), will not see by default (or when -quiet)

<<[[CLI.main()]] [[options]] elements>>=
"-quiet", Arg.Unit (fun () -> level := None),
" ";
@
% remove even warnings

\section{Explain mode: [[mk -e]]}

<<constant [[Flags.explain_mode]]>>=
let explain_mode = ref false
@

<<[[CLI.main()]] [[options]] elements>>=
"-e", Arg.Set Flags.explain_mode,
" explain mode";
@

<<[[Outofdate.dorecipe()]] when compute [[all_prereqs]] if explain mode>>=
(* less: could do that instead in work when find out about
 * an outofdate arc
 *)
if !Flags.explain_mode && outofdate node arc
then Logs.info (fun m -> m "%s(%.1f) < %s(%.1f)"
            node.G.name (opt0 node.G.time)
            prereq.G.name (opt0 prereq.G.time));
@

\section{Dry mode: [[mk -n]]}

<<constant [[Flags.dry_mode]]>>=
let dry_mode = ref false
@

<<[[CLI.main()]] [[options]] elements>>=
"-n", Arg.Set Flags.dry_mode,
" dry mode";
@


<<[[Scheduler.sched()]] if dry mode>>=
if !Flags.dry_mode 
then job.J.target_nodes |> List.iter (fun node ->
  node.G.time <- Some (Unix.time ());
  node.G.state <- G.Made;
)
@
% no exec_recipe branch

\section{What-if mode: [[mk -w]]{\em file}}
% ported to OCaml?

%\section{Processor utilization: [[mk -u]]}
%TODO

\section{Strict mode}

%new: not in original mk
<<constant [[Flags.strict_mode]]>>=
let strict_mode = ref false
@
<<[[CLI.main()]] [[options]] elements>>=
(* less: -a, etc *)
"-strict", Arg.Set Flags.strict_mode,
" strict mode";
@


<<[[Env.add_var()]] forbid redefinition in strict mode>>=
(* stricter: forbid redefinitions.
 * (bug: but ok to redefine variable from environment, otherwise
 *  hard to use mk recursively, hence the use of vars_we_set below)
 * less: could allow to redefine in strict mode if previous
 *  def was empty.
 *)
| _ when Hashtbl.mem env.vars s && Hashtbl.mem env.vars_we_set s 
    && !Flags.strict_mode ->
  raise (Redefinition s)
@

<<exception [[Env.Redefinition]]>>=
exception Redefinition of string
@



<<[[Eval.eval_word()]] when [[Not_found]] exn thrown for var [[v]]>>=
(* stricter: mk does not complain *)
if !Flags.strict_mode
then begin 
  if !Flags.dump_env 
  then Env.dump_env env;
  error loc (spf "variable not found '%s'" v);
end;
@
% see dump_env later
  


%******************************************************************************
\chapter{Advanced Features}
%******************************************************************************
\label{chap:advanced}

%\section{Regular-expression rules: [[:R:]]}
%\label{sec:regexp}

\section{Shell-command expansion: [[`]]{\em cmd}[[`]]}
\label{sec:backquotes}
%TODO: copy titles from Make.nw

\subsection{Parsing backquotes}

<<[[Ast.word_element]] cases>>=
 (* stricter: backquotes are allowed only in word context, not at toplevel
  * so no `echo '<foo.c'` *)
 (* `...` or `{...} (the string does not include the backquote or braces) *)
| Backquoted of string
@

<<Parser extra tokens>>=
%token <string> TBackquoted
@

<<[[Lexer.token()]] quoted string cases>>=
(* stricter: does not allow leading space *)
(* sh syntax *)
| "`" { TBackquoted (backquote lexbuf) }
(* rc syntax *)
| "`{" { TBackquoted (backquote2 lexbuf) }
@

<<Lexer other rules>>=
<<rule [[Lexer.backquote]]>>
<<rule [[Lexer.backquote2]]>>
@

<<rule [[Lexer.backquote]]>>=
(* sh syntax *)
and backquote = parse
  | "`"                  { "" }

  | '\\' '\n'            { incr Globals.line; " " ^ backquote lexbuf }
  (* new: instead of "missing closing '"  *)
  | '\n' { error "newline in backquoted string" }

  | [^ '\\' '\'' '`' '\n']+ 
      { let x = Lexing.lexeme lexbuf in x ^ backquote lexbuf }
  (* bugfix: we want to preserve the quote here! *)
  | "'" { let s = quote lexbuf in "'" ^ s ^ "'" ^ backquote lexbuf }

  (* new: instead of "missing closing `"  *)
  | eof  { error "end of file in backquoted string" }
  | _    { error "missing closing `" }
@

<<rule [[Lexer.backquote2]]>>=
(* rc syntax *)
and backquote2 = parse
  | "}"                  { "" }

  | '\\' '\n'            { incr Globals.line; " " ^ backquote2 lexbuf }
  (* new: instead of "missing closing '"  *)
  | '\n' { error "newline in backquoted string" }

  | [^ '\\' '\'' '}' '\n']+ 
      { let x = Lexing.lexeme lexbuf in x ^ backquote2 lexbuf }
  (* bugfix: we want to preserve the quote here! *)
  | "'" { let s = quote lexbuf in "'" ^ s ^ "'" ^ backquote2 lexbuf }

  (* new: instead of "missing closing `"  *)
  | eof  { error "end of file in backquoted string" }
  (* TODO: if use } below get weird ocamllex error *)
  |_ { error "missing closing brace" }
@

<<rule [[Parser.word_elem]] other cases>>=
| TBackquoted { Backquoted $1 }
@

\subsection{Executing backquotes}

<<[[Eval.eval_word()]] match [[x]] other cases>>=
| A.Backquoted cmd -> 
  let shellenv = Env.shellenv_of_env env in
  let s = Shell.exec_backquote caps shellenv cmd in
  let ys = Str.split (Str.regexp "[ \t\n]+") s in
  (match acc, xs with
  | [], []  -> Left ys
  (* stricter: *)
  | _ -> error loc (spf "use of `%s` in scalar context" cmd)
  )
@

%\subsection{Adjusting [[exec_recipe()]]}

<<signature [[Shell.exec_backquote]]>>=
val exec_backquote :
  < caps; .. > ->
  Shellenv.t ->
  string (* sh stdin (recipe) *) ->
  string (* sh output *)
@


<<function [[Shell.exec_backquote]]>>=
let exec_backquote (caps : < caps; ..>) (shellenv : Shellenv.t) (input : string) =
  let (pipe_read_input, pipe_write_input)   = Unix.pipe () in
  let (pipe_read_output, pipe_write_output) = Unix.pipe () in

  let pid = CapUnix.fork caps () in

  (* child case *)
  if pid = 0
  then begin
    Unix.dup2 pipe_read_input Unix.stdin;
    Unix.dup2 pipe_write_output Unix.stdout;
    Unix.close pipe_read_input;
    Unix.close pipe_write_input;
    Unix.close pipe_read_output;
    Unix.close pipe_write_output;

    exec_shell caps shellenv [] [] 
    (* unreachable *)
  end else begin
    (* parent case *)

    Unix.close pipe_read_input;
    Unix.close pipe_write_output;

    feed_shell_input [input] pipe_write_input;

    (* read the shell output through the other pipe *)
    let buffer = Bytes.create 1024 in
    let rec loop_read () =
      let n = Unix.read pipe_read_output buffer 0 1024 in
      match n with
      | 0 -> ""
      | _ when n < 0 ->
        failwith "Could not read from pipe to shell";
      | _ -> 
        let s = Bytes.sub_string buffer 0 n in
        s ^ loop_read ()
    in
    let output = loop_read () in
    CapUnix.waitpid caps [] pid |> ignore;
    output
  end
@
% diff with exec_recipe? can factorize?
        
\section{Dynamic [[mkfile]]: [[<|]]{\em prog}}
\label{sec:dynamic-mkfile}

% compensate for lack of ifdef of GNU make?
% ifdef are kinda useful, see Makefiles of Goken9cc

<<[[Ast.instr_kind]] cases>>=
(* the words can contain variables, ex: <|rc ../foo.rc $CONF 
 * less: we could also do PipeInclude of recipe I think *)
| PipeInclude of words
@


<<Parser extra tokens>>=
%token <Ast.loc> TInfPipe
@

<<[[Lexer.token()]] symbol cases>>=
| "<|" { TInfPipe (loc()) }
@

<<rule [[Parser.instr]] other cases>>=
| TInfPipe words TNewline  { [{instr = PipeInclude $2; loc = $1}] }
@

<<[[Eval.eval()]] match instruction kind cases>>=
| A.PipeInclude ws ->
  let res = eval_words caps loc env ws in
  let recipe = 
    match res with
    | Left xs -> String.concat " " xs
    | Right _xs -> raise Todo
  in
  if recipe = ""
  then failwith "missing include program name";
  let shellenv = Env.shellenv_of_env env in
  let tmpfile = Shell.exec_pipecmd caps shellenv recipe in
  let xs = FS.with_open_in caps Parse.parse (Fpath.v tmpfile) in
  (* recurse *)
  instrs xs
@

<<signature [[Shell.exec_pipecmd]]>>=
val exec_pipecmd :
  < caps ; .. > ->
  Shellenv.t ->
  string (* sh stdin (recipe) *) ->
  string (* sh output *)
@

<<function [[Shell.exec_pipecmd]]>>=
let exec_pipecmd (caps: < caps; .. >) (shellenv : Shellenv.t) input =
  let tmpfile = Filename.temp_file "mk" "sh" in
  let (pipe_read_input, pipe_write_input)   = Unix.pipe () in

  let pid = CapUnix.fork caps () in

  (* child case *)
  if pid = 0
  then begin
    Unix.dup2 pipe_read_input Unix.stdin;
    Unix.close pipe_read_input;
    Unix.close pipe_write_input;
    let fd = Unix.openfile tmpfile [Unix.O_WRONLY] 0o640 in
    Unix.dup2 fd Unix.stdout;
    Unix.close fd;

    exec_shell caps shellenv [] [];
    (* unreachable *)
  end else begin
    (* parent case *)

    Unix.close pipe_read_input;
    
    feed_shell_input [input] pipe_write_input;

    let (pid2, status) = CapUnix.waitpid caps [] pid in
    if pid <> pid2
    then raise (Impossible "waitpid takes the specific pid");
    (match status with
    | Unix.WEXITED 0 -> tmpfile
    (* stricter: fail fast, no "warning: skipping missing program file: " *)
    | _ -> failwith "bad include program status"
    )
  end
@
% diff with other exec_xxx? can't factorize a bit?  

\section{Substitution variables: [[${]]{\em name}[[:]]{\em pattern}[[=]]{\em subst}[[}]]}
\label{sec:subst-var}

\subsection{Parsing substitutions}

<<[[Ast.var]] cases>>=
 (* ${name:a%b=c%d} *)
| SubstVar of (string * word * word list)
@

<<Parser extra tokens>>=
%token <string> TVarColon
%token TCBrace
@

<<[[Lexer.token()]] variable cases>>=
(* important to eat ':' otherwise would trigger a AfterColon we don't want *)
| '$' '{' (ident (*as s*)) ':'
    {
      let s = Lexing.lexeme lexbuf in
      (* this is to handle '=' inside ${} *)
      save_state_outside_brace := !state_;
      state_ := InBrace;
      TVarColon (String.sub s 2 (String.length s - 3)) 
    }
| '}' 
    { state_ := !save_state_outside_brace; 
      save_state_outside_brace := Start;
      TCBrace 
    }

| '$' { error "missing variable name" }
@
%$

<<[[Lexer.state]] other cases>>=
(* except inside ${x:...=...} where we still want = to be TEq *)
| InBrace
@

<<global [[Lexer.save_state__outside_brace]]>>=
(* A single var is enough since mk does not allow recursivity in braces
 * as in ${x:%${y}x=%.c}. We do not need a stack.
 * *)
let save_state_outside_brace = ref Start
@


<<rule [[Parser.word_elem]] other cases>>=
| TVarColon word TEq words TCBrace { Var (SubstVar ($1, W $2, $4)) }
@


\subsection{Executing substitutions}

<<[[Eval.eval_word()]] adjust [[ys]] for [[SubstVar]] case>>=
let ys =
  match vkind with
  | A.SimpleVar _ -> ys
  | A.SubstVar (_, pattern, substs) -> 
    (* recurse! pattern can contain some variable *)
    let pattern = eval_word caps loc env pattern in
    let subst   = substs |> List.map (eval_word caps loc env) in
    (match pattern, subst with
    | Right pattern, [Right subst] ->
        ys |> List.map (fun s -> 
          Percent.match_and_subst pattern subst s
        )
    (* todo: ugly, should be more general, works only for 
     * subst like ${OPAM_LIBS:%=-I $OPAM/%}
    *)
    | Right pattern, [Right (P.P [P.PStr x]); Right subst] ->
        ys |> List.map (fun s -> 
          [x;Percent.match_and_subst pattern subst s]
        ) |> List.flatten
    (* stricter? what does mk?*)
    | _ -> 
      Logs.debug (fun m -> m "subst = %s" (Dumper.dump subst));
      error loc 
        "pattern or subst does not resolve to a single string"
    )
in
@

%: [[subsub()]]

<<signature [[Percent.match_and_subst]]>>=
(* print a warning if not match *)
val match_and_subst :
  pattern (* pattern *) -> pattern (* subst *) -> string (* src *) -> string
@

<<function [[Percent.match_and_subst]]>>=
let match_and_subst pat sub str =
  match match_ pat str with
  | Some stem -> subst sub stem
  | None -> str
@

\section{Rule attributes}
\label{sec:rule-attributes-advanced}

\subsection{Parsing and propagating rule attributes}
<<rule [[Parser.instr]] other cases>>=
| words TColon TOther TColon words_opt TNewline recipe 
    { [{instr = Rule { targets = $1; prereqs = $5; 
                       attrs = attrs_of_string $2 $3; 
                       recipe = $7;
                      };
        loc = $2;
       }]
    }
@

<<function [[Parser.attrs_of_string]]>>=
let attrs_of_string loc s =
  s |> Common2.list_of_string |> List.map (function
    | 'Q' -> Quiet
    | 'V' -> Virtual
    | 'D' -> Delete
    | 'I' -> Interactive
    | ('N' | 'R' | 'n') as c  -> NotHandled c
    | c -> error_loc loc (spf "unknown attribute: %c" c)
  )
@

<<[[Graph.build_graph()]] propagate attributes on the graph [[root]]>>=
propagate_attributes root;
@

<<function [[Graph.propagate_attributes]]>>=
let rec propagate_attributes node =
  node.arcs |> List.iter (fun arc ->
    arc.rule.R.attrs2 |> Set.iter (function
      | A.Virtual -> 
          node.is_virtual <- true;
          (* maybe there was a file with the name of the virtual target 
           * in the directory, but we do not want its time
           *)
          node.time <- None;
      | _ -> ()
    );
    arc.dest |> Option.iter propagate_attributes
  )
@


<<[[Ast.rule]] other fields>>=
attrs: rule_attribute list;
@

<<type [[Ast.rule_attribute]]>>=
and rule_attribute =
<<[[Ast.rule_attribute]] cases>>
| NotHandled of char
@



<<[[Rules.rule]] other fields>>=
attrs: Ast.rule_attribute Set_.t;
@

<<[[Rules.rule_exec]] other fields>>=
attrs2: Ast.rule_attribute Set_.t;
@
  
\subsection{Virtual target: [[:V:]]}
\label{sec:virtual}


<<[[Ast.rule_attribute]] cases>>=
| Virtual
@

<<[[Graph.node]] other fields>>=
mutable is_virtual: bool;
@

<<[[Graph.update()]] if virtual node>>=
if node.is_virtual
then begin
  node.time <- Some 1.0;
  (* less: take max time of prereqs, need that? *)
end
@


<<[[Outofdate.dorecipe()]] when no arcs with a recipe, if virtual node>>=
if node.G.is_virtual
then G.update node
@


\subsection{Deleting a target when the recipe returns an error: [[:D:]]}

<<[[Ast.rule_attribute]] cases>>=
| Delete
@

<<[[Scheduler.waitup()]] job exited with error code [[n]], if [[Delete]] rule>>=
(* less: call shprint *)
if Set.mem Ast.Delete job.J.rule.R.attrs2 
then 
  job.J.rule.R.all_targets |> List.iter (fun f ->
    if Sys.file_exists f
    then begin
      Logs.info (fun m -> m "deleting %s" f);
      Sys.remove f
    end
  );
@

\subsection{Not printing the recipe (quiet mode): [[:Q:]]}

<<[[Ast.rule_attribute]] cases>>=
| Quiet
@

<<[[Scheduler.sched()]] guard to display the recipe>>=
if not (Set.mem Ast.Quiet rule.R.attrs2)
@

\subsection{Running a shell script without [[-e]]: [[:E:]]}
%TODO

\subsection{Disabling the no-recipe warning: [[:N:]]}
%TODO

\subsection{Forbidding metarules to match virtual targets:  [[:n:]]}
%TODO

%\subsection{Custom-dependency comparison program: [[:P:]]}
%\label{sec:custom-comparison}

\subsection{Interactive recipe: [[:I:]]}

<<[[Ast.rule_attribute]] cases>>=
| Interactive (* pad: I added this one *)
@

<<[[Scheduler.sched()]] let [[interactive]]>>=
let interactive = Set.mem Ast.Interactive rule.R.attrs2 in
@

<<[[Shell.exec_recipe]] when children case, if [[interactive]]>>=
(* pad: I added this feature so mk can call interactive program
 * such as syncweb. Otherwise stdin is used to feed the shell
 * and so any program called from the shell will not have any stdin
 *)
if interactive 
then begin
  let tmpfile = Filename.temp_file "mk" "sh" in
  (try
     (* nosemgrep: use-caps *)
     let chan = open_out tmpfile in
     inputs |> List.iter (fun s -> 
       output_string chan s; 
       output_string chan "\n"
     );
     close_out chan
   with Sys_error s -> 
     failwith (spf "Could not create temporary file (error = %s)" s)
  ); 
  exec_shell caps shellenv flags [tmpfile]
  (* less: delete tmpfile *)
(* unreachable *)
end 
@

\section{Variable attributes}
\label{sec:variable-attributes}

\subsection{Private variables: [[=U=]]}

\section{Advanced [[mk]] variables}

\subsection{[[$target]] versus [[$alltargets]]}

\subsection{[[$prereq]] versus [[$newprereq]]}

\subsection{[[$NREP]]}

\subsection{[[$pid]]}

\subsection{[[$nproc]]}


%\section{Dealing with archives (libraries)}

\section{Optimizations}

%\subsection{Node cache}

%\subsection{Missing-intermediates optimization: [[mk -I]]}
%\label{sec:pretending}

%\subsection{Touching-mode optimization: [[mk -t]]}

\subsection{Time cache}
\label{sec:time-cache}

\subsection{Bulk time optimisation}

\section{Recompiling everything: [[mk -a]]}

\section{Recursive [[mk]]}
% MKFLAGS

\section{[[mk -k]]}
% ??

%******************************************************************************
\chapter{Conclusion}
%******************************************************************************
\label{chap:conclusion}


%******************************************************************************
\appendix
%******************************************************************************


%******************************************************************************
\chapter{Debugging for the [[mk]] Developer}
%******************************************************************************
\label{chap:debugging-appendix}

 
<<constant [[Flags.debugger]]>>=
let debugger = ref false
@
%TODO: DELETE

<<[[CLI.main()]] [[options]] elements>>=
"-debugger", Arg.Set Flags.debugger,
" ";
@

<<[[CLI.build_targets()]] if debugger set>>=
(* ???
if !Flags.debugger then begin
  CapSys.chdir caps (Filename.dirname !!infile);
  Env.add_var env "objtype" ["386"]
end;
*)
@

\section{Exception backtraces}

<<[[CLI.main()]] debugging initializations>>=
let backtrace = ref false in
@
<<[[CLI.main()]] [[options]] elements>>=
"-backtrace", Arg.Set backtrace,
" dump the backtrace after an error";
@

<<[[CLI.main()]] when [[exn]] thrown in [[build_targets()]]>>=
if !backtrace || !Flags.debugger
then raise exn
else 
  (match exn with
  <<[[CLI.main()]] when [[Failure]] [[exn]] thrown in [[build_targets()]]>>
  | _ -> raise exn
  )
@

\section{Tracing function calls: [[mk -debug]]}
% Logging part2

<<[[CLI.main()]] [[options]] elements>>=
"-debug", Arg.Unit (fun () -> 
  level := Some Logs.Debug;
  Flags.explain_mode := true;
),
" trace the main functions";
@
% explain_mode later

   
\section{Dumpers}


\subsection{Dumping tokens: [[mk -dump_tokens]]}

<<constant [[Flags.dump_tokens]]>>=
let dump_tokens = ref false
@
<<[[CLI.main()]] [[options]] elements>>=
"-dump_tokens", Arg.Set Flags.dump_tokens,
" dump the tokens as they are generated";
@

<<[[Parse.parse()]] [[lexfunc()]] possibly dump the token>>=
if !Flags.dump_tokens 
then Logs.app (fun m -> m "%s" (Dumper.dump tok));
@

\subsection{Dumping the AST: [[mk -dump_ast]]}

<<constant [[Flags.dump_ast]]>>=
let dump_ast = ref false
@
<<[[CLI.main()]] [[options]] elements>>=
"-dump_ast", Arg.Set Flags.dump_ast,
" dump the parsed AST";
@

<<[[CLI.build_targets()]] possibly dump the AST>>=
if !Flags.dump_ast
then Ast.dump_ast instrs;
@

<<function [[Ast.dump_ast]]>>=
let dump_ast instrs =
  Logs.app (fun m -> m "AST = %s" (show_instrs instrs))
@

\subsection{Dumping the environment: [[mk -dump_env]]}

<<constant [[Flags.dump_env]]>>=
let dump_env = ref false
@
<<[[CLI.main()]] [[options]] elements>>=
"-dump_env", Arg.Set Flags.dump_env,
" dump the environment";
@

<<signature [[Env.dump_env]]>>=
val dump_env : t -> unit
@
<<[[CLI.build_targets()]] possibly dump the environment>>=
if !Flags.dump_env
then Env.dump_env env;
@

<<function [[Env.dump_env]]>>=
let dump_env env =
  Logs.debug (fun m -> m "Dump_env:");
  env.vars |> Hashtbl.iter (fun k v ->
    Logs.debug (fun m -> m " %s -> %s" k (Dumper.dump v));
  )
@

\subsection{Dumping the graph: [[mk -dump_graph]]}
%alt: could be put in User Debugging chapter? Useful feature for the user no?

<<constant [[Flags.dump_graph]]>>=
let dump_graph = ref false
@
<<[[CLI.main()]] [[options]] elements>>=
"-dump_graph", Arg.Set Flags.dump_graph,
" dump the generated graph (in graphviz dot format)";
@

<<[[CLI.build_target()]] possibly dump the graph>>=
(* could do that after the checks *)
if !Flags.dump_graph 
then Graph.dump_graph root;
@

<<signature [[Graph.dump_graph]]>>=
(* output graphviz dot file *)
val dump_graph : t -> unit
@


<<function [[Graph.dump_graph]]>>=
let dump_graph node =
  let pr s = 
    print_string (s ^ "\n") 
  in
  pr "digraph misc {";
  pr "size = \"10,10\";" ;
  let hdone = Hashtbl.create 101 in
  let rec aux node1 =
    if Hashtbl.mem hdone node1.name
    then ()
    else begin
      Hashtbl.add hdone node1.name true;
      node1.arcs |> List.iter (fun arc ->
        match arc.dest with
        | None -> pr (spf "\"%s\" -> \"<NOTHING>\";    # %s" 
                        node1.name (loc_of_arc arc))
        | Some node2 -> 
          pr (spf "\"%s\" -> \"%s\";       # %s" 
                node1.name node2.name (loc_of_arc arc));
          (* recurse *)
          aux node2
      )
    end
  in
  aux node;
  pr "}";
  ()
@

<<function [[Graph.loc_of_arc]]>>=
let loc_of_arc arc =
  let loc = arc.rule.R.loc2 in
  spf "(%s:%d)" !!(loc.Ast.file) loc.Ast.line
@

\subsection{Tracing jobs: [[mk -dump_jobs]]}

<<constant [[Flags.dump_jobs]]>>=
let dump_jobs = ref false
@
<<[[CLI.main()]] [[options]] elements>>=
"-dump_jobs", Arg.Set Flags.dump_jobs,
" ";
@

<<[[Scheduler.run]] possibly dump the job>>=
if !Flags.dump_jobs
then dump_job "run: " job None;
@

<<[[Scheduler.sched()]] possibly dump job>>=
if !Flags.dump_jobs
then dump_job "sched1: firing up " job None;
@

<<[[Scheduler.sched()]] possibly dump job after [[exec_recipe]]>>=
if !Flags.dump_jobs
then dump_job "sched2: " job (Some pid);
@

<<[[Scheduler.waitup()]] possibly dump job>>=
if !Flags.dump_jobs
then dump_job "waitup: " job (Some pid);
@


<<function [[Scheduler.dump_job]]>>=
let dump_job func job pidopt =
  Logs.debug (fun m -> m "(%d): %s pid = %d; targets = %s" 
         (Unix.getpid())
         func 
         (match pidopt with Some pid -> pid | None -> 0)
         (job.J.target_nodes |> List.map (fun node -> node.G.name) 
             |> String.concat " "))
@


\section{CLI Actions}

<<[[CLI.main()]] debugging initializations>>=
let action = ref "" in
@

<<[[CLI.main()]] [[options]] elements>>=
(* pad: I added that *)
"-test_parser", Arg.Unit (fun () -> action := "-test_parser"), " ";
@
<<[[CLI.main()]] [[options]] elements>>=
"-test_eval", Arg.Unit (fun () -> action := "-test_eval"), " ";
@

<<[[CLI.main()]] CLI action processing>>=
(* to test and debug components of mk *)
if !action <> "" then begin 
  do_action caps !action (List.rev !targets); 
  raise (Exit.ExitCode 0)
end;
@
  
<<function [[CLI.do_action]]>>=
(* to test the different mk components *)
let do_action caps s xs =
  match s with
  | "-test_parser" ->
      xs |> List.iter (fun file ->
        Logs.info (fun m -> m "processing %s" file);
        let instrs = FS.with_open_in caps Parse.parse (Fpath.v file) in
        Console.print caps (spf "%s" (Ast.show_instrs instrs))
      )
  | "-test_eval" ->
      xs |> List.iter (fun file ->
        Logs.info (fun m -> m "processing %s" file);
        let env = Env.initenv caps in
        let instrs = FS.with_open_in caps Parse.parse (Fpath.v file) in
        let _rules, env = Eval.eval caps env (ref []) instrs in
        Env.dump_env env;
        ()
      )
  | _ -> failwith ("action not supported: " ^ s)
@

%******************************************************************************
\chapter{Profiling}
%******************************************************************************
\label{chap:profiling-appendix}

%\chapter{Error Management}
%\label{chap:error}

% related is mk -k, but not really error management in the end.
% automatic error handling
% Also call Exit, not exit! so carefully wait for children.

%\chapter{Utilities}
%\label{chap:utilities}

%******************************************************************************
\chapter{Examples of [[mkfile]]s}
%******************************************************************************
\label{chap:examples}

\section{The [[mkfile]] of [[mk]]}
% actually need also mkprog, mkcommon, mkconfig, etc.

\section{The [[mkfile]]s of \plan}

%\chapter{Changelog}
% code via 'cd ..;mk loc' = 3070 LOC (after lpizer), after full lpized ?? LOC
% orig Mk.nw = 3972 LOC, after full lpized and comments in sections ??
% now: ? LOC so added ?? LOE (Lines of explanations)
% mk in C: ? LOC (but not all features: no archive, no :P, etc)



\ifallcode
#include "omk_extra.nw"
\fi %ifallcode


%******************************************************************************
\chapter*{Glossary}
\addcontentsline{toc}{chapter}{Glossary}
\label{sec:glossary}

\begin{verbatim}
LOC = Lines Of Code
DSL = Domain Specific Language
DAG = Directed Acyclic Graph
DFS = Depth-First Search
\end{verbatim}

\chapter*{Indexes}
\addcontentsline{toc}{chapter}{Index}

%src: wc.nw in noweb source
Here is a list of the identifiers used, and where they appear.
Underlined entries indicate the place of definition.
This index is generated automatically.

%\twocolumn does not work
\nowebindex

%\chapter{References} 
\addcontentsline{toc}{chapter}{References}

\bibliography{latex/Principia}
\bibliographystyle{alpha}

%******************************************************************************
% Postlude
%******************************************************************************

\end{document}
