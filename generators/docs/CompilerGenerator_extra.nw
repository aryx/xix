\section{[[ocamllex/]]}

\subsection{[[lex/Ast.ml]]}


%-------------------------------------------------------------

<<lex/Ast.ml>>=
<<copyright ocamllex>>
(* The shallow abstract syntax *)

<<type [[Syntax.charpos]]>>

<<type [[Syntax.location]]>>

<<type [[Syntax.char_]]>>

let char_class c1 c2 =
  let rec cl n =
    if n > c2 then [] else n :: cl(succ n)
  in cl c1

(* CONFIG *)
let charset_size = 256
let char_eof = 256
let all_chars = char_class 0 255
(* alt:
let charset_size = 255
let char_eof = 0
let all_chars = char_class 1 255
*)

<<type [[Syntax.regular_expression]]>>

<<type [[Syntax.action]]>>

<<type [[Syntax.rule]]>>

<<type [[Syntax.lexer_definition]]>>
@


\subsection{[[lex/Output.mli]]}



%-------------------------------------------------------------

<<lex/Output.mli>>=
<<copyright ocamllex>>
<<signature [[Output.output_lexdef]]>>

val output_lexdef_simple:
      in_channel -> out_channel ->
      Ast.location (* header *) ->
      Lexgen.automata_entry list * Lexgen.automata_matrix ->
      Ast.location (* trailer *) ->
      unit


@


\subsection{[[lex/Output.ml]]}


%-------------------------------------------------------------

<<lex/Output.ml>>=
<<copyright ocamllex>>
(* Output the DFA tables and its entry points *)

open Printf
open Ast
open Lexgen
open Compact

<<constant [[Output.copy_buffer]]>>

<<function [[Output.copy_chunk]]>>

<<function [[Output.output_byte]]>>

<<function [[Output.output_array]]>>

<<function [[Output.output_tables]]>>

<<function [[Output.output_entry]]>>

<<function [[Output.output_lexdef]]>>

(*****************************************************************************)
(* Simpler version *)
(*****************************************************************************)

let debug = ref true

(* 1- Generating the actions *)

let output_action ic oc (i,act) =
  output_string oc ("action_" ^ string_of_int i ^ " lexbuf = (\n");
  if !debug 
  then output_string oc (" log \"action_" ^ string_of_int i ^ "\";\n");
  copy_chunk ic oc act;
  output_string oc ")\nand ";
  ()

(* 2- Generating the states *)

let states = ref ([||] : Lexgen.automata_matrix)

let enumerate_vect v =
  let rec enum env pos =
    if pos >= Array.length v 
    then env 
    else
      try
        let pl = List.assoc v.(pos) env in
          pl := pos :: !pl; enum env (succ pos)
        with Not_found ->
          enum ((v.(pos), ref [pos]) :: env) (succ pos) 
  in
  List.sort
    (fun (_e1, pl1) (_e2, pl2) -> compare (List.length !pl1)  (List.length !pl2))
    (enum [] 0)

let output_move oc = function
    Backtrack ->
      if !debug
      then output_string oc "log \"backtrack\"; ";
      output_string oc "backtrack lexbuf"
  | Goto dest ->
      match !states.(dest) with
        Perform act_num ->
          output_string oc ("action_" ^ string_of_int act_num ^ " lexbuf")
      | _ ->
          (* Many states are just Perform so this explains why there is some
           * big jumps in the generated files from e.g. state_3 to state_9
           * without any intermediate state_4 function; it's because state 4
           * was a Perform.
           *)
          output_string oc ("state_" ^ string_of_int dest ^ " lexbuf")

let output_char_for_read oc = function
    '\''  -> output_string oc "\\'"
  | '\\' -> output_string oc "\\\\"
  | '\n' -> output_string oc "\\n"
  | '\t' -> output_string oc "\\t"
  | c ->
      let n = Char.code c in
      if n >= 32 && n < 127 then
        output_char oc c
      else begin
        output_char oc '\\';
        output_char oc (Char.chr (48 + n / 100));
        output_char oc (Char.chr (48 + (n / 10) mod 10));
        output_char oc (Char.chr (48 + n mod 10))
      end

let rec output_chars oc = function
    [] ->
      failwith "output_chars"
  | [c] ->
      if c <= 255 then begin
      output_string oc "'";
      output_char_for_read oc (Char.chr c);
      output_string oc "'"
      end else output_string oc "'\\000'"
  | c::cl ->
      if c <= 255 then begin
      output_string oc "'";
      output_char_for_read oc (Char.chr c);
      output_string oc "'|";
      output_chars oc cl
      end else output_string oc "'\\000'"

let output_one_trans oc (dest, chars) =
  output_chars oc !chars;
  output_string oc " -> ";
  output_move oc dest;
  output_string oc "\n |  ";
  ()

let output_all_trans oc trans =
  output_string oc "  let c = Lexing.get_next_char lexbuf in\n";
  if !debug
  then output_string oc "  log (\"consuming:\" ^ (Char.escaped c));\n";
  output_string oc "  match c with\n    ";
  match enumerate_vect trans with
    [] ->
      failwith "output_all_trans"
  | (default, _) :: rest ->
      List.iter (output_one_trans oc) rest;
      output_string oc "_ -> ";
      output_move oc default;
      output_string oc "\nand ";
      ()

let output_state oc state_num = function
    Perform _i ->
      ()
  | Shift(what_to_do, moves) ->
      output_string oc
        ("state_"  ^ string_of_int state_num ^ " lexbuf =\n");
      if !debug 
      then output_string oc("  log \"state_" ^string_of_int state_num^ "\";\n");

    (match what_to_do with
      No_remember -> ()
    | Remember i ->
        output_string oc "  lexbuf.lex_last_pos <- lexbuf.lex_curr_pos;\n";
        output_string oc ("  lexbuf.lex_last_action_simple <- Obj.magic action_" ^
                             string_of_int i ^ ";\n")
    );
    output_all_trans oc moves

(* 3- Generating the entry points *)
          
let rec output_entries oc = function
    [] -> failwith "output_entries"
  | entry :: rest ->
      let name = entry.auto_name in
      let state_num = entry.auto_initial_state in
      output_string oc (name ^ " lexbuf =\n");
      if !debug 
      then output_string oc ("log \"" ^ name ^ "\";\n");
      output_string oc "  Lexing.start_lexing lexbuf;\n";
      output_string oc ("  state_" ^ string_of_int state_num ^ " lexbuf\n");
      match rest with
        [] -> output_string oc "\n"; ()
      | _  -> output_string oc "\nand "; output_entries oc rest

(* All together *)

let output_lexdef_simple ic oc header (initial_st, st) trailer =
  print_int (Array.length st); print_string " states, ";
(*  print_int (List.length actions); print_string " actions."; *)
  print_newline();
  (* for the labels *)
  output_string oc "open Lexing\n\n";
  if !debug
  then output_string oc
    "let log x = print_endline (\"LEX: \" ^ x); flush stdout\n";
  copy_chunk ic oc header;
  output_string oc "\nlet rec ";
  states := st;
  initial_st |> List.iter (fun entry ->
    let actions = entry.auto_actions in
    List.iter (output_action ic oc) actions;
    output_string oc "\n";
  );
  output_string oc "\n";
  for i = 0 to Array.length st - 1 do
    output_state oc i st.(i)
  done;
  output_string oc "\n";
  output_entries oc initial_st;
  output_string oc "\n";
  copy_chunk ic oc trailer

@


\subsection{[[lex/Lexgen.mli]]}


%-------------------------------------------------------------

<<lex/Lexgen.mli>>=
<<copyright ocamllex>>
(* Representation of automata *)

<<type [[Lexgen.action_id]]>>

<<type [[Lexgen.automata]]>>
<<type [[Lexgen.automata_trans]]>>
<<type [[Lexgen.automata_move]]>>

<<type [[Lexgen.automata_entry]]>>

<<type [[Lexgen.automata_matrix]]>>

<<signature [[Lexgen.make_dfa]]>>
@


\subsection{[[lex/Lexgen.ml]]}


%-------------------------------------------------------------

<<lex/Lexgen.ml>>=
<<copyright ocamllex>>
(* Compiling a lexer definition *)

open Ast
module Set = Set_
module Map = Map_

<<type [[Lexgen.action_id]]>>

<<type [[Lexgen.charset_id]]>>

<<type [[Lexgen.regexp]]>>

<<type [[Lexgen.lexer_entry]]>>
    
(* Representation of automata *)

<<type [[Lexgen.automata]]>>
<<type [[Lexgen.automata_trans]]>>
<<type [[Lexgen.automata_move]]>>

<<type [[Lexgen.automata_entry]]>>

<<type [[Lexgen.automata_matrix]]>>
    
(* From shallow to deep syntax *)

<<constant [[Lexgen.chars]]>>
<<constant [[Lexgen.chars_count]]>>
<<constant [[Lexgen.actions]]>>
<<constant [[Lexgen.actions_count]]>>

<<function [[Lexgen.encode_regexp]]>>

<<function [[Lexgen.encode_casedef]]>>

<<function [[Lexgen.encode_lexdef]]>>


(* To generate directly a NFA from a regular expression.
   Confer Aho-Sethi-Ullman, dragon book, chap. 3 *)

<<type [[Lexgen.transition]]>>

<<type [[Lexgen.state]]>>

<<function [[Lexgen.nullable]]>>

<<function [[Lexgen.firstpos]]>>

<<function [[Lexgen.lastpos]]>>

<<function [[Lexgen.followpos]]>>

<<constant [[Lexgen.no_action]]>>

<<function [[Lexgen.split_trans_set]]>>

<<constant [[Lexgen.state_map]]>>
<<constant [[Lexgen.todo]]>>
<<constant [[Lexgen.next_state_num]]>>

<<function [[Lexgen.reset_state_mem]]>>

<<function [[Lexgen.get_state]]>>

<<function [[Lexgen.map_on_all_states]]>>

<<function [[Lexgen.goto_state]]>>

<<function [[Lexgen.transition_from]]>>

<<function [[Lexgen.translate_state]]>>

<<function [[Lexgen.encode_lexentries]]>>

<<function [[Lexgen.make_dfa]]>>
@


\subsection{[[lex/Compact.mli]]}


%-------------------------------------------------------------

<<lex/Compact.mli>>=
<<copyright ocamllex>>
<<type [[Compact.lex_tables]]>>

<<signature [[Compact.compact_tables]]>>
@


\subsection{[[lex/Compact.ml]]}



%-------------------------------------------------------------

<<lex/Compact.ml>>=
<<copyright ocamllex>>
(* Compaction of an automata *)

open Lexgen

<<function [[Compact.most_frequent_elt]]>>

<<function [[Compact.non_default_elements]]>>

(* Compact the transition and check arrays *)

<<global [[Compact.trans]]>>
<<global [[Compact.check]]>>
<<global [[Compact.last_used]]>>


<<function [[Compact.grow_transitions]]>>

<<function [[Compact.pack_moves]]>>

<<type [[Compact.lex_tables]]>>

<<function [[Compact.compact_tables]]>>

@

\subsection{[[lex/CLI.mli]]}

<<signature [[CLI.main]]>>=
val main: unit -> unit
@

%-------------------------------------------------------------

<<lex/CLI.mli>>=
<<signature [[CLI.main]]>>
@

\subsection{[[lex/CLI.ml]]}


%-------------------------------------------------------------

<<lex/CLI.ml>>=
<<copyright ocamllex>>
(* The lexer generator. Command-line parsing. *)

open Ast
(* for ocaml-light fields access *)
open Lexgen
open Output

<<function [[CLI.main]]>>

@

\subsection{[[lex/Main.ml]]}


%-------------------------------------------------------------

<<lex/Main.ml>>=

<<toplevel [[Main._1]]>>
@

\subsection{[[lex/Lexer.mll]]}


%----------------------------------------------------


\subsection{[[lex/parser.mly]]}

<<copyright ocamllex bis>>=
/***********************************************************************/
/*                                                                     */
/*                           Objective Caml                            */
/*                                                                     */
/*            Xavier Leroy, projet Cristal, INRIA Rocquencourt         */
/*                                                                     */
/*  Copyright 1996 Institut National de Recherche en Informatique et   */
/*  Automatique.  Distributed only by permission.                      */
/*                                                                     */
/***********************************************************************/
@
% C style comment, for parser.mly


\subsection{[[stdlib/Lexing_.mli]]}


<<signature [[Lexing.from_channel]]>>=
val from_channel : in_channel -> lexbuf
        (* Create a lexer buffer on the given input channel.
           [Lexing.from_channel inchan] returns a lexer buffer which reads
           from the input channel [inchan], at the current reading position. *)
@

<<signature [[Lexing.from_string]]>>=
val from_string : string -> lexbuf
        (* Create a lexer buffer which reads from
           the given string. Reading starts from the first character in
           the string. An end-of-input condition is generated when the
           end of the string is reached. *)
@

<<signature [[Lexing.from_function]]>>=
val from_function : (bytes -> int -> int) -> lexbuf
        (* Create a lexer buffer with the given function as its reading method.
           When the scanner needs more characters, it will call the given
           function, giving it a character string [s] and a character
           count [n]. The function should put [n] characters or less in [s],
           starting at character number 0, and return the number of characters
           provided. A return value of 0 means end of input. *)
@



<<signature [[Lexing.lexeme]]>>=
val lexeme : lexbuf -> string
        (* [Lexing.lexeme lexbuf] returns the string matched by
           the regular expression. *)
@

<<signature [[Lexing.lexeme_char]]>>=
val lexeme_char : lexbuf -> int -> char
        (* [Lexing.lexeme_char lexbuf i] returns character number [i] in
           the matched string. *)
@

<<signature [[Lexing.lexeme_start]]>>=
val lexeme_start : lexbuf -> int
        (* [Lexing.lexeme_start lexbuf] returns the position in the
           input stream of the first character of the matched string.
           The first character of the stream has position 0. *)
@

<<signature [[Lexing.lexeme_end]]>>=
val lexeme_end : lexbuf -> int
        (* [Lexing.lexeme_end lexbuf] returns the position in the input stream
           of the character following the last character of the matched
           string. The first character of the stream has position 0. *)
@



%-------------------------------------------------------------

<<stdlib/Lexing_.mli>>=
<<copyright ocamllex>>
(* Module [Lexing]: the run-time library for lexers generated by [ocamllex] *)

(*** Lexer buffers *)

<<type [[Lexing.lexbuf]]>>

<<signature [[Lexing.from_channel]]>>
<<signature [[Lexing.from_string]]>>
<<signature [[Lexing.from_function]]>>

(*** Functions for lexer semantic actions *)

        (* The following functions can be called from the semantic actions
           of lexer definitions (the ML code enclosed in braces that
           computes the value returned by lexing functions). They give
           access to the character string matched by the regular expression
           associated with the semantic action. These functions must be
           applied to the argument [lexbuf], which, in the code generated by
           [camllex], is bound to the lexer buffer passed to the parsing
           function. *)

<<signature [[Lexing.lexeme]]>>
<<signature [[Lexing.lexeme_char]]>>
<<signature [[Lexing.lexeme_start]]>>
<<signature [[Lexing.lexeme_end]]>>

(*--*)

<<type [[Lexing.lex_tables]]>>

(* take an integer representing a state and return an integer representing
 * an action_id
 *)
external engine: lex_tables -> int -> lexbuf -> int = "lex_engine"


(* functions used by the generated scanners using the simple code generation
 *  method *)
val get_next_char : lexbuf -> char
val backtrack : lexbuf -> 'a

val start_lexing : lexbuf -> unit

@

\subsection{[[stdlib/Lexing_.ml]]}

<<function [[Lexing.lex_refill]]>>=
let lex_refill read_fun aux_buffer lexbuf =
  let read =
    read_fun aux_buffer (Bytes.length aux_buffer) in
  let n =
    if read > 0
    then read
    else (lexbuf.lex_eof_reached <- true; 0) in
  if lexbuf.lex_start_pos < n then begin
    let oldlen = lexbuf.lex_buffer_len in
    let newlen = oldlen * 2 in
    let newbuf = Bytes.create newlen in
    Bytes.unsafe_blit lexbuf.lex_buffer 0 newbuf oldlen oldlen;
    lexbuf.lex_buffer <- newbuf;
    lexbuf.lex_buffer_len <- newlen;
    lexbuf.lex_abs_pos <- lexbuf.lex_abs_pos - oldlen;
    lexbuf.lex_curr_pos <- lexbuf.lex_curr_pos + oldlen;
    lexbuf.lex_start_pos <- lexbuf.lex_start_pos + oldlen;
    lexbuf.lex_last_pos <- lexbuf.lex_last_pos + oldlen
  end;
  Bytes.unsafe_blit lexbuf.lex_buffer n
                     lexbuf.lex_buffer 0 
                     (lexbuf.lex_buffer_len - n);
  Bytes.unsafe_blit aux_buffer 0
                     lexbuf.lex_buffer (lexbuf.lex_buffer_len - n)
                     n;
  lexbuf.lex_abs_pos <- lexbuf.lex_abs_pos + n;
  lexbuf.lex_curr_pos <- lexbuf.lex_curr_pos - n;
  lexbuf.lex_start_pos <- lexbuf.lex_start_pos - n;
  lexbuf.lex_last_pos <- lexbuf.lex_last_pos - n
@

<<function [[Lexing.from_function]]>>=
let from_function f =
  { refill_buff = lex_refill f (Bytes.create 512);
    lex_buffer = Bytes.create 1024;
    lex_buffer_len = 1024;
    lex_abs_pos = - 1024;
    lex_start_pos = 1024;
    lex_curr_pos = 1024;
    lex_last_pos = 1024;
    lex_last_action = 0;
    lex_last_action_simple = dummy_action;
    lex_eof_reached = false }
@

<<function [[Lexing.from_channel]]>>=
let from_channel ic =
  from_function (fun buf n -> input ic buf 0 n)
@

<<function [[Lexing.from_string]]>>=
let from_string s =
  { refill_buff = (fun lexbuf -> lexbuf.lex_eof_reached <- true);
    lex_buffer = Bytes.of_string s;
    lex_buffer_len = String.length s;
    lex_abs_pos = 0;
    lex_start_pos = 0;
    lex_curr_pos = 0;
    lex_last_pos = 0;
    lex_last_action = 0;
    lex_last_action_simple = dummy_action;
    lex_eof_reached = true }
@
% why s ^ ""? to build a new string so safe?


<<function [[Lexing.lexeme]]>>=
let lexeme lexbuf =
  let len = lexbuf.lex_curr_pos - lexbuf.lex_start_pos in
  let s = Bytes.create len in
  Bytes.unsafe_blit lexbuf.lex_buffer lexbuf.lex_start_pos s 0 len;
  (* pad: at this point why not just use Bytes.sub above? *)
  Bytes.to_string s

@

<<function [[Lexing.lexeme_char]]>>=
let lexeme_char lexbuf i =
  Bytes.get lexbuf.lex_buffer (lexbuf.lex_start_pos + i)
@

<<function [[Lexing.lexeme_start]]>>=
let lexeme_start lexbuf =
  lexbuf.lex_abs_pos + lexbuf.lex_start_pos
@

<<function [[Lexing.lexeme_end]]>>=
let lexeme_end lexbuf =
  lexbuf.lex_abs_pos + lexbuf.lex_curr_pos
@

%-------------------------------------------------------------

<<stdlib/Lexing_.ml>>=
<<copyright ocamllex>>

(* coupling: lexbuf and lexing.c lexer_buffer must match! *)
<<type [[Lexing.lexbuf]]>>

let dummy_action x = failwith "lexing: empty token"


<<type [[Lexing.lex_tables]]>>


<<function [[Lexing.lex_refill]]>>

<<function [[Lexing.from_function]]>>

<<function [[Lexing.from_channel]]>>

<<function [[Lexing.from_string]]>>

<<function [[Lexing.lexeme]]>>

<<function [[Lexing.lexeme_char]]>>

<<function [[Lexing.lexeme_start]]>>

<<function [[Lexing.lexeme_end]]>>

(*****************************************************************************)
(* Helpers for lexers using the compact code generation method *)
(*****************************************************************************)

(*less: put lex_tables also here *)

external engine: lex_tables -> int -> lexbuf -> int = "lex_engine"


(*****************************************************************************)
(* Helpers for lexers using the simple code generation method *)
(*****************************************************************************)

let get_next_char lexbuf =
  let p = lexbuf.lex_curr_pos in
  if p < lexbuf.lex_buffer_len then begin
    let c = Bytes.unsafe_get lexbuf.lex_buffer p in
    lexbuf.lex_curr_pos <- p + 1;
    c
  end else begin
    lexbuf.refill_buff lexbuf;
    let p = lexbuf.lex_curr_pos in
    let c = Bytes.unsafe_get lexbuf.lex_buffer p in
    lexbuf.lex_curr_pos <- p + 1;
    c
  end


let start_lexing lexbuf =
  lexbuf.lex_start_pos <- lexbuf.lex_curr_pos;
  lexbuf.lex_last_action_simple <- dummy_action

let backtrack lexbuf =
  lexbuf.lex_curr_pos <- lexbuf.lex_last_pos;
  Obj.magic(lexbuf.lex_last_action_simple lexbuf)


@













\section{[[ocamlyacc/]]}

\subsection{[[yacc/ast.ml]]}


%-------------------------------------------------------------

<<yacc/ast.ml>>=
<<copyright ocamlyacc>>

(*****************************************************************************)
(* Types *)
(*****************************************************************************)

<<type [[Ast.term]](yacc)>>
<<type [[Ast.nonterm]](yacc)>>

<<type [[Ast.symbol]](yacc)>>

<<type [[Ast.charpos]](yacc)>>
<<type [[Ast.location]](yacc)>>
<<type [[Ast.action]](yacc)>>

<<type [[Ast.grammar]](yacc)>>
<<type [[Ast.rule_]](yacc)>>

<<type [[Ast.directive]](yacc)>>

<<type [[Ast.type_]](yacc)>>

<<type [[Ast.parser_definition]](yacc)>>

<<constant [[Ast.noloc]](yacc)>>

(* for the augmented grammar *)

<<constant [[Ast.start_nonterminal]](yacc)>>
<<constant [[Ast.dollar_terminal]](yacc)>>

(*****************************************************************************)
(* Helpers *)
(*****************************************************************************)

<<function [[Ast.start_symbol]](yacc)>>
@


\subsection{[[yacc/check.mli]]}


%-------------------------------------------------------------

<<yacc/check.mli>>=

<<type [[Check.error]](yacc)>>

<<exception [[Check.Error]](yacc)>>

<<signature [[Check.check]](yacc)>>
@


\subsection{[[yacc/check.ml]]}


%-------------------------------------------------------------

<<yacc/check.ml>>=
<<copyright ocamlyacc>>
open Ast

(*****************************************************************************)
(* Prelude *)
(*****************************************************************************)

(* TODO:
 * - exist 'start', and 'type' directives
 * - classic use/def: remember set of terms and non terms and look
 *   for use of undefined symbols, or unused symbols.
 * - wrong $ number, too big, $22 not handled for instance
 * - typechecking (but this is done for free by ocaml in the generated code)
 *)

(*****************************************************************************)
(* Types *)
(*****************************************************************************)

<<type [[Check.error]](yacc)>>

<<exception [[Check.Error]](yacc)>>

(*****************************************************************************)
(* Helpers *)
(*****************************************************************************)

<<function [[Check.report_error]](yacc)>>

(*****************************************************************************)
(* Main entry point *)
(*****************************************************************************)
<<function [[Check.check]](yacc)>>

@
%$


\subsection{[[yacc/lr0.mli]]}


%-------------------------------------------------------------

<<yacc/lr0.mli>>=

<<type [[Lr0.ruleidx]](yacc)>>
<<type [[Lr0.dotidx]](yacc)>>

<<type [[Lr0.stateid]](yacc)>>

<<type [[Lr0.item]](yacc)>>

<<type [[Lr0.items]](yacc)>>

<<type [[Lr0.env]](yacc)>>

<<type [[Lr0.automaton]](yacc)>>

<<signature [[Lr0.mk_env_augmented_grammar]](yacc)>>

<<signature [[Lr0.closure]](yacc)>>

<<signature [[Lr0.goto]](yacc)>>

<<signature [[Lr0.canonical_lr0_automaton]](yacc)>>

(* helper functions used also by slr.ml *)

<<signature [[Lr0.after_dot]](yacc)>>

<<signature [[Lr0.all_symbols]](yacc)>>
@


\subsection{[[yacc/lr0.ml]]}


%-------------------------------------------------------------

<<yacc/lr0.ml>>=
<<copyright ocamlyacc>>
open Ast

module Set = Set_
module Map = Map_

(*****************************************************************************)
(* Prelude *)
(*****************************************************************************)
(* Computing the LR(0) automaton for a context free grammar, using
 * the algorithm described in the dragon book in chapter 4.
 *)

(*****************************************************************************)
(* Types *)
(*****************************************************************************)

<<type [[Lr0.ruleidx]](yacc)>>
<<type [[Lr0.dotidx]](yacc)>>

<<type [[Lr0.stateid]](yacc)>>

<<type [[Lr0.item]](yacc)>>

<<type [[Lr0.items]](yacc)>>

<<type [[Lr0.env]](yacc)>>

<<type [[Lr0.automaton]](yacc)>>

(*****************************************************************************)
(* Helpers *)
(*****************************************************************************)

<<function [[Lr0.mk_env_augmented_grammar]](yacc)>>

<<function [[Lr0.rules_of]](yacc)>>

<<function [[Lr0.after_dot]](yacc)>>

<<function [[Lr0.move_dot_right]](yacc)>>

<<function [[Lr0.all_symbols]](yacc)>>


(*****************************************************************************)
(* Algorithms *)
(*****************************************************************************)

<<function [[Lr0.closure]](yacc)>>

<<function [[Lr0.goto]](yacc)>>

(*****************************************************************************)
(* Main entry point *)
(*****************************************************************************)

<<function [[Lr0.canonical_lr0_automaton]](yacc)>>
@


\subsection{[[yacc/first_follow.mli]]}


%-------------------------------------------------------------

<<yacc/first_follow.mli>>=

<<type [[First_follow.first]](yacc)>>

<<type [[First_follow.epsilon]](yacc)>>

<<signature [[First_follow.compute_first]](yacc)>>

<<type [[First_follow.follow]](yacc)>>

<<signature [[First_follow.compute_follow]](yacc)>>
@


\subsection{[[yacc/first_follow.ml]]}



%-------------------------------------------------------------

<<yacc/first_follow.ml>>=
<<copyright ocamlyacc>>
open Ast
open Lr0 (* for the augmented grammar *)

module Set = Set_
module Map = Map_

(*****************************************************************************)
(* Prelude *)
(*****************************************************************************)
(* Computing the first and follow set for a context free grammar, using
 * the algorithm described in the dragon book in chapter 4.
 * 
 * The only difference with the dragon book is that I've split their
 * FIRST into a first map and an epsilon set, so epsilon is never
 * in first.
 *)

(*****************************************************************************)
(* Types *)
(*****************************************************************************)

<<type [[First_follow.first]](yacc)>>

<<type [[First_follow.epsilon]](yacc)>>

<<type [[First_follow.follow]](yacc)>>

(*****************************************************************************)
(* Helpers *)
(*****************************************************************************)

<<function [[First_follow.first_of_sequence]](yacc)>>

<<function [[First_follow.epsilon_of_sequence]](yacc)>>

(*****************************************************************************)
(* Algorithms *)
(*****************************************************************************)

<<function [[First_follow.compute_first]](yacc)>>

<<function [[First_follow.compute_follow]](yacc)>>
@


\subsection{[[yacc/lrtables.ml]]}


%-------------------------------------------------------------

<<yacc/lrtables.ml>>=

<<type [[Lrtables.action]](yacc)>>

<<type [[Lrtables.action_table]](yacc)>>

<<type [[Lrtables.goto_table]](yacc)>>
    
<<type [[Lrtables.lr_tables]](yacc)>>

@


\subsection{[[yacc/slr.mli]]}



%-------------------------------------------------------------

<<yacc/slr.mli>>=

<<signature [[Slr.lr_tables]](yacc)>>
@


\subsection{[[yacc/slr.ml]]}



%-------------------------------------------------------------

<<yacc/slr.ml>>=
<<copyright ocamlyacc>>
open Ast
open Lr0
open Lrtables

module Set = Set_
module Map = Map_

(*****************************************************************************)
(* Prelude *)
(*****************************************************************************)
(* Computing the SLR(1) tables for a context free grammar using
 * the algorithm described in the dragon book in chapter 4.
 *)

(*****************************************************************************)
(* Helpers *)
(*****************************************************************************)

<<function [[Slr.filter_some]](yacc)>>

<<function [[Slr.map_filter]](yacc)>>


(*****************************************************************************)
(* Main entry point *)
(*****************************************************************************)

<<function [[Slr.lr_tables]](yacc)>>
@


\subsection{[[yacc/lalr.mli]]}


%-------------------------------------------------------------

<<yacc/lalr.mli>>=
@


\subsection{[[yacc/lalr.ml]]}


%-------------------------------------------------------------

<<yacc/lalr.ml>>=
@


\subsection{[[yacc/output.mli]]}


%-------------------------------------------------------------

<<yacc/output.mli>>=

<<signature [[Output.output_parser]](yacc)>>
@


\subsection{[[yacc/output.ml]]}


%-------------------------------------------------------------

<<yacc/output.ml>>=
<<copyright ocamlyacc>>
open Ast
open Lr0
open Lrtables

module Set = Set_
module Map = Map_

(*****************************************************************************)
(* Prelude *)
(*****************************************************************************)

(*****************************************************************************)
(* Helpers *)
(*****************************************************************************)

<<constant [[Output.copy_buffer]](yacc)>>

<<function [[Output.get_chunk]](yacc)>>

<<function [[Output.copy_chunk]](yacc)>>

<<function [[Output.replace_dollar_underscore]](yacc)>>

<<constant [[Output.spf]](yacc)>>

<<function [[Output.int_of_char]](yacc)>>

<<function [[Output.extract_dollars_set]](yacc)>>


(*****************************************************************************)
(* Main entry point *)
(*****************************************************************************)

<<function [[Output.output_parser]](yacc)>>

@


\subsection{[[yacc/dump.mli]]}



%-------------------------------------------------------------

<<yacc/dump.mli>>=

<<signature [[Dump.dump_item]](yacc)>>

<<signature [[Dump.dump_items]](yacc)>>

<<signature [[Dump.dump_lr0_automaton]](yacc)>>

<<signature [[Dump.dump_lrtables]](yacc)>>
@


\subsection{[[yacc/dump.ml]]}


%-------------------------------------------------------------

<<yacc/dump.ml>>=
<<copyright ocamlyacc>>
open Format

open Ast
open Lr0

module Set = Set_
module Map = Map_

(*****************************************************************************)
(* Prelude *)
(*****************************************************************************)

(* TODO: does not indent things correctly, even after an
 * open_box 2; I don't understand
 *)

(*****************************************************************************)
(* Helpers *)
(*****************************************************************************)

(* common.ml *)
<<type [[Dump.either]](yacc)>>

<<function [[Dump.partition_either]](yacc)>>

<<function [[Dump.hash_of_list]](yacc)>>



<<function [[Dump.string_of_symbol]](yacc)>>

<<constant [[Dump.pf]](yacc)>>
<<constant [[Dump.spf]](yacc)>>

<<function [[Dump.string_of_action]](yacc)>>


(*****************************************************************************)
(* Dumpers *)
(*****************************************************************************)

<<function [[Dump.dump_symbol]](yacc)>>

<<function [[Dump.dump_item]](yacc)>>

<<function [[Dump.dump_items]](yacc)>>

<<function [[Dump.dump_lr0_automaton]](yacc)>>


<<function [[Dump.dump_lrtables]](yacc)>>

@


\subsection{[[yacc/tests.ml]]}


%-------------------------------------------------------------

<<yacc/tests.ml>>=
open Ast
open Lr0

module Set = Set_
module Map = Map_

<<constant [[Tests.arith]](yacc)>>
<<function [[Tests.test_lr0]](yacc)>>
  
<<function [[Tests.test_slr]](yacc)>>


<<constant [[Tests.arith_ll]](yacc)>>

<<function [[Tests.test_first_follow]](yacc)>>

open Parsing_

<<type [[Tests.token]](yacc)>>

<<function [[Tests.test_lr_engine]](yacc)>>


@

\subsection{[[yacc/lexer.mll]]}

<<backward compatible lexing rules(yacc)>>=
(* to be backward compatible with ocamlyacc *)
and action2 = parse
| '{' 
    { incr brace_depth;
      action2 lexbuf }
| "%}" 
    { decr brace_depth;
      if !brace_depth == 0 
      then Lexing.lexeme_start lexbuf 
      else action2 lexbuf }
| "}" 
    { decr brace_depth;
      if !brace_depth == 0 
      then Lexing.lexeme_start lexbuf 
      else action2 lexbuf }
| "(*" 
    { comment_depth := 1;
      comment lexbuf;
      action2 lexbuf }

| eof { raise (Lexical_error "unterminated action") }
| _   { action2 lexbuf }

(* to be backward compatible with ocamlyacc *)
and comment2 = parse
| "*/" { () }
| ['*''/']+ { comment2 lexbuf }
| eof { raise (Lexical_error "unterminated C comment") }
| _   { comment2 lexbuf }
@


<<[[Lexer.main()]] backward compatible cases (yacc)>>=
(* to be backward compatible with ocamlyacc *)
| "%%" { main lexbuf }
| "%{" 
    { let n1 = Lexing.lexeme_end lexbuf in
      brace_depth := 1;
      let n2 = action2 lexbuf in
      TAction(Location(n1, n2)) }
| "/*" { comment2 lexbuf; main lexbuf }
@


\subsection{[[yacc/parser.mly]]}


\subsection{[[yacc/main.ml]]}


%-------------------------------------------------------------

<<yacc/main.ml>>=
<<copyright ocamlyacc>>
open Ast

(*****************************************************************************)
(* Prelude *)
(*****************************************************************************)
(* An OCaml port of yacc.
 *   
 * The original yacc is written in old C. ocamlyacc in the OCaml
 * distribution is actually also written in C.
 *
 * todo:
 *  - handle priorities, precedences
 *  - EBNF support!
 *)

(*****************************************************************************)
(* Main entry point *)
(*****************************************************************************)

<<function [[Main.main]](yacc)>>

<<toplevel [[Main._1]](yacc)>>
@


\subsection{[[stdlib/parsing_.mli]]}

<<signature [[Parsing.symbol_start]](yacc)>>=
(* Module [Parsing]: the run-time library for parsers generated by [ocamlyacc]*)

val symbol_start : unit -> int
@

<<signature [[Parsing.symbol_end]](yacc)>>=
val symbol_end : unit -> int
        (* [symbol_start] and [symbol_end] are to be called in the action part
           of a grammar rule only. They return the position of the string that
           matches the left-hand side of the rule: [symbol_start()] returns
           the position of the first character; [symbol_end()] returns the
           position of the last character, plus one. The first character
           in a file is at position 0. *)
@

<<signature [[Parsing.rhs_start]](yacc)>>=
val rhs_start: int -> int
@

<<signature [[Parsing.rhs_end]](yacc)>>=
val rhs_end: int -> int
        (* Same as [symbol_start] and [symbol_end], but return the
           position of the string matching the [n]th item on the
           right-hand side of the rule, where [n] is the integer parameter
           to [lhs_start] and [lhs_end]. [n] is 1 for the leftmost item. *)
@

<<signature [[Parsing.clear_parser]](yacc)>>=
val clear_parser : unit -> unit
        (* Empty the parser stack. Call it just after a parsing function
           has returned, to remove all pointers from the parser stack
           to structures that were built by semantic actions during parsing.
           This is optional, but lowers the memory requirements of the
           programs. *)
@


<<type [[Parsing.parse_tables]](yacc)>>=
type parse_tables =
  { actions : (parser_env -> Obj.t) array;
    transl_const : int array;
    transl_block : int array;
    lhs : string;
    len : string;
    defred : string;
    dgoto : string;
    sindex : string;
    rindex : string;
    gindex : string;
    tablesize : int;
    table : string;
    check : string;
    error_function : string -> unit }
@

<<exception [[Parsing.YYexit]](yacc)>>=
exception YYexit of Obj.t
@

<<signature [[Parsing.yyparse]](yacc)>>=
val yyparse :
      parse_tables -> int -> (Lexing.lexbuf -> 'a) -> Lexing.lexbuf -> 'b
@

<<signature [[Parsing.peek_val]](yacc)>>=
val peek_val : parser_env -> int -> 'a
@

<<signature [[Parsing.is_current_lookahead]](yacc)>>=
val is_current_lookahead : 'a -> bool
@

<<signature [[Parsing.parse_error]](yacc)>>=
val parse_error : string -> unit
@



%-------------------------------------------------------------

<<stdlib/parsing_.mli>>=
(***********************************************************************)
(*                                                                     *)
(*                           Objective Caml                            *)
(*                                                                     *)
(*            Xavier Leroy, projet Cristal, INRIA Rocquencourt         *)
(*                                                                     *)
(*  Copyright 1996 Institut National de Recherche en Informatique et   *)
(*  Automatique.  Distributed only by permission.                      *)
(*                                                                     *)
(***********************************************************************)

<<signature [[Parsing.symbol_start]](yacc)>>
<<signature [[Parsing.symbol_end]](yacc)>>
<<signature [[Parsing.rhs_start]](yacc)>>
<<signature [[Parsing.rhs_end]](yacc)>>
<<signature [[Parsing.clear_parser]](yacc)>>

<<exception [[Parsing.Parse_error]](yacc)>>

(*--*)

(* The following definitions are used by the generated parsers only.
   They are not intended to be used by user programs. *)

type parser_env

<<type [[Parsing.parse_tables]](yacc)>>

<<exception [[Parsing.YYexit]](yacc)>>

<<signature [[Parsing.yyparse]](yacc)>>
<<signature [[Parsing.peek_val]](yacc)>>
<<signature [[Parsing.is_current_lookahead]](yacc)>>
<<signature [[Parsing.parse_error]](yacc)>>



(* functions and types used by the generated parsers using the simple code
 * generation method *)

<<type [[Parsing.stateid]](yacc)>>
<<type [[Parsing.nonterm]](yacc)>>
<<type [[Parsing.rule_action]](yacc)>>
<<type [[Parsing.action]](yacc)>>

<<type [[Parsing.lr_tables]](yacc)>>

type parser_env_simple
<<type [[Parsing.rules_actions]](yacc)>>

<<signature [[Parsing.peek_val_simple]](yacc)>>


<<signature [[Parsing.yyparse_simple]](yacc)>>

@


\subsection{[[stdlib/parsing_.ml]]}

<<type [[Parsing.parser_env]](yacc)>>=
(* Internal interface to the parsing engine *)

type parser_env =
  { mutable s_stack : int array;        (* States *)
    mutable v_stack : Obj.t array;      (* Semantic attributes *)

    mutable symb_start_stack : int array; (* Start positions *)
    mutable symb_end_stack : int array;   (* End positions *)

    mutable stacksize : int;            (* Size of the stacks *)
    mutable stackbase : int;            (* Base sp for current parse *)

    mutable curr_char : int;            (* Last token read *)
    mutable lval : Obj.t;               (* Its semantic attribute *)

    mutable symb_start : int;           (* Start pos. of the current symbol*)
    mutable symb_end : int;             (* End pos. of the current symbol *)

    mutable asp : int;                  (* The stack pointer for attributes *)
    mutable rule_len : int;             (* Number of rhs items in the rule *)
    mutable rule_number : int;          (* Rule number to reduce by *)

    mutable sp : int;                   (* Saved sp for parse_engine *)
    mutable state : int;                (* Saved state for parse_engine *)
    mutable errflag : int }             (* Saved error flag for parse_engine *)
@

<<type [[Parsing.parse_tables]]([[(stdlib/parsing.ml) (yacc)]])>>=
(* coupling: parse_tables and parsing.c parse_tables must match! *)

type parse_tables =
  { actions : (parser_env -> Obj.t) array;
    transl_const : int array;
    transl_block : int array;
    lhs : string;
    len : string;
    defred : string;
    dgoto : string;
    sindex : string;
    rindex : string;
    gindex : string;
    tablesize : int;
    table : string;
    check : string;
    error_function : string -> unit }
@

<<exception [[Parsing.YYexit]]([[(stdlib/parsing.ml) (yacc)]])>>=
exception YYexit of Obj.t
@

<<exception [[Parsing.Parse_error]]([[(stdlib/parsing.ml) (yacc)]])>>=
exception Parse_error
@

<<type [[Parsing.parser_input]](yacc)>>=
type parser_input =
    Start
  | Token_read
  | Stacks_grown_1
  | Stacks_grown_2
  | Semantic_action_computed
  | Error_detected
@

<<type [[Parsing.parser_output]](yacc)>>=
type parser_output =
    Read_token
  | Raise_parse_error
  | Grow_stacks_1
  | Grow_stacks_2
  | Compute_semantic_action
  | Call_error_function
@

<<constant [[Parsing.env]](yacc)>>=
let env =
  { s_stack = Array.make 100 0;
    v_stack = Array.make 100 (Obj.repr ());
    symb_start_stack = Array.make 100 0;
    symb_end_stack = Array.make 100 0;
    stacksize = 100;
    stackbase = 0;
    curr_char = 0;
    lval = Obj.repr ();
    symb_start = 0;
    symb_end = 0;
    asp = 0;
    rule_len = 0;
    rule_number = 0;
    sp = 0;
    state = 0;
    errflag = 0 }
@

<<function [[Parsing.grow_stacks]](yacc)>>=
let grow_stacks() =
  let oldsize = env.stacksize in
  let newsize = oldsize * 2 in
  let new_s = Array.make newsize 0
  and new_v = Array.make newsize (Obj.repr ())
  and new_start = Array.make newsize 0
  and new_end = Array.make newsize 0 in
    Array.blit env.s_stack 0 new_s 0 oldsize;
    env.s_stack <- new_s;
    Array.blit env.v_stack 0 new_v 0 oldsize;
    env.v_stack <- new_v;
    Array.blit env.symb_start_stack 0 new_start 0 oldsize;
    env.symb_start_stack <- new_start;
    Array.blit env.symb_end_stack 0 new_end 0 oldsize;
    env.symb_end_stack <- new_end;
    env.stacksize <- newsize
@

<<function [[Parsing.clear_parser]](yacc)>>=
let clear_parser() =
  Array.fill env.v_stack 0 env.stacksize (Obj.repr ());
  env.lval <- Obj.repr ()
@

<<constant [[Parsing.current_lookahead_fun]](yacc)>>=
let current_lookahead_fun = ref (fun (x: Obj.t) -> false)
@

<<function [[Parsing.yyparse]](yacc)>>=
let yyparse tables start lexer lexbuf =
  let rec loop cmd arg =
    match parse_engine tables env cmd arg with
      Read_token ->
        let t = Obj.repr(lexer lexbuf) in
        env.symb_start <- lexbuf.lex_abs_pos + lexbuf.lex_start_pos;
        env.symb_end   <- lexbuf.lex_abs_pos + lexbuf.lex_curr_pos;
        loop Token_read t
    | Raise_parse_error ->
        raise Parse_error
    | Compute_semantic_action ->
        let (action, value) =
          try
            (Semantic_action_computed, tables.actions.(env.rule_number) env)
          with Parse_error ->
            (Error_detected, Obj.repr ()) in
        loop action value
    | Grow_stacks_1 ->
        grow_stacks(); loop Stacks_grown_1 (Obj.repr ())
    | Grow_stacks_2 ->
        grow_stacks(); loop Stacks_grown_2 (Obj.repr ())
    | Call_error_function ->
        tables.error_function "syntax error";
        loop Error_detected (Obj.repr ()) in
  let init_asp = env.asp
  and init_sp = env.sp
  and init_stackbase = env.stackbase
  and init_state = env.state
  and init_curr_char = env.curr_char
  and init_errflag = env.errflag in
  env.stackbase <- env.sp + 1;
  env.curr_char <- start;
  try
    loop Start (Obj.repr ())
  with exn ->
    let curr_char = env.curr_char in
    env.asp <- init_asp;
    env.sp <- init_sp;
    env.stackbase <- init_stackbase;
    env.state <- init_state;
    env.curr_char <- init_curr_char;
    env.errflag <- init_errflag;
    match exn with
      YYexit v ->
        Obj.magic v
    | _ ->
        current_lookahead_fun :=
          (fun tok ->
            if Obj.is_block tok
            then tables.transl_block.(Obj.tag tok) = curr_char
            else tables.transl_const.(Obj.magic tok) = curr_char);
        raise exn
@

<<function [[Parsing.peek_val]](yacc)>>=
let peek_val env n =
  Obj.magic env.v_stack.(env.asp - n)
@

<<function [[Parsing.symbol_start]](yacc)>>=
let symbol_start () =
  if env.rule_len > 0
  then env.symb_start_stack.(env.asp - env.rule_len + 1)
  else env.symb_end_stack.(env.asp)
@

<<function [[Parsing.symbol_end]](yacc)>>=
let symbol_end () =
  env.symb_end_stack.(env.asp)
@

<<function [[Parsing.rhs_start]](yacc)>>=
let rhs_start n =
  env.symb_start_stack.(env.asp - (env.rule_len - n))
@

<<function [[Parsing.rhs_end]](yacc)>>=
let rhs_end n =
  env.symb_end_stack.(env.asp - (env.rule_len - n))
@

<<function [[Parsing.is_current_lookahead]](yacc)>>=
let is_current_lookahead tok =
  (!current_lookahead_fun)(Obj.repr tok)
@

<<function [[Parsing.parse_error]](yacc)>>=
let parse_error (msg: string) = ()
@





%-------------------------------------------------------------

<<stdlib/parsing_.ml>>=
(***********************************************************************)
(*                                                                     *)
(*                           Objective Caml                            *)
(*                                                                     *)
(*            Xavier Leroy, projet Cristal, INRIA Rocquencourt         *)
(*                                                                     *)
(*  Copyright 1996 Institut National de Recherche en Informatique et   *)
(*  Automatique.  Distributed only by permission.                      *)
(*                                                                     *)
(***********************************************************************)

(* The parsing engine *)

open Lexing

<<type [[Parsing.parser_env]](yacc)>>

<<type [[Parsing.parse_tables]]([[(stdlib/parsing.ml) (yacc)]])>>

<<exception [[Parsing.YYexit]]([[(stdlib/parsing.ml) (yacc)]])>>
<<exception [[Parsing.Parse_error]]([[(stdlib/parsing.ml) (yacc)]])>>

<<type [[Parsing.parser_input]](yacc)>>

<<type [[Parsing.parser_output]](yacc)>>

(*
external parse_engine :
    parse_tables -> parser_env -> parser_input -> Obj.t -> parser_output
    = "parse_engine"
*)
let parse_engine a b c d =
  failwith "use yyparse_simple or Parsing module"

<<constant [[Parsing.env]](yacc)>>

<<function [[Parsing.grow_stacks]](yacc)>>

<<function [[Parsing.clear_parser]](yacc)>>

<<constant [[Parsing.current_lookahead_fun]](yacc)>>

<<function [[Parsing.yyparse]](yacc)>>

<<function [[Parsing.peek_val]](yacc)>>

<<function [[Parsing.symbol_start]](yacc)>>
<<function [[Parsing.symbol_end]](yacc)>>

<<function [[Parsing.rhs_start]](yacc)>>
<<function [[Parsing.rhs_end]](yacc)>>

<<function [[Parsing.is_current_lookahead]](yacc)>>

<<function [[Parsing.parse_error]](yacc)>>


(*****************************************************************************)
(* Helpers for parsers using the simple code generation method *)
(*****************************************************************************)

<<type [[Parsing.stateid]](yacc)>>
<<type [[Parsing.nonterm]](yacc)>>
<<type [[Parsing.rule_action]](yacc)>>

<<type [[Parsing.action]](yacc)>>

<<type [[Parsing.lr_tables]](yacc)>>

<<type [[Parsing.parser_env_simple]](yacc)>>

<<type [[Parsing.rules_actions]](yacc)>>

<<constant [[Parsing.spf]](yacc)>>

<<constant [[Parsing.debug]](yacc)>>
<<function [[Parsing.log]](yacc)>>

  

<<function [[Parsing.peek_val_simple]](yacc)>>

<<function [[Parsing.value_of_tok]](yacc)>>

<<function [[Parsing.yyparse_simple]](yacc)>>
  
@
