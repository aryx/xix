\documentclass[12pt]{report}
%alt: 12pt, twocolumn, landscape

\input{latex/Packages}
\input{latex/Config}
\input{latex/Macros}

%last:
% - microgit, in Python, with diff-style doc (=~ LP)
%   https://www.leshenko.net/p/ugit/#

%******************************************************************************
% Prelude
%******************************************************************************

%------------------------------------------------------------------------------
%history: 
%------------------------------------------------------------------------------

%thx to LP, I changed for the better a few things:
% - have a small set of cmd_xxx.ml files 
%   (dulwich has a big porcelain.py and dulwich.py files, 
%    ocaml-git has just ogit.ml,
%    git has many git-xxx.c but too many; porcelain vs plumb is useless)

%thx to this manual, I better understand VCSs (and git):
% - intuition of Torvalds for a stupid content tracker with very
%   different strategies (e.g., rename handled at query time) 
% - merge and MERGE_HEADS state?
% - beauty of design using SHA1 used for so many things (Graydon Hoare?)

%history LP-ization:
% * wanted to LPize camp (simplified clone of darcs, also in Haskell)
% * LPized finally dulwich (clone of git in Python)
% - skeleton, mostly copy paste of Template.nw skeleton
% - put all content of files in the Extra section, via 'pfff -lpize'
%   which also now split in chunks!
%    * function, global, struct, enum, constant, macro(actually function)
%    * [[xxx]] other fields, [[xxx]] extra fields
% - read Extra section, identify concepts, first TOC
% - distribute parts of the Extra section in the main file
% - understand main(), LP split main, improve TOC
% - understand main functions, LP split, cluster, improve TOC
% - LP split the structures, use datalog for flow to field info
% - nullify, boolify, errorify, enumify,  typeify,    scheckify, plan9ify
% - aspecify advanced features! remove useless features
% * port dulwich to OCaml thx to lpized version of dulwich
% * LPized my ocaml port of dulwich
% - SEMI add figures
% - SEMI add explanations

%\allcodefalse
% ifallcode is used for:
% - extra copyright 
% - file skeleton, extra signatures (stuff in Extra.nw)
% - todos in code in chunks
%\newif\iffinal
%\newif\ifverbose
%\finaltrue\verbosefalse % see also other newif in Macros.tex


\begin{document}
%******************************************************************************
% Title
%******************************************************************************
\title{
{\Huge 
Principia Softwarica: The Version Control System ([[ocaml]])[[git]]
}\\
{version 0.1}
}

\author{
Yoann Padioleau\\
\texttt{yoann.padioleau@gmail.com}\\
\\
with code from\\
Yoann Padioleau
}
\maketitle 
\l Jelmer Vernooij, Thomas Gazagnaire
\l Linus Torvalds

%\onecolumn
\hrule
\input{../docs/latex/Copyright}
%nope: \input{../docs/latex/CopyrightPlan9}
\begin{quote}
The source code is Copyright \copyright{} 2017 Yoann Padioleau.\\
Permission is granted to copy, distribute, and/or modify the source code
under the terms of the GNU Lesser General Public License version 2.1.
\end{quote}
\hrule
%\twocolumn

\begingroup
\hypersetup{linkcolor=blue}
% need to s/onecolumn/twocolumn in report.cls :) for \tableofcontents
\tableofcontents
\endgroup

%******************************************************************************
% Body
%******************************************************************************

\chapter{Introduction}

The goal of this book is to explain with full details the source code of
a {version control system}.

\section{Motivations}

Why a version control system (VCS)?
Because I think you are a better programmer if
you fully understand how things work under the hood, and
%dup: Make.nw
a VCS is one of the tools a programmer uses the most.
\n def, cos maybe not super well known term and can be confused with SCM
Indeed, programmers use VCSs, 
which manage {efficiently} changes to a file or set of files,
to manage the vital product of their labour: source code.

%src: SCCS paper
VCSs allow to {store} and {retrieve} past versions of a file, and to {record}
{who} made each change, {when}, {where}, and {why}.
\l Important cos program changes all the time! bugs/features/maintenance/opti
\l need 'system' to help 'control versions' otherwise chaos (said later?)
\l introduce checkin/checkout, delta so can talk about it in next section?
\l store/retrieve/track and coordinate work of multiple people.
%
VCSs are mostly used by programmers but
you can use a VCS to manage any text-based documents
(e.g., the source of this book), configuration files, and even binaries.
\n e.g., images, but not good IMHO to store binaries.
\l Word/Excel/Google-Docs/Wikipedia have their own VCS.

For projects with a single developer, a VCS is useful
to keep track of changes: it allows the programmer to easily go back to
past versions if he messed things up.
\l also git grep, git bisect, git revert, git blame, ... (said later?)
%
For projects with multiple developers, a VCS is almost mandatory:
it allows programmers to collaborate with each other and 
even to work on and modify the same files concurrently.
\l also git merge, git blame, ... (said later?)


%dup: Make.nw
\l not as interesting as kernel/compiler, but necessary!
\n bootstrapping issues (said later)
\l many nice algos. interesting study.
\t copy building-git.launchrock pitch?

Here are a few questions I hope this book will answer:
\begin{itemize}

%dup: Make.nw
\item What are the fundamental concepts of a VCS? 
\n repo (file db), commit (changeset), branches, version DAG
What are the core algorithms behind a VCS?
\n delta (diff), diff3 (merge), zip/unzip, sha1 (at least consistency check)

\item How does a VCS store efficiently multiple versions of a file?
\l store efficiently past versions of set of files
\n delta (diff), reversed-delta
%git: sha1 deduplicating (but not delta/diff really), compression,
% dedup of blob but also of (sub)trees, pack delta and compression

\item How does a VCS represent changes to a file, or changes 
to a set of files? 
\n changeset tree, other?
%git: does not record change but state!
How does a VCS represent the addition, deletion, or renaming of a file?
\n CVS Attic is a mess, git simple model for rename (del/add)

\item How does a VCS allow multiple users to work on and 
modify the same files at the same time?
\l pseudo-simultaneously (CVS uses this term)
How can a VCS help coordinate the actions of multiple users?
\l concurrent development
\n locks, merge

\item How does a VCS support parallel developments in a project?
How can
some developers work on the main release, 
some developers on experimental features, and 
others on fixing bugs on previously shipped releases 
all at the same time?
What is a branch?
How does a VCS reconcile multiple branches?
%What are the differences between concurrent and parallel development?
%src: 7 concurrency book:
% - concurrent program has multiple logical threads of control. These threads
%   may or may not run in parallel (can interleave)
% - parallel program runs more quickly than a sequential program by
%   executing different parts of the computation simultaneously (in //).
%   It may or may not have more than one logical thread of control.

\item What is a merge algorithm? When is a merge safe? 
What is a merge conflict? How does a VCS resolve conflicts?
\n it does not resolve conflicts! it lets user, too complicated, ok to delegate

\end{itemize}

%companies:
\t Important, companies invest in VCS: Facebook (mercurial, git), Google? (Perforce?),
\t  Microsoft (Sourcesafe, Visual Team Source Control, Git), Sun (TeamWare), 
\t  IBM (ClearCase)
\t Apple? amazon? netflix?

\t put in conclusion non-trivial adv algo and data structures seen? see comment
%data-structures (beyond list/hashtbl): (use lists, hashtbl)
% - crypto SHA1 DAG (authentificated from the root!) of commit
% - Merkel Trees (related to version DAG)
% - Huffman?
% - graph (DAG)

%algorithms (beyond search/sort): (appendix)
% - sha1
% - unzip (with huffman inside, adler32, lzh)
% - zip
% - diff
% - diff3 (aka merge)

%tags used in this file for different recurring themes:
 %git: git-specific stuff in early sections
 %rcs: %cvs: %sccs: good to see alternate design decisions
 %facebook: my facebook experience using a VCS (mostly SVN -> git -> hg)
 %ocaml: ocaml-specific trick or annoyance
 %
 %toc: %trans: %dup: ...

\section{The version control system Git (and [[ocamlgit]])}
\label{sec:vcs-git-ocamlgit}

I will explain in this book the code of the VCS 
[[ocamlgit]]\furl{https://github.com/aryx/plan9-ocaml/tree/master/version_control},
which contains about 6200 lines of code (LOC).
\n [[gut]] shortand? meh, confusing. ocamlgit and git should have same UI.
%
As its name suggests, [[ocamlgit]] is written in OCaml and is a clone
of the popular VCS
Git\furl{https://git-scm.com/}, which is written in C.

As opposed to most books in \principia, I could not choose a \plan
program for this book because there are no \plan VCSs.
\l (they rely on fs?) /n/sources/? (said later?)
%
There are many open source \unix VCSs with different user interfaces, storage
strategies, concurrency models, or features. I will present
a few of those VCSs in Section~\ref{sec:other-vcs}.
%
For this book, I decided to base the presentation on Git because
Git is one of the most popular VCSs in the open source community.
Moreover, when coupled with the hosting website 
GitHub\furl{https://github.com}, 
Git makes it really easy for people to collaborate with each other.
\n mercurial/bitbucket, CVS/sourceforge/savannah but GitHub better interface
\l Cf OCaml experiment with Github vs CVS/Mantis, no match! Easy to setup.
\n  very low barrier
\l Meta: OCaml, lang of ocamlgit, now under github itself! so can use ocamlgit
\l  to get code of ocaml :)

However, Git is a rather large project with more
than 200 000 LOC. It is impossible to present all this code
in a book of a reasonable size.
%
There are a few clones of Git written in higher-level languages than C,
for example, Dulwich\furl{https://www.dulwich.io/} written
in Python with only 16 000 LOC.
%
I could have based this book on Dulwich, but this would introduce
another language in the \principia book series in addition
to C (used in most of the books) 
and OCaml (used in the editor, web browser, and code generators books).
%
This would also in turn require to present the code of the Python interpreter,
which contains more than 170 000 lines of C code.
\n and far more of Python code (not counting test and third-party C libs)
%
Instead, I decided to port the Python code of Dulwich to OCaml, resulting
in [[ocamlgit]], and to present the code of [[ocamlgit]].
\n other ocaml clones ocaml-git (said later)
\n in fact I LPized first full code of dulwich, which helped understanding it

%https://sqlite.org/whynotgit.html

\section{Other version control systems}
\label{sec:other-vcs}
%me: manual backups -> RCS -> CVS -> PRCS -> git -> darcs -> 
% (FB-in) SVN -> git -> hg -> (FB-out) git

Here are a few VCSs that I considered for this book, but
which I ultimately discarded:
\begin{itemize}

\item The Revision Control System
(RCS)~\cite{rcs}\furl{https://www.gnu.org/software/rcs/}
was the first open source VCS.
%history:
Like its predecessor, the Source Code Control System
(SCCS)~\cite{sccs}\furl{http://sccs.sourceforge.net/},
\n RCS closed in 1982, free in 1990? (SCCS closed in 1976, free only in 2006)
\n CSSC alternative OSS version of SCCS
RCS uses {\em deltas} to store efficiently the past versions of a file
(Section~\ref{sec:diff-algo} will present the {Diff} algorithm to compute
those deltas).
However, RCS improves over SCCS by using {\em reverse-deltas} to 
enable the user to also retrieve quickly the last version of a file
(a recurring operation).
\l but blaming is faster with SCCS

RCS is still a reasonable choice to manage a small project
with a single developer or a small set of developers who can 
share access to a common directory 
(for example, by using NFS and symbolic links).
%
However, the use of {\em locks} in RCS to forbid multiple developers
to modify the same file at the same time and its focus on individual files make
% Mostly single file. treat files separately. Each has different version. 
%  can be used for multiple files, but abuse shell (wildcard on ,v)
%  but not really good for projects with subdirs.
RCS inadequate for large projects with many independent developers.
%
Moreover, even if RCS is very limited compared to modern VCSs like Git,
RCS still contains more than 17 500 LOC.
\n (not including testsuite, but small anyway)
\l Why? too subtle diff representation?
\n has kinda branch, and rcsmerge, and tags, but hacks
\l SRC wrapper from ESR? 


\item The Concurrent Versions System
CVS~\cite{cvs}\furl{http://www.nongnu.org/cvs/}
was the most popular VCS for over a decade
before distributed VCSs (e.g., Git) took over.
%
CVS introduced a few important innovations.
\n STUG award 2003
First, CVS was designed to operate on a set of files 
at once\footnote{RCS can operate on multiple files by using shell 
wildcards, but it was not designed for it.}, 
with files possibly organized in a tree.
\n RCS cannot do that.
With CVS, you can group together related changes to a set of files 
and you can easily retrieve past versions of a whole {project}.
\l not atomic commit though, SVN fixed that (said later?)
\n can with RCS, with tags, or date, but again not really designed for
%
Secondly, CVS allows multiple users to work on and modify the same
files concurrently (hence the 'C' in CVS).
CVS relies on the [[merge]] program instead of locks
(Section~\ref{sec:diff3-algo} will present the Diff3 algorithm which
underlies the [[merge]] program).
\l who commit first always succeeds and snd needs update and merge (said later)
%
Finally, CVS introduced later in 1995 a {\em client/server} architecture 
where a {\em repository} could be stored on a remote machine.
\t should find a way to define repo before, and so no need em here
\n TCP/IP really made took off, but was done later, not in 1986.
When coupled with the free hosting site
Sourceforge\furl{https://sourceforge.net}, 
CVS allowed developers to easily start and collaborate on new projects.
\l but branch and parallel development is really tedious (said later?)

CVS started as a few shell scripts using RCS as a backend.
\n so did not need free version of RCS?
\n rewritten in C in 1990
However, today CVS is a very large C program with more than
80 000 LOC.
\l cvs 1.3 is only 17 000 LOC
\n not third-party libs (diff/zlib/lib/os2/NT/vms) and sanity.sh
The backend file [[src/rcs.s]] contains already 9000 LOC.
\l reputed difficult to understand, hence SVN

\n I presented a bit git before so needs less intro
\item Git~\cite{git-book}\furl{https://git-scm.com} was originally created
by Linus Torvalds in 2005 to manage the source code of the Linux kernel.
It followed a series of
{\em distributed VCSs} 
(e.g., TeamWare, BitKeeper, Arch, Darcs, Monotone) 
designed to overcome the main limitations of CVS (a {centralized VCS}).
%
Because a distributed VCS (DVCS) does not require access to a
central repository, it allows developers to work independently offline.
%
A DVCS makes it also easy and cheap to create {\em branches}
representing parallel developments, and to reconcile later those branches
(see Section~\ref{sec:distributed-vs-centralized} for more discussions
on the advantages of distributed VCSs over centralized VCSs).
\l has to, because everybody is a branch (said later?)
\l also atomic, consistency checks! fast! done the right way!
\l peer-to-peer (said later?)

As I explained in Section~\ref{sec:vcs-git-ocamlgit}, Git
is a large program with more than 200~000 LOC spread over more than 400 files
(not including the tests, GUIs, and extra contributions).
%
The first version of Git was small and contained only 1000 LOC\footnote{
\url{https://github.com/git/git/commit/e83c5163316f89bfbde7d9ab23ca2e25604af290}}.
However, it contained only a few low-level commands that were not easy to use.
This forced programmers to develop and use the extra program 
[[cogito]]\furl{http://git.or.cz/cogito/}, which
provided an extra layer of higher-level commands (called {\em porcelain}),
but added many more lines of code.
\t count? Now integrated in Git but Git also bigger
\l also libgit2, LOC? share code with git?

% related book:
% - https://building-git.launchrock.com/ 
%   https://shop.jcoglan.com/building-git/contents.pdf

\item Mercurial~\cite{hgbook}\furl{https://www.mercurial-scm.org/}
is another popular DVCS started also in 2005 by another 
Linux kernel programmer: Matt Mackal.
\l after BitKeeper fiasco
It is mostly written in Python and relies only on a few C files for critical
operations. Its code is arguably easier to understand than Git
but it still contains more than 100~000 LOC spread over more than 170 files
(not including the tests, extensions, and extra contributions).
\l core of 1.0 is? maybe not that bad
\l bitbucket equivalent of github

\end{itemize}

% In the end I picked a mix between git and mercurial: git, but
% implemented in the language used for mercurial (Python)
% by the guy who apparently has been involved in bazaar :)

%Figure~\ref{fig:timeline-vcs} presents a timeline and summary
%of the major innovations in the development of VCSs.
%\begin{figure}[!]\centering
%\begin{verbatim}
%1975  | VCS idea, repository, delta, locks
%      | (SCCS)
%      |
%      |
%1985  | Concurrent (lockless), project-centered
%      | (CVS)
%      |
%      |
%1995  | networking, collaboration through Internet
%      | (CVS)
%      |
%      |
%2005  | Distributed
%      | (TeamWare, BitKeeper, Git, Mercurial, ...)
%      |
%      |
%      v
%\end{verbatim}
%\caption{Version control systems timeline.}\label{fig:timeline-vcs}
%\end{figure}
\n algos: Diff, Diff3, Zip, Sha1
\t actually first distributed Sun Workshop Teamware; wikipedia says '1990?'
\t  and Bitkeeper was 2000
\l and in 2015?
%      |
%2015  | ???
%      |


\begin{figure}[]\centering
\includegraphics[height=0.45\textheight]{lineage}
\caption{Version control systems timeline}
\label{fig:lineage}
\end{figure}


%dup: Shell.nw
Figure~\ref{fig:lineage} presents a timeline of major VCSs.
%
[[ocamlgit]] is not as efficient and complete as Git or Mercurial, 
but it provides almost all of the essential features of those programs
%dup: intro/ocamlgit
with more than an order of magnitude less code (6500 LOC).
\l could bench ocamlgit vs git? also percentage commands covered in Cheat sheet?
\l not as efficient as git, not as famous as Torvalds for coding style,
\l  but not too bad (bench?) and easier entry point to then look code of git.

%last:
% - microgit in python: https://www.leshenko.net/p/ugit/
%   why not dulwich??

%industry:
% - Perforce
% - Rational Clearcase (and DSEE before)
% - Microsoft Visual Sourcesafe
% - Sun TeamWare (distributed VCS on top of SCCS), atomic updates
% - BitKeeper (main inspiration for git), followed TeamWare
%history:
% - SCCS http://sccs.sourceforge.net
%   and modern version CSSC https://www.gnu.org/software/cssc/
%other:
% - Subversion (630 000 LOC, hmm)
% - PRCS http://prcs.sourceforge.net/ P for project, better than RCS and
%   CVS for grouping. Kinda snapshot based
%other DVCSs:
% - Darcs 80 000 LOC (using literate haskell), maybe good candidate, simpler
%   model, arguably simpler than git (rebase for free?), some patch theory.
%   But code looks actually awful. Lots of boilerplate. Huge types.
% - GNU Arch (aka tla 273 000 LOC) described as very complicated by many
%   but seems like one of the first DVCS
% - Bazaar (477 000 LOC) and bazaar-NG in Python
%   https://www.jelmer.uk/pages/bzr-a-retrospective.html
% - Monotone (99 000 LOC for 1.1), apparently good source of inspiration
%   for Git because introduced the DAG of SHA1; focused a lot on security
%   13 000 LOC for 0.4
% - Codeville, by Bram Cohen of Bittorrent fame
% - Pijul, initially in OCaml (3000 LOC), then in Rust, but seems to have 
%   a slow development
% - Fossil??
%git alternate porcelain:
% - Gitless, a better design for git, great paper:
%   http://people.csail.mit.edu/sperezde/pre-print-oopsla16.pdf
%   (can implement this design with dulwich?)
%mini:
% - Camp is a simplified version at 6300 LOC
%   a mini Darcs. Simple? Elegant? Arguably more powerful. < 10 000 LOC.
%   Can be good opportunity also to read some haskell code. Maybe can then
%   port the code to OCaml.
% - http://benhoyt.com/writings/pygit/ 500 LOC to push to github,
%   with init/add/commit/push/status/diff/, very nice, but simplified
%   so only support toplevel files, no subdirs (so no subtree).
% - http://gitlet.maryrosecook.com/ mini git in Javascript, heavily
%   commented (but LP would be better)
% - gg 7000 LOC, but no locking, no push, and requires external diff.
%   http://www-cs-students.stanford.edu/~blynn/gg/
%   this guy also wrote a book on Git "Git Magic"
% - SRC, by raymond, wrapper around RCS
%   http://www.catb.org/esr/src/
% - Cmt, git inspired, in OCaml, cornell student project
%   https://github.com/loganallen/CmlControl
%clones in other languages (all clones of git actually):
% - dulwich: git written in python (15000 LOC (without tests))
%   which includes some porcelain now (there is also another project
%   called gittle which is porcelain for dulwich).
%   Used by Google for some projects to provide bridge between
%   mercurial and git.
%   Originally created to offer bridge between bazaar and git by one
%   of bazaar maintainer. Based on python-git hack by James Westby.
% - git-go: git written in Go (but seems limited to archeology command)
% - JGit: git in Java
% - Git in Javascript
%   https://github.com/creationix/js-git
% - Another git in Javascript
%   https://github.com/isomorphic-git/isomorphic-git
% - libgit(2): git in C, but reuse git code or new implem?
% - gat: git clone in haskell http://evan-tech.livejournal.com/254793.html
%   another one:
%   http://stefan.saasen.me/articles/git-clone-in-haskell-from-the-bottom-up/
%   pretty complete, nice figures, quite long
% - another haskell lib
%   http://vaibhavsagar.com/blog/2017/08/13/i-haskell-a-git/
% - ocaml-git: 15 000 LOC, but  heavily functorized (to support unix 
%   but also mirage), many dependencies (mstructs, cstruct, topkg, logs)
%   and seems to be only an API to access data. No support
%   for diffs; no merge; limited porcelain.
% - Git in Ruby?
%   https://www.thestrangeloop.com/2017/re-writing-history.html

%https://en.wikipedia.org/wiki/List_of_revision_control_software
%http://www.catb.org/esr/writings/version-control/version-control.html
%http://better-scm.shlomifish.org/comparison/comparison.html

%future:
% - my semantic-vcs proposal!
%   related: https://www.semanticmerge.com/
% - gitless design  http://people.csail.mit.edu/sperezde/pre-print-oopsla16.pdf
%   that uses pygit2 (a binding to libgit2)
% - CRDTs? inspired by merge in VCS?
% - use git model for more things, like in mirage and irmin?



\section{Getting started}
\label{sec:getting-started}

To play with [[ocamlgit]], you will first need to install it
by following the instructions at~\urlinstallbis\footnote{
%bootstrap: 
As you follow the document in the Wiki, you will see that
you will need a VCS program ([[git]]) to get the source of another 
VCS program ([[ocamlgit]]).
This is similar to bootstrapping issues in compilers.
However, for VCSs an easy way to avoid those issues is to provide
instead an archive file of the source (e.g., [[ocamlgit-0.1.tar.gz]]).
\n and extra patches 
\l but then need wget or browser and network stack 
}.
Once installed, you can test [[ocamlgit]] under \plan or \unix with
the following commands:

\begin{verbatim}
1 $ cd /tests/
2 $ mkdir hello
3 $ cd hello/
4 $ ocamlgit init
5 Initialized empty Git repository in /tests/hello/.git/
6 $ echo "Hello Git" > hello.txt
7 $ ocamlgit add hello.txt
8 $ ocamlgit commit -m "first commit" --author "pad <todo@todo>"
...
\end{verbatim}
\t implement --author
\n alternative is to have config file, but need explain that
\n no need --comitter here
\l more? 2nd modif with 2nd commit and then go back?
\l  but then need explain checkout, HEAD^, too complex? or use git revert?
\l  but it's a commit, because distributed, so complex again.

The command in Line~4 {initializes} a new {\em repository} by
creating the appropriate {metadata} in the [[/tests/hello/.git/]]
subdirectory.
%
Line~7 then {adds} the new file [[hello.txt]] to the {\em staging area} of Git
(I will explain later in Section~\ref{sec:staging-area} what is 
a staging area).
\l same than index? no index is internal DS for managing stage area
Finally, Line~8 {\em commits} what was staged to the repository and {records}
this commit with the {message} ``first commit'' and the
author ``pad''\footnote{This is my nickname}.
\l and author and date?

\label{sec:git-abbrev}
In the rest of this document, I will often abbreviate 
the command [['ocamlgit']] by using instead the command [['git']].
You can even define [['git']] as an alias for [['ocamlgit']] in your shell.
Indeed, [[ocamlgit]] uses the same command-line interface
than the program [[git]]. 
Almost all [[ocamlgit]] commands are valid [[git]] commands\footnote{
The reverse is not true. [[ocamlgit]] implements only a subset of the
commands supported by [[git]].}.
When the interfaces differ, I will explicitely use [['ocamlgit']].



\section{Requirements}

Because most of this book is made of OCaml source code, 
you will need to know the 
OCaml programming language~\cite{ocaml-ref-manual} to understand it.
%
The code of [[ocamlgit]] uses only the core language of OCaml, and none
of its advanced features 
(e.g., functors, objects, labels, polymorphic variants, GADTs),
thus a knowledge of 
Caml~\cite{caml-leroy}, 
Standard ML~\cite{ml-working-programmer}, or 
any of the dialect of ML (e.g., F\#~\cite{fsharp-book}) 
should be enough to understand this book.


You do not need to know Git, or more generally any VCSs,
to understand this book.
%
However, if while reading this book you have specific questions
on the interface of Git, I suggest you to consult the man
pages of Git\furl{https://git-scm.com/docs}, 
or any of the books on Git (e.g., \cite{git-book}).


\section{About this document}
% include "../docs/latex/About.nw"
\input{../docs/latex/About}

\section{Copyright}

I wrote most of the code in this document. 

<<copyright ocamlgit>>=
(* Copyright 2017 Yoann Padioleau, see copyright.txt *)
@

The code is licensed under the 
GNU Lesser General Public License version 2.1
as published by the Free Software Foundation.

%dup: intro/ocamlgit
As I said in Section~\ref{sec:vcs-git-ocamlgit},
most of the code of [[ocamlgit]] is a port in OCaml of Python code from
Dulwich, which is governed by the following copyright:

<<dulwich license>>=
# Dulwich is dual-licensed under the Apache License, Version 2.0 and the GNU
# General Public License as public by the Free Software Foundation; version 2.0
# or (at your option) any later version. You can redistribute it and/or
# modify it under the terms of either of these two licenses.
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# You should have received a copy of the licenses; if not, see
# <http://www.gnu.org/licenses/> for a copy of the GNU General Public License
# and <http://www.apache.org/licenses/LICENSE-2.0> for a copy of the Apache
# License, Version 2.0.
@

I also sometimes took inspiration from code written by Thomas Gazagnaire 
for [[ocaml-git]]\furl{https://github.com/mirage/ocaml-git}
(another clone of Git in OCaml but intented to be used
as a library in the MirageOS ecosystem\furl{https://mirage.io/}).
\l explain more later?

<<copyright ocaml-git>>=
(*
 * Copyright (c) 2013-2017 Thomas Gazagnaire <thomas@gazagnaire.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 *)
@

\ifallcode
% Also use code from a few OCaml libraries.

<<copyright ocaml-diff-myers>>=
(*
 * Copyright (C) 2016 OOHASHI Daichi
 *
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
 * THE SOFTWARE.
 *)
@

<<copyright ocaml-hex>>=
(*
 * Copyright (c) 2015 Trevor Summers Smith <trevorsummerssmith@gmail.com>
 * Copyright (c) 2014 Thomas Gazagnaire <thomas@gazagnaire.org>
 *
 * Permission to use, copy, modify, and distribute this software for any
 * purpose with or without fee is hereby granted, provided that the above
 * copyright notice and this permission notice appear in all copies.
 *
 * THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
 * WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
 * MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
 * ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
 * WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
 * ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
 * OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 *)
@

<<copyright uuidm>>=
(*
Copyright (c) 2008 Daniel C. BÃ¼nzli

Permission to use, copy, modify, and/or distribute this software for any
purpose with or without fee is hereby granted, provided that the above
copyright notice and this permission notice appear in all copies.

THE SOFTWARE IS PROVIDED "AS IS" AND THE AUTHOR DISCLAIMS ALL WARRANTIES
WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR
ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF
OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
*)
@

<<copyright ocaml-unzip>>=
(*
 * Unzip - inflate format decompression algorithm
 * Copyright (C) 2004 Nicolas Cannasse
 * Compliant with RFC 1950 and 1951
 *
 * This library is free software; you can redistribute it and/or
 * modify it under the terms of the GNU Lesser General Public
 * License as published by the Free Software Foundation; either
 * version 2.1 of the License, or (at your option) any later version,
 * with the special exception on linking described in file LICENSE.
 *
 * This library is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
 * Lesser General Public License for more details.
 *
 * You should have received a copy of the GNU Lesser General Public
 * License along with this library; if not, write to the Free Software
 * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
 *)
@

<<copyright camlzip>>=
(***********************************************************************)
(*                                                                     *)
(*                         The CamlZip library                         *)
(*                                                                     *)
(*            Xavier Leroy, projet Cristal, INRIA Rocquencourt         *)
(*                                                                     *)
(*  Copyright 2001 Institut National de Recherche en Informatique et   *)
(*  en Automatique.  All rights reserved.  This file is distributed    *)
(*  under the terms of the GNU Lesser General Public License, with     *)
(*  the special exception on linking described in file LICENSE.        *)
(*                                                                     *)
(***********************************************************************)
@
\fi

The prose and figures are mine and are licensed under the \license.

\section{Acknowledgments}

I would like to acknowledge first the author of Dulwich,
Jelmer Vernooij, who wrote in some sense most of this book.
%dup: intro/ocamlgit intro/copyright
Indeed, I used mainly the code of Dulwich to write the code of [[ocamlgit]]. 
Dulwich provided an easier path towards understanding
the concepts and implementation of Git.
\l Also Thomas gazanaire.


I would like also to thank Linus Torvalds, the original author of Git,
for designing this simple but powerful VCS.
%
Many of his design decisions seem obvious
in retrospect but they are not: most VCSs chose different designs
(for the storage, 
file permissions, 
for the way to handle renames,
etc.)
\l snapshot-based > changeset?, SHA1 DAG (but Monotone), GMT time, etc.
which in the end are more complicated
and usually less efficient than in Git.
\l ocamlgit only 6400 LOC (C bigger but original C 1000 LOC), far more powerful 
\l than RCS 30 000, in big part due to simple but clever design of Git





\chapter{Overview}

%trans: %dup: Assembler.nw
Before showing the source code of [[ocamlgit]] in the following chapters, 
%toc: %dup: Assembler.nw
I first give an overview in this chapter of the general principles of a VCS.
I also quickly describe the command-line interface of [[ocamlgit]],
\l (and so of [[git]] too),
the format of a Git repository, and I use a simple terminal session containing
[[ocamlgit]] commands to illustrate its major features.
%dup: Assembler.nw
Finally, I define terms, explain how the code is organized, 
and more generally give the background necessary
to understand the code I will show later.

\section{Version control system principles}
\l principles? requirements? features?

% nice docs:
% - ten innovations in the history of vcs:
%    http://www.flourish.org/2011/12/astonishments-ten-in-the-history-of-version-control/
% - https://betterexplained.com/articles/a-visual-guide-to-version-control/
% - Misfits paper, great summary of essential purposes.
% - git from the bottom up intro with nice glossary
% - Mercurial chapter in AOSA book (ok)
% - Git chapter in AOSA book (meh)
% - dulwich/docs/ (very limited)

\t different UI, different command name, but superficial differences,
\t  share many principles/features

%manual backups, tarballs, email back and forth patches?
% (\footnote{how Linux done for a long time}, human VCS) :) )
% no git blame. discipline.
%src: SCCS paper
% Code changes all the time. Bugs, experimentatl features, optims.
%  not just current version but last year's (still supported) and next year!
%  maintenance old code. Chaos if no tool, if no discipline.

\l VCS vs SCM?


%toc:
The main requirements for a modern VCS are to be able to
store past versions of a set of files,
\l and retrieve, and actually set of files
to track the changes to those files, 
and to help multiple developers to collaborate with each other 
on those files by supporting
concurrent and parallel development (I will explain soon the differences
between those two kinds of development).
%
The next sections will each give more details about those requirements.
I will also try to present the major techniques used by popular VCSs 
to satisfy those requirements. 
%
Finally, I will discuss two different architectures for VCSs: 
centralized and distributed.

% try be general and add %git: for git instantiation of general principles
\subsection{Storing past versions}

The first requirement of a VCS is to store past versions of a file,
hence the 'V' in VCS. However, there is also an 'S' in VCS, which means
it must be done in a systematic way. 
\l and with user in 'C'ontrol, or in a Controlled way
\t meh
%without:
Indeed, one way to understand the usefulness of a VCS
is to see how people are struggling when they are managing
documents that evolves (e.g., source code, LaTeX files, notes) without
a VCS.
%
In that situation, people often uses [[cp]] to {\em backup} files, but it is
inefficient space-wise and error-prone. 
\l but backup where?
%It is easy to forget to backup.
\l but with VCS you have to remember too to commit



%trans:
% first purpose of VCS is store (and also retrieve) past versions.

% Some fs can do that. in fact plan9 used that! \cite? VMS had versioned FS?
% But dedicated FS. VCS is regular tool, no need special kernel.

% Time filesystem could do that, e.g. cd /2016/01/01/project/.
% Can even be encoded efficiently (deltas backup system, deduplication).
% But need special fs. And VCS provides additional nice services
% like commit message, and git blame!! who, when, why, where!
% (but could have a history.txt file in the project,
% and also symlinks to tag version at specific time).

\subsubsection{The repository}
%\subsubsection{Metadata}

% RCS/, CVS/CVSRoot in each dir, .git/ toplevel (hidden by default with ls)

% Actually def of repo? just .git/? or .git/ + working files?
% so kinda of topdir?
% Can mean whole thing or just metadata depending on context. Fuzzy.

% No fs, no hidden meta-data, 
% so need use filesystem as a db.

% file version database
% metadata (RCS/,v, .git/objects/, CVS/CVSRoot and other dir or server, etc.)
% metadata and data in fact. past versions are really data.

% First, store past versions. Can go back in time if made a mistake.
% Could get that with copy, but need discipline, filename encoding
%  better organized, and storing deltas has efficiency implications. 
%update: actually git does not really use delta. really more a content tracker.
%update: actually can use delta, but for packfile.

% Different storage strategy.
% Some use per-file history [[,v]], flat dirs (.git/objects/), 
% Berkely DB (SVN), Sqlite (monotone), changesets (?)

\subsubsection{Working copy}
% you work on copy from repo (hence name)

% working tree

% checkout, checkin

% So can use any editor to edit!
% (departure from Word/Excel where versions and editing are using same tool)

%rcs: checkout

\subsubsection{Delta}

\subsubsection{Compression}

\subsection{Tracking changes}

%trans: %dup: intro/motivations
% second is track changes. when, where, who, why each change.

% fs could do. But which granularity? let user records
% relevant change points!

%without:
% Changelog file in many programs

\subsubsection{The commit}

%dup: intro/motivations
% who, when, what/where, and why.

% attach note to changeset.
% incredibly useful for git blame! can help find bugs, see related
% code because related changes!

% record who made change, what change, and even why! great resource.
% git blame!

%rcs: checkin

% then commit information.
%git: again use object for that. then easy to reference
% a tree version by referencing a commit id.
% Also then can have references, symbolic references.
% Also have parents! so full history on how you got there.


\subsubsection{Version identifier}

% version, revision.

% need have different versions, different version id.
%git: use simple scheme: not v1, v2, ... but sha1 of content!
% then get for free consistency checking

% release.level
% so one way to organize set of files and have changeset by having
% all developers increment release (but then need modify every file? RCS
% does not accept empty updates)

%sccs: introduced extra lettre for different customer, so 1.2.p

% 1.1, 1.2,
%git:
%  or sha1! identified by its content! file content! but can
%  also scale to set of files! or tree! or commit!
%  has some advantages.
%Also in distributed settings, how can have global identifier?
% each user need tags its version number with its name?
% another thing where sha1 is good, they are stable across machines,
% they are global!

\subsubsection{Change granularity}

% set of logical changes as an individual group (atomic).

%cvs: not atomic?

% then need to have not just version of one file (RCS) but version
% of a tree.
%git: have tree structure which references other blob id and other trees.
% if a full subtree does not change, then share reference.

% single-file history, or whole-tree history.

% - release/level discipline, so update release for all files at certain
%   point
% - use date
% - use tag

% or simply use commit id in modern VCSs :)


\subsubsection{[[diff]]}

% cite paper

% Source code is text!

% sometimes people use commit and diff and patch interchangebly.

% diff can be used especially internally in VCS to efficiently store deltas.
%git: used in pack only
% It got used after as a way to display changes? (and later for coccinelle!)

% Also by having delta
% and message associated with it help explore history. Git log, git
% blame are fantastic tool, even in single-user mode. To know
% code related to a line, the message of this patch, etc.
% Also in multi-user mode good to know the author, test plan, test
% files, coupled code, etc.
% I used it a lot to understand code at Facebook.

% Usually diff at granularity line-level. So add/delete a line are 
% the primitives
% (since SCCS). Fine granularity for source code.
% Could use char, but too big then.


\subsubsection{[[patch]]}

% diff -u, unified format.

%dual of diff. One create diff on his machine, other can apply patch on his.
% (also some fuzzy apply algorithm).

% first years of Linux was managed just with patches.
% tarballs and patches. linux-mm still use patches (quilt).

% In fact git has some commands to deal with paches contained in email
% or to generate such patches.

\subsection{Concurrent development}

%trans:
% Other role of VCS is help coordinate work of multiple developers.

% When multiple developers, may modify same file, dont want one
% to overwrite change of other. Need control access to shared
% resource, the source file.
% How?

% Then when work in groups, useful to have way to work concurrently,
% to not pass his copy and wait for the "token". Concurrent
% techniques are lock, or better optimistic and later merge.

%\subsubsection{Shared space}
%if collaborate, need shared space (hmm with DVCS no, except central repo
% sometimes)

\subsubsection{Locks}

% Simple.

% NFS symlinks

% but easy to forget to unlock, and really annoying for other.
% RCS.

% Locks make sense only with centralized model.

\subsubsection{Merging}
% optimistic merging?

% surprisingly, it works!
% CVS.
% Pseudo-simultaneously

% 3 way merge.
% cite paper?

% but need update first. 
%facebook: What if time update and time commit long
% so always another guy in the middle.

% Actually CVS did not have atomic commit of multiple files at the
% same time. Files were still treated separately.

\subsubsection{Merge conflicts}

% show conflict with <<<< === >>>>

\subsection{Parallel development}

%trans:
% Finally, can help organize development.

% like concurrent, but longer time-scale. Does not expect to merge
% immediately.

\subsubsection{Branch}

% Branches are also very useful. Work on different tasks, different
% branches. Can juggle between those.

% - temp fixes (never merged)
% - parallel devel for experimental feature (may be merged)
% - real fork (may be merged)

% RCS had branches, but per-file! tedious.
% CVS got it, but complicated, because was relying on RCS.
% git far easier! because every different repo/user is a branch! because
%  distributed, so had to get merge right and fast!

% so line, then tree, then DAG.

% Saw merge before, but merge really make sense with branching.
% Useful to branch and merge. 
% Also useful for branch and merge on a peer-to-peer basis
% (networking)

\subsubsection{Merging}

% Same, but usually bigger, and can get complicated?

% Real VCS needs cheap branches and good (heuristics) merging.

%\subsection{Revision graph}
% RCS was a tree, but then when introduce real branches get merges and a DAG!
% head, tip, branch, fork, merge, root, trunk, ... lots of graph words.
%\subsubsection{A mainline} 
%\subsubsection{A tree of branches} 
%\subsubsection{A direct-acyclic graph of merges} 
\subsubsection{A direct acyclic graph of versions}
%Again, ... as in Make.nw.


% really important. linear versions, then tree, then DAG!
% Lots of terminology about graph (HEAD, tip, ...)

% Previous VCS did not record relation between changeset (which
% requires identify changeset), and so merge could also not work good?




%\subsection{Variants}
\subsection{Centralized versus distributed}
\label{sec:distributed-vs-centralized}
% pulling and pushing

% but in both cases pull and push.

% github kinda centralize, but still independent repo! can work offline

% decentralized so no need access permission! Can fork, work,
% commit locally, and then ask for master to merge you.

% What brings distributed then? More convenient than centralized.
% Less imposing. Nice to have everything locally. Just more general.
% Can do centralized with distributed (e.g. "main" repo on github
% is the main thing to pull from).

% When distributed, not centralized, so no need path to shared repo
% or CVSROOT and so no need concepts such as module as in CVS.
% (actually there is concept of submodule and gitlink)
% Have different projects? Use different repo! Simple.

%\subsection{Snapshot versus changeset}
% on changesets vs snapshot-based VCS
%https://web.archive.org/web/20100327150715/sourcefrog.net/weblog/software/vc/derivatives.html
% snapshot fast to go back to previous version. No delta application.
% Just copy blob!
% But blame slower with snapshot. Need explore all history.

%\subsection{Hosting}
%\subsection{Github}
% sourceforge before.
% Finally github is fantastic. Easy to setup and start sharing work.

% Before pain create repo to collaborate. Need server, start and config
% CVS server there, password, etc. Now just create on github and clone!

%\subsection{Git}
% many more concepts: index/HEAD/master/remote/sha1 but git specific



\section{[[git]] command-line interface}

%trans: %dup: Windows.nw
I just described the general principles of a VCS, 
and illustrated some of those principles with examples from RCS, CVS, or Git.
I will now focus exclusively on Git and give more details about
the interface of its command-line program: [[git]].
%dup: intro/getting-started
As I mentioned in Section~\ref{sec:git-abbrev}, the
command-line interface of [[ocamlgit]] is almost identical
to the one of the program [[git]]. This is why I will often use
[[git]] as an alias for [[ocamlgit]] in the rest of this document.

The command-line interface of [[git]] (and [[ocamlgit]]) is pretty simple:
%dup: (but use git not ocamlgit this time) intro/getting-started
\begin{verbatim}
1 $ git
2 usage: git <init|add|rm|commit|branch|checkout|reset|...> [options]
3 $ git init
4 Initialized empty Git repository in /tests/hello/.git/
5 $ git add hello.txt
6 $ git commit -m "first commit" --author "pad <todo@todo>"
\end{verbatim}
% git <cmd> [-options] <extra arguments>

[[git]] takes first a {\em command} as its first argument and then
options and extra arguments specific to this command.
\l git uses also some common options for all its commands (but not ocamlgit)
%
For example, the command 
[[init]] at Line~3 does not need any extra arguments, but
[[add]] at Line~5 requires at least the name of a file or directory, and 
[[commit]] at Line~6 usually requires command-line flags.
%chunks:
I will gradually describe the different [[git]] commands, their
options, and implementations in the following chapters.
%alt:
\l vcs <cmd> simpler than having 10 command-line /bin programs (started by CVS?)


\section{Git concepts and data structures}
\label{sec:git-concepts-and-ds}

%git docs:
% - https://www.kernel.org/pub/software/scm/git/docs/user-manual.html#birdview-on-the-source-code
% - https://git-scm.com/book/en/v2/Git-Internals-Plumbing-and-Porcelain
% - git v0:
%   https://github.com/git/git/commit/e83c5163316f89bfbde7d9ab23ca2e25604af290
% - git from the bottom up (great, I read it while at FB)
% - https://building-git.launchrock.com/ 
%   learn git by building your own, an expansion of a blog on git
% - https://codewords.recurse.com/issues/two/git-from-the-inside-out
% - http://eagain.net/articles/git-for-computer-scientists/
% - https://stevebennett.me/2012/02/24/10-things-i-hate-about-git/
% - Bram cohen vs torvalds on deep algo in git:
%   http://www.wincent.com/a/about/wincent/weblog/archives/2007/07/a_look_back_bra.php

%trans:
To understand how Git is implemented, and 
to some degree to learn how to use Git effectively,
you need to know the few concepts underlying Git.
%toc:
Those concepts are 
%toc:
the {\em object store}, 
\l (SHA1 (double DAG) Merkel Tree?)
the {\em reference}, and 
the {\em staging area}.
%
They correspond also to [[ocamlgit]]'s main data structures,
which I will describe fully in Chapter~\ref{chap:core-ds}.
%toc:
The following sections will just give an overview of those data structures. 

\subsection{Object store}
\label{sec:object-store}

%torvalds:
To really understand Git, you need to realize that at its core,
Git is a simple {\em content-addressable storage system}.
\l stupid content tracker, as said by torvalds in his first commit
\n rsync was first content-based addressing with md5sum?
%
Given the {\em hash} of a content (Git uses SHA1 hashes, as explained below), 
Git can retrieve back quickly the full corresponding content.
%
Git internally is simply a {\em persistent hash table}, also known
as a {\em key/value store}.

\n the value
In this store, Git manipulates mainly three kinds of values, known
as {\em objects} in Git terminology (hence the term {\em object store}):
\begin{itemize}
\item A {\em blob}: to represent the content of a file at
a specific time.
\l version
\l can also be symlinkk content hence use of Blob and not File (also because
\l  specific to a time)

\item A {\em tree}: to assign names to blobs or other subtrees

\item A {\em commit}: to associate to a specific toplevel tree
a message, an author, a date, and zero or more {\em parent} commits
\n also file types

\end{itemize}

You will see another kind of objects in Section~\ref{sec:tags} with the 
{\em tag}.
%
In addition to those objects, Git maintains also {\em references}
to specific commits and an {\em index} of specific blobs, as explained 
in the next sections.

%\subsubsection{SHA1 objects DAG}

\label{sec:git-sha1-intro}
\n the key
Regarding the keys of the store, Git uses the 
SHA1 algorithm~\cite{sha1,rfc3174}
to compute the hash of an object.
This algorithm associates an almost unique number of 160 bits
(which amounts to 20 bytes, or 40 digits in hexadecimal format) to 
any content of arbitrary length.
\l message digest (MD as in MD5), actually message must be < 2^64
Section~\ref{sec:sha1-algo} presents the code of this algorithm
and gives more information on SHA1.
%
For example, given the content [[Hello Git\n]], the SHA1 algorithm will return
the number [[9f4d96d5b00d98959ea9960f069585ce42b1349a]]
in hexadecimal format.
%
Here the hashing is not very interesting because the hash is bigger
than the original content, but in practice most files under a VCS
are far bigger than 20 bytes.



SHA1 is a complex {cryptographic hash function}. It is outside
the scope of this book to explain how and why it works, but
what is important for Git is that SHA1 is an almost perfect hash function:
\l gperf?
given two different content, there is an almost zero probability
that SHA1 will return the same hash number. 
Such an event is called a {\em collision}, and in practice it
should never happen.
%
Thanks to this almost perfect hash function, Git can {identify}
any content of any length with just a 20 bytes number.
%
In Git, the SHA1 of a file is similar to the {\em inode} of
a file in a filesystem (see the \book{Kernel} for more information
on filesystems and inodes)\footnote{
%torvalds:
The author of Git, Linus Torvalds, is also the author of Linux,
which explains why he chose a design inspired by filesystems.
},
except it references a specific version of a file.
%
In the tree object, which associates names to blobs, Git
uses the SHA1 of a blob to identify this blob. In the same way,
in the commit object, Git uses the SHA1 of a tree to identify
the toplevel tree a commit refers to.



Figure~\ref{fig:objects-sha1-dag} presents the Git objects
(and their relationships) of the Git repository created 
in Section~\ref{sec:getting-started} after the addition of another commit.
%
The first commit, which added [[hello.txt]], is at the top left of 
Figure~\ref{fig:objects-sha1-dag}.
The second commit, below, added the two files [[foo.txt]] and [[bar.txt]]
under a directory [[dir1/]], and also modified [[hello.txt]].
%
I will describe soon in Section~\ref{sec:repository-format} 
how Git stores those objects on the disk.
\t Same file, 2 blobs. Versioned. Sometimes 2 files, same blob. Dedup.
\t But each version store entirely. Seems naive compared to RCS deltas.
\t But gzip, and later will see pack to optimize.

\begin{figure}[!]\centering
\begin{verbatim}
commit 19d977...-----+
|tree:               |   tree 2f092e...-------+      blob 9f4d96...+
| 2f092e... ---------+-->| hello.txt 9f4d96.--+----->|Hello Git    |
|parents:            |   +--------------------+      |             |
| None               |                               |             |
|Author: pad         |                               +-------------+
| <todo@todo>        |
|Date: Fri Sep 29    |                               blob 557db0...+
| 14:04:46 2017 -0700|                            +->|Hello World  |
|Message:            |                            |  |             |
| first commit       |  +->tree 0c4b27...-------+ |  |             |
+--------------------+  | ++ dir1 7e8bb2...     | |  +-------------+
                   ^    | || hello.txt 557db0...+-+
                   |    | |+--------------------+
commit 5d9dfe...---+---+| |
|tree:             |   || |                          blob 452a53...+
| 0c4b27...--------+---++ |                          |baaaaaaaaaa  |
|parents:          |   |  |                        +>|aaaaaaaaaaa  |
| 19d977-----------+   |  |                        | |aaaaaaaaaar  |
|Author: pad           |  |  tree 7e8bb2...-----+  | +-------------+
| <todo@todo>          |  +->| bar.txt 452a53.--+--+
|Date: Fri Sep 29      |     | foo.txt 96ea4a.--+--+ blob 96ea4a...+
| 14:26:23 2017 -0700  |     +------------------+  | | fooooooooo  |
|Message:              |                           +>| oooooooooo  |
| second commit, subdir|                             | oooooooooo  |
+----------------------+                             +-------------+
\end{verbatim}
\caption{Git objects relationships for [[hello/.git]] after two commits.}
\label{fig:objects-sha1-dag}
\end{figure}

\l so back to content-addressable storage, given hash xxx
\l  Git can retrieve quickly blob content.

\l similar to FS. Tree, files. But differences.
\l First DAG! blob can have multiple parents
\l  (also when add in index, some blob get multiple parents)
\l tree can refer same blob, same subtree. DAG.
\l   Like versioned FS.

\l SHA1 used for many things for Git (said later?)
\l SHA1 dedup (said later)
%torvalds:
\l SHA1 checking .not just for identify, also for checking. signature
\l   Make sure what get back what was put. Essential for VCS for torvalds
\l SHA1 to index key/value

\l git does not track changes, it track states! so very different approach
% which in the end I think simplify many things.
% snapshot-based (so fast, at potentially cost of disk space, always
% tradeoff). No delta app.

\l Stored as diffs? apparently not. Just compressed and indexed by sha.
% If same content, then same id.
% No delta (well more on this later with packing).


%\subsubsection{SHA1 Commit DAG}

Commit objects are linked together, 
as shown in Figure~\ref{fig:objects-sha1-dag}
with the second commit linked to the first commit
through the [[parents]] field of the object.
%
Those links represent the history of the repository, also known
as its {\em log}.
%
A commit can have multiple parents
in the case of a {\em merge} 
(I will explain in Section~\ref{sec:git-merge} how to merge branches in Git).
Thus, the log forms a {\em graph}, or more specifically 
a {\em direct acyclic graph} (DAG).
%
Figure~\ref{fig:commit-dag} shows such a graph for an additional series of
commits following the first two commits of Figure~\ref{fig:objects-sha1-dag}.
%
In this example, a developer {\em forked} first 
an experimental branch called [[branch1]] 
(I will explain briefly how to create a branch in
Section~\ref{sec:create-branch-tutorial}
and fully in Section~\ref{sec:create-branch})
following the second commit of Figure~\ref{fig:objects-sha1-dag}. 
%
At the same time, development on the main branch, called the 
{\em master branch} in Git terminology, continued and saw two commits:
[[commit4]] and [[commit6]].
%
The experimental branch got {\em merged} later at [[commit7]]
(I will explain in Section~\ref{sec:git-merge} how to merge branches in Git).
This is why this commit has two parents.
%
Later on, a developer created another branch called [[experiment]] that
remained {active} and did not get merged yet; 
it follows in parallel the development of the {master branch}.

\begin{figure}[!]\centering
\begin{verbatim}
       master
+-------------------+
|commit1 (19d977...)|
+--------+----------+
         |
+--------v----------+    Fork (branch)
|commit2 (5d9dfe...)|----------+
+--------+----------+          |
         |             branch1 |
         |            +--------v-------+
 +-------v--------+   |    commit3     |
 |    commit4     |   +--------+-------+
 +-------+--------+            |
         |            +--------v-------+
 +-------v--------+   |    commit5     |
 |    commit6     |   +-------+--------+
 +-------+--------+           |
         |                    |
 +-------v--------+           |
 |commit7 (merge) |<----------+
 +-------+--------+          Merge
         |
 +-------v--------+     Fork (branch)            -
 |    commit8     |---------------+
 +-------+--------+<------refs/remotes/origin/master
         |                        |
 +-------v--------+               |
 |    commit10    |     experiment|
 +----------------+         +-----+->-------+
         ^                  |    commit9    |
         |                  +---------------+
         |                          ^
         |                          |
 refs/heads/master          refs/heads/experiment
          ^
           \------\
                   \
                   HEAD
\end{verbatim}
\caption{Commit graph and references.}\label{fig:commit-dag}
\end{figure}

% branches, fork, and then merge!
\l second DAG. commit can have multiple parents

%https://blog.jayway.com/2013/03/03/git-is-a-purely-functional-data-structure/

\subsection{References}
\label{sec:references}
\l and the commit graph

%trans: %dup: overview/hello.git/concepts/content-addressable
As I mentionned briefly in the previous section, 
Git maintains, in addition to the object store, {\em references} to
specific commit objects. 
%
Those references have a {\em name} and a {\em content}.
%
For example, in Figure~\ref{fig:commit-dag}, the reference named
[[refs/heads/experiment]]
points to the last commit of the [[experiment]] branch, and
its content is the SHA1 of the [[commit9]] object.
%
I will explain in Section~\ref{sec:repository-format} how
Git stores those references on the disk.

\label{sec:HEAD}
Git maintains also a {special reference} called the {\em HEAD}
which points to the last commit of the {\em current branch}
(see the bottom of Figure~\ref{fig:commit-dag}).
\n actually points to another head
Its content is usually not a SHA1 but the name of another reference.
%
By default, [[HEAD]] points to the master branch, as shown at the bottom of
Figure~\ref{fig:commit-dag}, and so its content is
the string [[ref: refs/heads/master]]
(and [[refs/heads/master]] contains the SHA1 of the last 
commit of the master branch).
%
When you switch branch
(I will explain how to switch branch briefly in 
Section~\ref{sec:switch-branch-tutorial} and fully in 
Section~\ref{sec:switch-branch}),
the content of the [[HEAD]] will change.


A reference pointing to the last commit of a branch
is called a {\em head} in Git terminology and starts with [[refs/heads/]].
In Figure~\ref{fig:commit-dag}, those heads are [[refs/heads/experiment]]
and [[refs/heads/master]].

Git maintains a final set of special references called
the {\em remotes}, for example [[refs/remotes/origin/master]]
pointing to [[commit8]]
in Figure~\ref{fig:commit-dag}. Those references are used 
when people are collaborating with each other and I will explain them
in Chapter~\ref{chap:exchanging}.
\l commit at last synchro and so local commits diverging from remote

% really object store and then .git/refs/ and using sha1 can encode
% many idioms (branches, origin for push/pull, tags, stash)

\subsection{Staging area}
\label{sec:staging-area}

%trans:
The last important concept of Git is the {\em staging area}.
\l which is a concept specfic to Git.
%
Git operates mainly on three different areas, as shown at
the top of Figure~\ref{fig:git-areas}:
\begin{enumerate}
\item The {\em working copy} contains the current state of the files

\item The {\em repository} contains all past versions of all the files 
including the state of the files at the last commit

\item The {\em staging area} contains what the user wants to commit
next
\end{enumerate}

\begin{figure}[!]\centering
\begin{verbatim}

Repository          Staging               working
  (HEAD)              area                  copy
             |                     |
 hello.txt   |                     |     hello.txt
             |                     |     (unmodified)
             |                     |
 bar.txt     |                     |     bar.txt
             |                     |     (modified)
             |                     |
 foo.txt     |   foo.txt       git add   foo.txt
             |   (staged)   <------+---  (modified)
         git commit                |
       <-----+------           git rm    misc.txt
 misc.txt    |   misc.txt     <----+---- (deleted)
             |   (marked for       |
             |   deletion)         |    other.txt
             |                     |    (untracked)
             |                     |
\end{verbatim}
\caption{Git areas.}\label{fig:git-areas}
\end{figure}
\l put remote1 and remote2 too?

After you {modify} a set of files in your working copy,
for example, [[bar.txt]], [[foo.txt]], and [[misc.txt]]
at the right of Figure~\ref{fig:git-areas}, you need to
indicate which of those files and modifications should be part
of the next commit.
%
To do so, you need to {\em mark} those files by using the command
[[git add]] (or [[git rm]] if you want to mark for deletion a file).
%
%After you created a new repository, you must also use [[git add]] to add a 
%new file to the repository.
%In that case the file is said to be {\em tracked} in Git terminology.
%
%Then, you must use [[git add]] when you modify a tracked file
%to mark it for the next commit.


Once you marked all the relevant files, you can use the command [[git commit]]
to commit the modifications to the repository.
\l also git add --patch for interactively adding hunks (used by magit?)
For example, in Figure~\ref{fig:git-areas}, only the modifications
to [[foo.txt]] and the deletion of [[misc.txt]] will be part
of the next commit, and not the modifications to [[bar.txt]].

Once you add a file in a repository, the file is said to be
{\em tracked} in Git terminology.
%
You can sometimes avoid manipulating explicitely the staging area 
by using instead the command [[git commit -a]] to automatically commit all
the modifications to the tracked files.
%
However, the staging area and [[git add]] give more flexibility
to the user by allowing to split a set of modifications in multiple
commits. For example, in Figure~\ref{fig:git-areas}, the modification
to [[bar.txt]] can be put in another commit.
%gitless: useless area

% git status, modified, staged, or untracked.

Internally, Git uses a data structure called the {\em index}
(also known as the {\em directory cache})
to manage the staging area.
%
I will explain later in Section~\ref{sec:index} why
this data structure is called an index.



\section{Repository format: [[.git/]]}
\label{sec:repository-format}

%trans: 
Now that you know the main concepts and data structures underlying Git, 
it will be easy to understand the format of the [[.git/]] directory.
%
Here is the sligtly edited output of the \unix command [[tree]],
which recursively explores a directory and displays its content as a tree
\footnote{See \url{http://mama.indstate.edu/users/ice/tree/}
for more information about the [[tree]] program. The [[-F]] option
used in the terminal session above is to add the special mark [['/']]
at the end of directory names, to help differentiate regular files from
subdirectories.
}.
\n actually now also in utilities/misc/tree.ml
The command is applied here to the [[/tests/hello/.git/]] directory after the 
last command in Section~\ref{sec:getting-started},
when the repository contained just one commit:

\begin{verbatim}
1 $ pwd
/tests/hello
2 $ tree -F .git/
.git/
|-- HEAD
...
|-- index
|-- objects/
|   |-- 2f/
|   |   `-- 092e9cadfc1eb4a6d2febfddb941f4c1fe6fd6
|   |-- 19/
|   |   `-- d977a48d1d7b7ae8d520dd66190702dd4fb5bc
|   |-- 9f/
|   |   `-- 4d96d5b00d98959ea9960f069585ce42b1349a
......
`-- refs/
    |-- heads/
    |   `-- master
.....
\end{verbatim}
\n more elided to simplify
%|-- COMMIT_EDITMSG
%|-- branches/
%|-- config
%|-- description
%|-- hooks/
%...
%|-- info/
%|   `-- exclude
%|-- logs/
%|   |-- HEAD
%|   `-- refs/
%|       `-- heads/
%|           `-- master
%`-- refs/
%    `-- tags/

\l encoding UTF8 for filenames.
% https://github.com/git/git/blob/master/Documentation/i18n.txt

The objects of the key/value store are simply stored in separate
files under [[.git/objects/]]. The hexadecimal digits of the
SHA1 of the object are split in two parts: 
the first two digits are used for the directory name containing the object and 
the remaining digits for the filename of the object.
%
For example, the file
[[.git/objects/9f/4d96d5b00d98959ea9960f069585ce42b1349a]] contains
the blob of [[Hello Git\n]] (see the blob
and its SHA1 at the top right of Figure~\ref{fig:objects-sha1-dag}).

Git uses the first two digits of the SHA1 to classify objects
in separate folders to avoid having too many files in the same
directory. Indeed, this would slow down filesystem operations
such as opening a file referenced by a specific SHA1 key,
a recurring operation under Git
(see the \book{Kernel} for more information on the performance
of filesystem operations).

The references are also stored simply in separate files.
Git uses the name of the reference as the path to a file
under [[.git/refs/]] (e.g., [[.git/refs/heads/master]] in the
example above).

Finally, the index and the HEAD are stored directly under [[.git/]]
in separate files.


\section{[[hello/.git/]]}
\label{sec:git-tutorial}
%\subsection{A terminal session using [[git]]}

%trans: ?
\t some trans?
%toc:
In this section, I will give a short tutorial on how to use Git. 
I will explain the main commands of [[git]] by using a terminal session
starting from an empty [[hello/]] directory.
%trans:
I will continue the series of commands I introduced 
in Section~\ref{sec:getting-started}.
%
I will also describe the semantics of those commands by showing
their effects on the Git metadata stored under the [[hello/.git/]] subdirectory
(by using mainly the output of the [[tree]] command,
as in the previous section).
%
This will hopefully help you to understand the code of
those commands I will present later in the following chapters.
%trans: %toc:
%However, before showing this terminal session, I need to present the main
%concepts behind Git, some Git-specific terminology, and
%the format of the [[.git/]] repository.


%trans:
%I can finally present the tutorial on how to use a few of the main commands
%of Git. I can now describe the precise semantics of those commands.
%
%I will start from the same commands than in Section~\ref{sec:getting-started},
%but I will also explain this time how those commands modify
%files under [[.git/]] (by using mainly the output of the [[tree]] command,
%as in the previous section).
%inspiration:
% - http://eagain.net/articles/git-for-computer-scientists/
% - git from the bottom up (great, I read it while at FB)

\l Here just quick session, quick tutorial.See book to learn how to use git
%dup: use git below, but really ocamlgit, try compatible UI.

\subsection{Creating a repository}
\label{sec:git-tutorial-init}

Here are the commands to create a fresh new repository:

%dup: (but uses git not ocamlgit and add tree command) intro/getting-started
\begin{verbatim}
1 $ cd /tests/
2 $ mkdir hello
3 $ cd hello/
4 $ git init
Initialized empty Git repository in /tests/hello/.git/
5 $ tree -F .git/
.git/
|-- HEAD
...
|-- objects/
`-- refs/
    |-- heads/
6 $ cat .git/HEAD
ref: refs/heads/master
\end{verbatim}
%|-- branches/
%|-- config
%|-- description
%|-- hooks/
% ...
%|-- info/
%|   `-- exclude
%...
%|   |-- info/
%|   `-- pack/
%...
%    `-- tags/

The [[init]] command creates just the directory structure
under [[.git/]], without any objects or references in it
(the [[.git/objects/]] and [[.git/refs/heads]] are empty directories above).
%
There is also not yet an index file.
%
There is a [[HEAD]] file, but its contents,
shown with command~6 above 
references an head that does not exist yet under [[.git/refs/heads/]].

\subsection{Staging a diff}

Here is the command to add a new file (or a new version
of a file) to the repository:

\begin{verbatim}
1 $ echo "Hello Git" > hello.txt
2 $ git add hello.txt
3 $ tree -F .git/
.git/
|-- HEAD
...
|-- index
...
|-- objects/
|   |-- 9f/
|   |   `-- 4d96d5b00d98959ea9960f069585ce42b1349a
...
`-- refs/
    |-- heads/
4 $ cat .git/objects/9f/4d96d5b00d98959ea9960f069585ce42b1349a 
x^K\312\311OR04`\360H\315\311\311Wp\317,\341^B^@4\201^Ec
\end{verbatim}
\l git rm


Adding the first file in a repository has two effects:

\begin{enumerate}
\item The creation of a new {blob object} 
(here in [[.git/objects/9f/4d96...]])
containing essentially the compressed form of the content of the added file
(hence the cryptic output of the [[cat]] command above).
I will fully explain in Chapter~\ref{chap:reading} the format
of a blob on the disk.
\n can now understand compression/decompression in code orga tabular
\l dedup discuss here? and git does not track changes but state?

\item The creation of the index file. Again, I will describe
precisely the format of the index file in Chapter~\ref{chap:reading},
but the index essentially associates to every tracked filenames by
the repository
the SHA1 of the blob {\em currently} corresponding to the filename. 
%
In the example above, the index will associate to the filename [[hello.txt]]
the SHA1 [[9f4d96...]].

\end{enumerate}

%dup: ?
You must use the command [[add]] to add a new file
to the repository, when the file was not yet {tracked} by
the repository. However, you must also use the command [[add]]
to stage the modifications on a tracked file as in 
Figure~\ref{fig:git-areas}.
\l really new version of a file
%dup: above
%
In that case, the [[add]] command also creates a new blob with the
current content of the file. It also updates the index so the filename
of the added file now points to the SHA1 of the new blob.


Note that using [[git add]] on an unmodified file will have no effect. Indeed,
Git will compute the SHA1 of the current content, which will be
identical to the SHA1 of an existing blob. Updating the index will have also
no effect because the filename will reference the same SHA1.
\l or look at date to optimize? 
\l immutable object store beauty (said later?)
\l FIGURE?

\subsection{Committing a diff}

Here is the command to commit to the repository what was previously
staged:

\begin{verbatim}
1 $ git commit -m "first commit" --author "pad <todo@todo>"
2 $ tree -F .git/
.git/
|-- HEAD
|-- index
|-- objects/
|   |-- 2f/
|   |   `-- 092e9cadfc1eb4a6d2febfddb941f4c1fe6fd6
|   |-- 19/
|   |   `-- d977a48d1d7b7ae8d520dd66190702dd4fb5bc
|   |-- 9f/
|   |   `-- 4d96d5b00d98959ea9960f069585ce42b1349a
`-- refs/
    |-- heads/
    |   `-- master
3 $ cat .git/refs/heads/master
19d977a48d1d7b7ae8d520dd66190702dd4fb5bc
\end{verbatim}
\t normally gives more output when commit something [master (root-commit)...]
%|-- COMMIT_EDITMSG
%|-- branches/
%|-- config
%|-- description
%|-- hooks/
%|-- info/
%|   `-- exclude
%|-- logs/
%|   |-- HEAD
%|   `-- refs/
%|       `-- heads/
%|           `-- master
%...
%|   |-- info/
%|   `-- pack/
%...
%    `-- tags/

The [[commit]] command has three effects:

\begin{enumerate}
\item The creation of a new {tree object}, in the example above
[[.git/objects/2f/092e...]]
(see Figure~\ref{fig:objects-sha1-dag} for the content of this tree).
This tree derives from the content of the index. Because the repository
contains only one directory (the toplevel root containing just [[hello.txt]]), 
[[git commit]] will create just one tree object, but in general when
a project has many directories [[git commit]] may create many new tree objects.
\t share! dedup!

\item The creation of a new {commit object}, here
[[.git/objects/19/d977...]],
referencing the newly created tree object
(again, see Figure~\ref{fig:objects-sha1-dag} for the content of this commit
and its relationship to the tree object).

\item The update of the content of the head of the current branch
([[refs/heads/master]] according to the content of [[.git/HEAD]])
to contain the SHA1 of the newly created commit object
(here [[19d977...]]), as shown by command~3 above.
\l note that first commit, so create first time refs/heads/master file
\end{enumerate}

Note that it can be tedious to specify each time on the command-line
your name and email through the [[--author]] flag of [[git commit]].
Git can also leverage a configuration file containing such
information in a [[.gitconfig]] file in your home directory
as explained in Section~\ref{sec:gitconfig}.

\l \subsection{New version of a file}

\subsection{Managing branches}
\label{sec:create-branch-tutorial}

%trans:
% covered all commands in Section X.
%Together, the [[init]], [[add]], and [[commit]] commands can cover
%most of the use case of a developer using Git by himself.
%Now powerful command for parallel development.
%As explained in Section X, To experiment with new features, 
% as in Figure~\ref{fig:commit-dag}.

Here is the command to create a new branch:

\begin{verbatim}
1 $ git branch experiment
2 $ tree -F .git/
.git/
|-- HEAD
...
`-- refs/
    |-- heads/
    |   |-- experiment
    |   `-- master
...
3 $ cat .git/HEAD 
ref: refs/heads/master
4 $ cat .git/refs/heads/master
19d977a48d1d7b7ae8d520dd66190702dd4fb5bc
5 $ cat .git/refs/heads/experiment
19d977a48d1d7b7ae8d520dd66190702dd4fb5bc
\end{verbatim}

As you can see, creating a new branch is an extremely cheap operation
under Git.
%
It consists just in adding a file under [[.git/refs/heads/]]
with the name of the new branch (here [[.git/refs/heads/experiment]]),
and the SHA1 commit of the current branch
for its content (here [[19d977...]]).
%
However, creating a branch does not switch to this branch as shown
by command~3 above.

\label{sec:switch-branch-tutorial}
Here is the command to switch to the new branch:

\begin{verbatim}
6 $ git checkout experiment
Switched to branch 'experiment'
7 $ cat .git/HEAD
ref: refs/heads/experiment
\end{verbatim}

Switching to a branch is usually a more costly operation.
%
[[git checkout]] modifies [[HEAD]] (as shown by command~7 above), 
which is fast, 
but it also recomputes the index from the tree
object that is referenced in the commit of the head of the new branch,
as well as from all its subtrees
(see Section~\ref{sec:index-from-tree} for the full description 
of this operation).
%
It also updates all the files so that they contain the content of
the blobs referenced in the index.
%
The more the new branch differs from the current branch, the more
costly switching to this new branch will be.

\subsection{Inspecting objects}
\label{sec:git-show-examples}

Git provides a few commands to query the repository.
Those commands are useful to understand the internal structures of Git.
They are also useful for doing some archeology on the history of a project,
as explained in Section~\ref{sec:archeology}.
%
The first of those commands, [[show]], shows the content of a Git object.
[[git show]] takes the SHA1 of an object as a parameter (in hexadecimal format)
\l or objectish ref?
and pretty prints its content in a readable format.
%
Here are a few examples of this command:

\begin{verbatim}
1 $ tree -F .git/
...
|-- objects/
|   |-- 2f/
|   |   `-- 092e9cadfc1eb4a6d2febfddb941f4c1fe6fd6
|   |-- 19/
|   |   `-- d977a48d1d7b7ae8d520dd66190702dd4fb5bc
|   |-- 9f/
|   |   `-- 4d96d5b00d98959ea9960f069585ce42b1349a
...
2 $ git show 9f4d96d5b00d98959ea9960f069585ce42b1349a
Hello Git
3 $ git show 2f092e9cadfc1eb4a6d2febfddb941f4c1fe6fd6
tree 2f092e9cadfc1eb4a6d2febfddb941f4c1fe6fd6

hello.txt
4 $ git show 19d977a48d1d7b7ae8d520dd66190702dd4fb5bc
commit 19d977a48d1d7b7ae8d520dd66190702dd4fb5bc
Author: pad  <todo@todo>
Date:   Fri Sep 29 14:04:46 2017 -0700

    first commit

diff --git a/hello.txt b/hello.txt
new file mode 100644
index 0000000..9f4d96d
--- /dev/null
+++ b/hello.txt
@@ -0,0 +1 @@
+Hello Git
\end{verbatim}
\t need fix ocamlgit to output that diff format
\l talk about diff?
\l would be nice to have tree SHA1 reference from commit and also
\l SHA1 reference of blobs in the tree.

The command [[show]] mainly opens the appropriate file under [[.git/objects/]],
decompresses the file, and finally displays its content.

Another important query command is [[log]] to see the full history
of a repository. Here is the output of this command on the
repository we used this far:

\begin{verbatim}
1 $ git log
commit 19d977a48d1d7b7ae8d520dd66190702dd4fb5bc
Author: pad  <todo@todo>
Date:   Fri Sep 29 14:04:46 2017 -0700

    first commit
\end{verbatim}

The command [[log]] mainly opens [[.git/HEAD]] to get a reference
to the last commit. Then, it goes through the parent links of the
commit object to recursively explore all the linked commit 
objects (stored again under [[.git/objects/]]).

\subsection{Other commands}

%trans:
%Together, the [[init]], [[add]], [[commit]], [[branch]], [[checkout]]
% commands can cover
%most of the use case of a developer using Git by himself.

%chunks:
There are a few other important Git commands: 
[[git merge]], 
[[git status]], 
[[git diff]],
[[git clone]], 
[[git pull]], or 
[[git push]], 
but I will introduce them later in this document.


\section{Code organization}

%dup: (and heavily adapted) from Assembler.nw
Table~\ref{tab:code-orga} presents short descriptions
of the source files used by [[ocamlgit]]
%together with the main entities (e.g., types, functions) the file defines,
and the corresponding chapters in this document in which the code
contained in the file is primarily discussed.
\n sorted by chapters, make more sense than sorted by dir

\begin{table*}[tbh!]
\begin{center}
\begin{tabular}{lcllr}
\toprule
{\bf Function}  & {\bf Chapter} & {\bf Files} & {\bf LOC} \\
\otoprule
SHA1 binary and hexadecimal hashes & \ref{chap:core-ds}              & [[sha1.mli]] [[hexsha.ml]] &    \\
repository type and main API       & \ref{chap:core-ds}              & [[repository.ml]] &    \\ % lots of func actually introduced later
objects                            & \ref{chap:core-ds}              & [[objects.ml]] [[blob.ml]] [[tree.ml]] [[commit.ml]] [[user.ml]] &    \\
references                         & \ref{chap:core-ds}              & [[refs.ml]] &    \\
staging area                       & \ref{chap:core-ds}              & [[index.ml]] &    \\
%client/server architecture         & \ref{chap:core-ds}              & [[client.ml]] [[server.ml]] &    \\

\midrule

reading from a repository & \ref{chap:reading}              & [[decompression.ml]] &    \\
%\midrule compressed data
writing to a repository   & \ref{chap:writing}              & [[compression.ml]] &    \\
%\midrule and compressing data

\midrule

list of commands                   & \ref{chap:main}              & [[cmd_.ml]] [[cmds.ml]] &    \\
entry point and command dispatcher & \ref{chap:main}              & [[main.ml]] &    \\
getting help                       & \ref{chap:main}              & [[cmd_help.ml]] &    \\

\midrule

creating a repository     & \ref{chap:creating}              & [[cmd_init.ml]] &    \\
%\midrule
staging a diff            & \ref{chap:staging}              & [[cmd_add.ml]] [[cmd_rm.ml]] [[cmd_mv.ml]]  &    \\
%\midrule
committing a diff         & \ref{chap:committing}              & [[cmd_commit.ml]]           &    \\
%\midrule
manipulating branches     & \ref{chap:branching}              & [[cmd_branch.ml]] [[cmd_checkout.ml]] [[cmd_reset.ml]] &    \\
%\midrule
merging multiple branches & \ref{chap:merging}              & [[cmd_merge.ml]] &    \\ %cmd_merge.ml cmd_cherrypick.ml 

\midrule

inspecting objects    & \ref{chap:inspecting}              & [[cmd_show.ml]] &    \\
tree and file changes & \ref{chap:inspecting}              & [[change.ml]] [[diff.ml]] &    \\
showing differences   & \ref{chap:inspecting}             &  [[cmd_diff.ml]] [[changes.ml]] [[diff_unified.ml]]  &    \\
commit history        & \ref{chap:inspecting}              & [[cmd_log.ml]]  &    \\
file status           & \ref{chap:inspecting}              & [[cmd_status.ml]]  &    \\
\midrule
packing objects and delta compression   & \ref{chap:packing}              & [[pack.ml]] &    \\
\midrule
exchanging commits    & \ref{chap:exchanging}              & [[cmd_pull.ml]] [[cmd_push.ml]]  &    \\
local exchange        & \ref{chap:exchanging}              & [[client_local.ml]]  &    \\
cloning a repository  & \ref{chap:exchanging}              & [[cmd_clone.ml]]  &    \\
\midrule
client/server architecture  & \ref{chap:networking}        & [[client.ml]] [[server.ml]] &    \\
networking clients    & \ref{chap:networking}              & [[clients.ml]]  &    \\ % protocol.ml
[[git://]] protocol   & \ref{chap:networking}              & [[client_git.ml]]  &    \\
\midrule
% bisect, blame
core algorithms           & \ref{chap:algorithms}             & [[sha1.ml]] [[zip.ml]] [[unzip.ml]] [[diff_basic.ml]] [[diff_myers.ml]] [[diff3.ml]]  &    \\ % (sha1.mli before)
\midrule

advanced features                & \ref{chap:advanced-features}              & [[config.ml]] [[ignore.ml]]  &    \\ %reflog.ml stash.ml graft.ml submodule.ml hooks.ml
% config.ml ignore.ml rename.ml
advanced commands                & \ref{chap:advanced-commands}              & [[tag.ml]]  &    \\ %cmd_bisect.ml cmd_revert.ml cmd_blame.ml cmd_grep.ml cmd_archive.ml
% cmd_plumb_fetch.ml
advanced networking & \ref{chap:advanced-networking} & & \\ % client_ssh.ml, ...

\midrule

dumpers and debugging support    & \ref{chap:debugging-ocamlgit}              & [[cmd_dump.ml]] [[dump.ml]] [[cmd_test.ml]]  &    \\
binary IO utilities       & \ref{chap:utilities}              & [[IO_.ml]]  &    \\

\otoprule
Total           &               &            &                & 6196  \\
\bottomrule
\end{tabular}
\end{center}
\caption{Chapters and source files of [[ocamlgit]].}
\label{tab:code-orga}
\end{table*}
\n see SRC_VIEWS in the mkfile, and mk loc
\l shorten diff and repo?

% requires also:
% - zlib (but hope I can port decompress code so no need libc)

% style: Xxx.t, match () with _ when ... ->, Common.

The most important files are [<repository.ml>], which contains
the main API to manipulate a repository, and the [[cmd_xxx.ml]]
files implementing each a Git command
(e.g., [<cmd_init.ml>] for [[git init]]).

\section{Software architecture}
\label{sec:archi}

Figure~\ref{fig:controlflow} describes the main {modules}
of [[ocamlgit]] and their main dependencies.
\n hidden client/pull/push stuff and reduced deps 
Those dependencies correspond roughly also to the main control 
flow of [[ocamlgit]].
%
This flow starts at the top of Figure~\ref{fig:controlflow} with the 
execution of [<Main.main()>] when the program [[ocamlgit]] starts. 
%
This function looks whether the first argument of [[ocamlgit]] is one
of the command listed in the global [<Cmds.main_commands>].
%
If it is, then [<Main.main()>] dispatches the appropriate
command, for example, [<Cmd_add.cmd>] if the first argument
to [[ocamlgit]] was [[add]].
%
Each command usually processes the remaining command-line arguments
to [[ocamlgit]] and uses functions from the API provided by
the [[Repository]] module. This API contains functions to
open a repository ([<Repository.open_()>]),
read an object ([<Repository.read_obj()>]),
add an object ([<Repository.add_obj()>]),
modify a reference ([<Repository.set_ref()>]),
modify the index ([<Repository.add_in_index()>]),
etc.
%
Internally, the [[Repository]] module relies on the
[[Objects]], [[Refs]], and [[Index]] modules to read and write
files under the [[.git/]] directory 
(e.g., [<Index.read()>] and [<Index.write()>] to respectively read and
write the index file in [[.git/index]]).
\l explain Blob/Tree/Commit ?
%
Those modules in turn rely on algorithms 
to compute SHA1 hashes ([<Sha1.sha1()>]),
to list the differences between two files ([<Diffs.diff()>]),
to merge two files coming from a common base file ([<Diff3.diff3()>]),
or to compress ([<Zip.deflate()>]) 
and decompress ([<Unzip.inflate()>]) data.
\l explain pull/push and clients? not enough space? too complicated for now?
\l say that in rest of doc will use SHA1 to mean SHA1 hash (shorter)

\begin{figure}[!]\centering
\begin{verbatim}
                  +-------+
                  | Main  |               Entry point
                  +---+---+
                      |
                  +---v---+
                  | Cmds  |                 Dispatch
                  +-------+
                      |
      +-------------+-+-----------+
 +----v---+   +-----v--+       +--v------+
 |Cmd_init|   |Cmd_add |  ...  |Cmd_pull |  Commands
 +------+-+   +------+-+       +--+------+
        |            |            |
        +----------+ | +----------+
                +--v-v-v---+
                |Repository|                Main API
                +-+--+--+--+
         +--------+  |  +------------+
   +-----v----+  +---v------+  +-----v----+
   | Objects  |  |   Refs   |  |  Index   |  Storage
   +---+-+--+-+  +----------+  +--+-------+
       | |  +----+------+ +-------+
       | +----+  |      | |
  +----v-+ +--v--v+ +---v-v+
  | Tree | |Commit| | Blob |                Git objects
  +------+ +------+ +------+


+------+ +----------+ +------+ +------+
| Sha1 | |Zip/Unzip | | Diff | |Diff3 |     Algorithms
+------+ +----------+ +------+ +------+
\end{verbatim}
\caption{Main module dependencies of [[ocamlgit]].}\label{fig:controlflow}
\end{figure}
\n see archi.pdf generated by ocamldot -dot, but too big and better hand-made

\n no really data flow. I could put DS relationships though, but
\l  explained before?


\n plumbing vs porcelain in original git version? Not important here.
% Linus started with low-level cmds for a content addressable storage engine.

%\section{Bootstrapping}
%bootstrap:
% just a tar.gz, simple, as mentioned before.

\section{Book structure}

%trans: %dup: (and adapted) from Assembler.nw
You now have enough background to understand the source code of [[ocamlgit]].
%toc: 
The rest of the book is organized as follows.
%dup: (repeat a bit) intro/code-orga
I will start by describing the core data structures of [[ocamlgit]]
in Chapter~\ref{chap:core-ds}.
Chapter~\ref{chap:reading} and Chapter~\ref{chap:writing} 
contains respectively the code to read and write those
data structures on the disk in files under [[.git/]].
%
Then, I will switch to a top-down approach, starting with 
Chapter~\ref{chap:main} with the description of [<Main.main()>] 
and the dispatch of the Git commands.
%
In Chapter~\ref{chap:creating} I will describe the code for the [[init]]
command, which initializes the [[.git/]] directory.
%
The following five chapters will describe the commands of [[ocamlgit]]
%dup:? ?
that cover most of the use-cases for a single developer:
%which rely on the code of the previous chapters to manipulate the files
%under [[.git/]]:
Chapter~\ref{chap:staging} will present the code to add files in
the staging area,
Chapter~\ref{chap:committing} the code to commit what was staged, 
Chapter~\ref{chap:branching} the code to create and switch branches,
Chapter~\ref{chap:merging} the code to merge branches, and finally
Chapter~\ref{chap:inspecting} the code to query the repository.
\l inspect Git objects.
%
Chapter~\ref{chap:packing} presents the code to pack and compress objects,
which is an important optimization.
%
Then I will present the commands for collaborating with other developers:
Chapter~\ref{chap:exchanging} presents the code to exchange commits between
repositories, and
Chapter~\ref{chap:networking} the code to exchange those commits through
the network.
%trans:
The code in the previous chapters rely on general algorithms that are useful
not only for Git but also for other programs.
\l ex of other programs?
I will present the code of those general algorithms in
Chapter~\ref{chap:algorithms} (e.g., 
the algorithm to compute the SHA1 of any string, or
the algorithm to compute the differences between two files).
%
Then, I will present advanced functionalities of Git 
that I did not present before to simplify the explanations.
Starting with Chapter~\ref{chap:advanced-features}, I will presents advanced 
features, for instance, the [[.gitconfig]] configuration file.
In Chapter~\ref{chap:advanced-commands} I will present advanced commands,
for instance, [[git tags]].
%for example commands that are useful for developers to develop 
%and debug programs (e.g., [[git bisect]]) when the  source code of 
%those programs is managed by Git, 
% to help develop! not just store/retrieve
Finally in Chapter~\ref{chap:advanced-networking} I will present advanced 
networking options,
for instance, a Git client and Git server using the [[http://]] protocol.
%
Chapter~\ref{chap:conclusion} concludes
and gives pointers to other books in the \principia series.
\l really what the conclusion does? no much pointers I think

Some appendices present the code of non-functional properties:
code to help debug [[ocamlgit]] itself 
in Appendix~\ref{chap:debugging-ocamlgit}.
%Chapter~\ref{chap:profiling-ocamlgit}
%Chapter~\ref{chap:error}
%
Finally, Appendix~\ref{chap:utilities} contains the code of generic utility
functions used by [[ocamlgit]] but which are not specific to [[ocamlgit]].

%##############################################################################

\chapter{Core Data Structures}
\label{chap:core-ds}

\begin{verse}
\begin{flushright}
  {\it Show me your code and conceal your data structures, and I shall
    continue to be mystified. Show me your data structures, and I
    won't usually need your code; it'll be obvious.\\
    ~\\
    Fred Brooks}
\end{flushright}
\end{verse}

%dup: overview/hello.git/git-concepts
I mentioned before in Section~\ref{sec:git-concepts-and-ds} the 
core data structures of Git:
the object store,
the reference, and
the index.
%toc:
This chapter contains three sections introducing the types of
those three data structures.
%
Those data structures contain SHA1 hashes, so I will present first
the types of the different kinds of SHA1 hashes (binary and hexadecimal).
%
%Finally, I will present types for advanced features of Git: 
%the {pack file}, to pack and compress multiple Git ojbects together, and
%the client/server architecture for exchanging Git objects and pack files 
%through the network.

\section{Secure Hash Algorithm (SHA1) hashes}
\n Secure, not Simple.

Git relies heavily on SHA1 hashes to name and address Git objects.
%toc
Git uses two different formats for those hashes: 
binary hashes (mainly for storage on the disk) and
hexadecimal hashes (mainly to interact with the user)
as explained in the following sections.

\t used for many things
%  - identifying (and versioning), 
%  - consistency checking, 
%  - indexing (and also for folders), 
%  - deduplicating (good for rename detection too)
% SHA1 underlies lots of things in git.

%sccs: used checksum (as opposed to RCS) to detect corrupted history files

\subsection{Binary hashes}

%dup: overview/hello.git/concept/object-store
As I mentioned in Section~\ref{sec:git-sha1-intro}, an SHA1 hash
is a 160 bits number. Such a number can be encoded as a sequence of 20 bytes.

<<type [[Sha1.t]]>>=
(* a 20 bytes number (really a string of length 20) *)
type t = string
@

The [[sha1()]] function returns a 20 bytes number for any content
of arbitrary length.

<<signature [[Sha1.sha1]]>>=
(* computes SHA1 of a series of bytes *) 
val sha1: string -> t
@
\n bytes to bytes in the end

I will present the code of [<Sha1.sha1()>] later in
Section~\ref{sec:sha1-algo}.

OCaml types are not powerful enough to express that a binary
SHA1 hash is a sequence of precisely 20 bytes\footnote{
We could use a tuple with 20 character elements, but that would be
tedious to use.}.
The function below expresses this additional constraint:

<<signature [[Sha1.is_sha]]>>=
val is_sha: t -> bool
@
<<function [[Sha1.is_sha]]>>=
let is_sha (x : t) : bool =
  String.length x = 20
@
\n extra checks? forbidden bytes? I dont think so.

This function will be used mostly as a form of
defensive programming in asserts.


\subsection{Hexadecimal hashes}

A 160 bits number can also be represented as 40 characters
in hexadecimal (two hexadecimal characters per byte,
e.g., [["ff"]] for 255).
\l (each byte is actually encoding only 16 values, an hexadecimal number)

<<type [[Hexsha.t]]>>=
(* a 40 characters string, e.g. "d670460b4b4aece5915caf5c68d12f560a9fe3e4" *)
type t = string
@

\t SHA1 used in git to identify things version ID (e.g., commit).
% But some commands expect version id. 
%rcs:
% With RCS easy to say retrieve version 1.1, but with git
% not easy to enter binary data i  terminal. 
% Enter Hexsha, ASCII Hexadecimal,  can be input
%dup:
% As I said, easier format for user to enter or read sha in terminal.


Again, OCaml types are not powerful enough to fully express
the format of an hexadecimal SHA1 hash, 
so the function below expresses the remaining constraints:

<<signature [[Hexsha.is_hexsha]]>>=
val is_hexsha: t -> bool
@
<<function [[Hexsha.is_hexsha]]>>=
let is_hexsha x =
 String.length x = 40 && x =~ "^[0-9a-fA-F]+$"
@
%$

\subsection{Conversion functions}

Both formats of SHA1 hashes are useful and we will need many times
to convert from one format to the other.
%
The first conversion function transforms an hexadecimal hash into a
binary hash.

% git use mostly internally binsha, less space, so need convert user
% Hexsha to bin sha1
\l actually commit object contains hexsha, same for references

<<signature [[Hexsha.to_sha]]>>=
val to_sha: t -> Sha1.t
@
<<function [[Hexsha.to_sha]]>>=
let to_sha s =
  assert (is_hexsha s);
  let n = String.length s in
  let buf = Bytes.create (n/2) in
  <<[[Hexsha.to_sha()]] fill [[buf]]>>
  Bytes.to_string buf
@
\t useful for?

%old: 
% let to_sha s =
%  assert (is_hexsha x);
%  to_string x
%let to_string ((*`Hex*) s) =
%  if s = "" 
%  then ""
%  else
%   ...
%let to_string hex =
%  to_helper ~empty_return:"" ~create:Bytes.create ~set:Bytes.set hex
%@

The function [[to_sha()]] relies on the nested function below to iterate over
all the pairs of characters in the hexadecimal hash and
to generate one byte from each pair:

<<[[Hexsha.to_sha()]] fill [[buf]]>>=
let rec aux i =
  if i >= n 
  then ()
  else begin
    <<[[hexsha.to_sha()]] double sanity check range i>>
    Bytes.set buf (i/2) (to_byte s.[i] s.[i+1]);
    aux (i+2)
  end
in
aux 0;
@
%old: let rec aux i j = ...
\l FIGURE? where pair 2 hex in boxes and then convert and show
\l  i range over boxes?

<<function [[Hexsha.to_char]]>>=
let to_byte hex1 hex2 =
  let code hex = 
    match hex with
    | '0'..'9' -> Char.code hex - Char.code '0'
    | 'A'..'F' -> Char.code hex - (Char.code 'A' + 10)
    | 'a'..'f' -> Char.code hex - (Char.code 'a' + 10)
    | _ -> 
      raise (Invalid_argument 
              (spf "Hex.to_byte: %d is an invalid hexadecimal digit" (Char.code hex)))
  in
  Char.chr (((code hex1) lsl 4) + (code hex2))
@
\t spf
%old:
% let to_char x y =
% Char.code c - 55 (* Char.code 'A' + 10 *)
% (useless partial evaluation opti)
% <<function Hexsha.invalid_arg>>=
% let invalid_arg fmt =
%   Printf.ksprintf (fun str -> raise (Invalid_argument str)) fmt
% @


<<[[hexsha.to_sha()]] double sanity check range i>>=
if i+1 >= n 
then raise (Invalid_argument "hex conversion: invalid hex string");
@
\l useless, double, because already is_hexsha assert so odd length

\t When communicate with user, 
% or when access loose object,
% need opposite conversion:

The other conversion function goes the other way around, from
a binary hash to an hexadecimal hash:

<<signature [[Hexsha.of_sha]]>>=
val of_sha: Sha1.t -> t
@
<<function [[Hexsha.of_sha]]>>=
let of_sha s =
  assert (Sha1.is_sha s);
  let n = String.length s in
  let buf = Bytes.create (n * 2) in
  <<[[Hexsha.of_sha()]] fill [[buf]]>>
  Bytes.to_string buf
@
%pad: use let n, not let len, so more consistent with other function
\l FIGURE? reverse of other one with boxes again?
%old:
%let of_sha x =
%  assert (Sha1.is_sha x);
%  of_string_fast x
%  ...
%    Bytes.unsafe_set buf (i * 2)
%      (String.unsafe_get hexa1 (Char.code (String.unsafe_get s i)));
%    Bytes.unsafe_set buf (succ (i * 2))
%      (String.unsafe_get hexa2 (Char.code (String.unsafe_get s i)));
%  (*pad:`Hex*) buf
%pad: succ? unsafe_get? extra intermediate func? bad.

This time, each byte from [[s]] generates two characters:

<<[[Hexsha.of_sha()]] fill [[buf]]>>=
for i = 0 to n - 1 do
  Bytes.set buf (i * 2) hexa1.[Char.code (s.[i])];
  Bytes.set buf ((i * 2) + 1) hexa2.[Char.code (s.[i])];
done;
@

The loop above relies on two constants containing 256 elements
mapping a byte to one of the two hexadecimal characters:

<<constant [[Hexsha.hexa1]]>>=
and hexa1 =
  "0000000000000000111111111111111122222222222222223333333333333333\
   4444444444444444555555555555555566666666666666667777777777777777\
   88888888888888889999999999999999aaaaaaaaaaaaaaaabbbbbbbbbbbbbbbb\
   ccccccccccccccccddddddddddddddddeeeeeeeeeeeeeeeeffffffffffffffff"
@
<<constant [[Hexsha.hexa2]]>>=
and hexa2 =
  "0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef\
   0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef\
   0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef\
   0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef"
@


\section{[[Repository.t]]}

In the following chapters, many functions will require to know
where is located the repository they need to operate on.
\l current dir? cwd?
Those functions will need to access files under the [[.git/]] subdirectory
or to access the working files of a repository.
%
The type below conveniently packs all the necessary information to locate
files on the disk:

<<type [[Repository.t]]>>=
type t = {
  worktree: Fpath.t;
  dotgit: Fpath.t; (* usually <worktree>/.git *)

  <<[[Repository.t]] index field>>
}
@
%  (* less: on bare repo, this could be None *)
%  (* less: on bare repo this could be the toplevel dir *)
%  (* less: compression level config field? *)
\l use Common.path?
\n dotgit could be called commondir or controldir when have bare repo.
\l Hooks later.
\l info?? useful for grafts and?

% Repository type is main type. Main API functions take
% repo as first parameter.

% Store path worktree, path metadata (dotgit),
% and also index. 3 main areas.


% will see open_() later.

% a repo is really a set of commits,
% and also set of names of commits (branches, tags, HEAD).
% But represented in subtle way in git.
% set of objects, and then refs of this object, where some objects can
% be commit.


%trans:
% dotgit contains objects and refs (see next 2 sections).
%python: [] accessors for repo.object_store and repo.refs
% (and even [] for repo itself for objectish)

% Present main API too? as I said in code orga tabular.

%\subsection{Object store}
\label{sec:object-store-function}

% git really is a content addressable storage engine,
% objects are stored in object store.
% To retrive object given its hash, just need path

Given a repository [[r]] and an hexadecimal SHA1 hash [[hexsha]], 
it is easy to locate a Git object on the disk thanks to the
following function:

% internal functions not exposed in repository.mli
<<function [[Repository.hexsha_to_filename]]>>=
(* for loose objects *)
let hexsha_to_filename (r : t) (hexsha : string) : Fpath.t =
  let dir = String.sub hexsha 0 2 in
  let file = String.sub hexsha 2 (String.length hexsha - 2) in
  r.dotgit / "objects" / dir / file
@
%python: nice syntax for string access like hex[:2] and hex[2:]
\l ex of use?  /hello/.git/...
\t comment about loose objects and packing reference?

%old: was used only in add_obj and simpler to use Filename.dirname
%<<function Repository.hexsha_to_dirname>>=
%let hexsha_to_dirname r hexsha =
%  let dir = String.sub hexsha 0 2 in
%  r.dotgit / "objects" / dir
%@

% Regular files!

% talk about the encoding stuff? should aspectize? confusing?

%python: nice overloading of [] (but bad to abuse it) to access object
% store.

The function above relies on a special operator to concatenate
filenames:

<<constant [[Repository.SlashOperator]]>>=
@


\section{[[Objects.t]]}

%dup: overview/hello.git/git-concepts core-ds
As I explained in Section~\ref{sec:object-store}, 
Git uses internally mainly three kinds of objects, as expressed
by the following type:

<<type [[Objects.t]]>>=
type t = 
  | Blob   of Blob.t
  | Tree   of Tree.t
  | Commit of Commit.t
  <<[[Objects.t]] cases>>
@

%https://git-scm.com/book/en/v2/Git-Internals-Git-Objects

%toc:
The following sections will detail [<Blob.t>], [<Tree.t>], and [<Commit.t>].
The following chapter will describe the format of those objects
on the disk.
\l and the code on how to read and write

\subsection{[[Blob.t]]}
% =~ file content (but no name, name is in tree)

A blob is simply a sequence of bytes. 

<<type [[Blob.t]]>>=
type t = string
@

In the following data structures, some fields will contain SHA1 hashes
that must refer to a blob. 
%
The type below can be used to express this constraint;
this constraint will not be checked statically, but
using the type provides a useful comment:
\l was typechecked actually in ocamlgit, but with tricks

<<type [[Blob.hash]]>>=
type hash = Sha1.t
@
% Later will want to specify that sha1 corresponds to a blob, so
% use type alias for readability (but not really typechecked)


% But no interleave deltas (SCCS), reverse deltas (RCS).
% Each modif generates new blob! disk is cheap now!
% But dedup!
% deduplicating! empty file! copy of file.
% And will see soon compressed on disk!
% And will see later more optim with pack files and deltas.

\subsection{[[Tree.t]]}
% =~ directories =~ project content.

A tree is an ordered list of {entries} where each entry
associates to a name a Git object through its (binary) SHA1.

%"It doesn't bother trying to store per-file histories;
%it instead stores the history at the tree level. When you perform a
%diff you are comparing two trees, not two files."

<<type [[Tree.t]]>>=
(* todo: entries must be sorted! and each name must be unique *)
type t = entry list
@
\t is_tree (consistent with is_sha, is_hexsha, etc)

<<type [[Tree.entry]]>>=
type entry = {
  (* relative to tree, so does not contain any '/', or '.' or '..' *)
  name: string;
  (* Blob.hash or Tree.hash *)
  id: Sha1.t;

  perm: perm;
}
@
%old: use id instead of node, so more consistent with Index.entry.id
%crossref: Sha1.t (said above indirectly)


<<type [[Tree.hash]]>>=
type hash = Sha1.t
@

Each name refers either to 
a file (a blob), or 
a directory (another tree).
% recursive here! with entry.id referencing another tree!

Git handles only a few file types and permissions for those entries,
as expressed by the type below:

% Name can contain space, utf8, whatever! 
% (seemed to be a pb in many other SCMs)

<<type [[Tree.perm]]>>=
(* similar to Index.mode, but with also a 'Dir' *)
type perm = 
  | Normal
  | Dir
  | Exec
  <<[[Tree.perm]] cases>>
@
% Nice simplification :) just needs that!
% Dont care about permission, time, inode-id, etc. 

% deduplicating! share subdir if no change.

I will present in Chapter~\ref{chap:advanced-features} a few 
more file types supported by Git (e.g., symbolic links, submodules).
\n ref{sec:symlinks} ref{sec:submodules}

Note that a tree entry does not specify the used id ([[uid]]) or
group id ([[gid]]) of a file, or the read-write-execute
permissions ([[rwx]]) of a file (except for the [[x]] with [[Exec]] above
to denote executable files).
%
Indeed, the repository must abstract away this kind of specific information.
Many people can collaborate with each other by working on the
same repository, so it would not make sense to favor any user or permission.
\l morever uid not stable acrosss machines

Git supports only a simple subset of \unix file types. It can not
store special files such as a socket, a named pipe, or a device file.

%alt: flat list of revision number for each file? how retrive file?
% if renamed? if removed?

% Merkel trees?
% Can reference entire tree with just hash of root tree! because
% This tree itself is hashed by its content.

\subsection{[[Commit.t]]}

%trans:
The last Git object, 
%
the commit, associates to a toplevel tree (again through its SHA1 binary hash) 
a set of parent commits, 
an author, 
a date,
and a commit message.

% =~ history
% each commit has a tree and a parent, so can trace history of full project.

<<type [[Commit.t]]>>=
type t = {
  tree     : Tree.hash; (* the root *)
  (* first commit has no parent, and merge commits have 2 parents *)
  parents  : hash list;
  (* note that User.t contains a time *)
  author   : User.t;
  message  : string;
  <<[[Commit.t]] extra fields>>
}
@
%crossref: Tree.hash (again indirectly via text above)

\ifallcode
<<[[Commit.t]] extra fields>>=
(* less: encoding, gpgsig, mergetag, extra *)
@
\fi

<<type [[Commit.hash]]>>=
and hash = Sha1.t
@

The [[User.t]] type below specifies the name and email of an author,
but also the date of the commit and the timezone of the author.
\t solve complicated time issue
%rcs: %sccs: had 2 digits for the year for a long time and was
% using local time

<<type [[User.t]]>>=
type t = {
  name : string;
  email: string;
  date : Int64.t (* seconds *) * timezone_offset;
}
@
%old: tz_offset (*option*)
\t int64, seconds, no 2032 issues

<<type [[User.tz_offset]]>>=
type timezone_offset = int (* +/- hours, [-12, +12] *)
@

%old:
% <<type User.tz_offset>>=
% type tz_offset = {
%   sign: sign;
%   hours: int;
%   min: int;
% }
% @
% <<type User.sign>>=
% type sign = Plus | Minus
% @

Git allows to differentiate who was the author of a modification
and who actually commited the modification to the repository.
\l useful? Linux email patch?

<<[[Commit.t]] extra fields>>=
committer: User.t;
@



% Fast checkout. Give me commit and I can grab
% all files from object store (looking first tree and then
% going recursively grabbing blobs on the way).
%rcs: innovated over slow sccs by storing diffs in reverse! fast checkout.

% DAG of version on top of tree of files. Subtle.
% Also merkle tree.

\section{References}

As I explained in Section~\ref{sec:references}, references,
which are mainly stored under [[.git/refs/]], are another
fundamental data structure of Git. 
%toc
References have 
a name (e.g., [[refs/heads/master]]), and 
a content (usually an hexadecimal SHA1 hash), 
as explained in the following sections.


%dup:
% Object store and reference store.

% kinda correspond to branch name.
% .git/refs/heads/xxx are branches.
% .git/HEAD is current branch (usually point to .git/refs/heads/master
%  but 'master' is really just a convention could be 'trunk' or whatever)
% then this simple model allow to encode many idioms:
% - remote push/pull .git/refs/remote/origin/master
% - tags (refs/tags/xxx)
% - stash
% - ?

%torvalds:
% And that's it! with objects and (atomic) refs, you can do everything!
% far more complicated to achieve the same in other VCSs.

\l when stuff under refs/... contain indirect ref? HEAD is indirect
\l ref, but when need indirect ref under refs/?

% then can even save history of those refs (the reflog).

%https://git-scm.com/book/en/v2/Git-Internals-Git-References
%references vs symbolic references.

\subsection{Reference names}

% Valid branch name:

<<type [[Refs.refname]]>>=
(* should always start with "refs/", see is_refname() later *)
type refname = string (* e.g. "refs/heads/master" *)
@

The format of a reference name has a few constraints that
the type can not easily express:

<<signature [[Refs.is_valid_refname]]>>=
val is_refname: refname -> bool
@
<<function [[Refs.is_valid_refname]]>>=
let is_refname str =
  str =~ "^refs/"
  (* todo: git-check-ref-format *)
@
%old: was is_valid_refname, but more consistent with is_hexsha, etc

\subsection{[[HEAD]]}

Most references are stored under [[.git/refs/]], but Git maintains
also a special reference called the [[HEAD]] (see Section~\ref{sec:HEAD})
to point to the head of the current branch, hence the following type:

<<type [[Refs.t]]>>=
type t =
  | Head
  | Ref of refname
@
\t which functin can take either?

% used for? dumper?
<<signature [[Refs.string_of_ref]]>>=
val string_of_ref: t -> string
@
<<function [[Refs.string_of_ref]]>>=
let string_of_ref = function
  | Head -> "HEAD"
  | Ref x -> x
@

\subsection{Reference content}

Most references contain the SHA1 hexadecimal hash of a commit, but 
they can also contain the name of another reference:
\l actually type below use Commit.hash, so more consistent, but on disk its hexa

<<type [[Refs.ref_content]]>>=
type ref_content =
  (* the final value when follow all the pointers *)
  | Hash of Commit.hash
  (* pointer (may contain sha1 or another pointer again) *)
  | OtherRef of refname
@
%crossref: Commit.hash (said in text)


By default, [[HEAD]] points to another reference:

<<signature [[Refs.default_head_content]]>>=
val default_head_content: ref_content
@
<<constant [[Refs.default_head_content]]>>=
let default_head_content = 
  OtherRef "refs/heads/master"
@

% follow() later.

\subsection{Reference store}
%similar to Object store, indeed .git/ is mostly objects and refs (and index)

%trans:
Similar to the objects in Section~\ref{sec:object-store-function}
with [<Repository.hexsha_to_filename()>], the function below computes
the path of a reference:

<<function [[Repository.ref_to_filename]]>>=
let ref_to_filename r aref =
  match aref with
  | Refs.Head -> r.dotgit / "HEAD"
  (* less: win32: should actually replace '/' in name *)
  | Refs.Ref name -> r.dotgit / name
@


\subsection{Objectish references}

Many commands of Git requires a commit as a parameter, for example
[[git checkout]].
It is convenient for the user to be able to specify a commit either 
through its hexadecimal SHA1, or 
through the name of a branch, or
through a reference,
hence the type below:

<<type [[Repository.objectish]]>>=
(* todo: handle ^ like HEAD^, so need more complex objectish parser *)
type objectish =
  | ObjByRef of Refs.t
  | ObjByHex of Hexsha.t
  | ObjByBranch of string
  <<[[Repository.objectish]] cases>>
@
\l branch is shorter name than Refs.
%crossref: Hexsha.t, Refs.t

\ifallcode
<<[[Repository.objectish]] cases>>=
(* todo:  ObjByShortHex *)
@
\fi


\section{[[Index.t]]}
\label{sec:index}
% Staging area, Initially called DIRC, directory cache?

%trans:
The last important Git data structure is the index stored under
[[.git/index]].

<<function [[Repository.index_to_filename]]>>=
let index_to_filename r =
  r.dotgit / "index"
@


An index is a sorted list of entries (similar to [<Tree.t>])
where each entry associates to a path an SHA1 binary hash.

% Seen in Section X staging area. Marks. But in practice
% not set of files with marks. Instead full set of files
% and current blob SHA1.

% To know diff between working tree and HEAD.
%gitless: misfit paper says that you do not need staging area and that in fact
%  it causes misfits


<<type [[Index.t]]>>=
(* the entries are sorted (see compare_entries below) *)
type t = entry list
@

% flat list

<<type [[Index.entry]]>>=
(** The type for a Git index entry. *)
type entry = {
  (* relative path *)
  path  : Fpath.t;
  id    : Blob.hash;

  stats : stat_info;
}
@
%old: stage : int; (*?? *)

As opposed to [<Tree.entry>], an [<Index.entry>]
contains a path to a file (e.g., [[dir/bar.txt]]), not 
the {basename} of file or directory.
%crossref:
Indeed, the type of the [[id]] field above refers only to the SHA1 of a blob.
%%dup: even if not checked statically
%
Moreover, instead of a small set of file types, an index entry
contains the full \unix stat of a file (including its [[uid]] and [[gid]]):

% Here id can refer only to a Blob. No subtree like for Tree.
% An index is a flat list of files (sorted).

% Index.stats vs Tree.perm.

<<type [[Index.stat_info]]>>=
(** The type for file-system stat information. *)
type stat_info = {
  mode : mode;

  ctime: time;
  mtime: time;

  dev  : Int32.t;
  inode: Int32.t;

  uid  : Int32.t;
  gid  : Int32.t;

  size : Int32.t;
}
@
% all those info disappear once in Tree.entry.
\l useful dev/inode?

An index entry is specific to a user.
The goal of the index, which was initially called the {\em directory cache}
in the first version of Git,
is to access quickly information about a tracked file,
for example the timestamp of a file at the moment it was checkout.


<<type [[Index.mode]]>>=
and mode =
  (* no directory here *)
  | Normal
  | Exec
  <<[[Index.mode]] cases>>
@
\t note that no dir! flat files! FIGURE?


<<type [[Index.time]]>>=
(** The type for a time represented by its [lsb32] and [nsec] parts. *)
and time = {
  lsb32: Int32.t;
  nsec : Int32.t;
}
@
\t more than int64 here? nano second also in repo?

Most Git commands will need information from the index 
(e.g., [[git commit]]), or will modify the index (e.g., [[git add]]),
so the index is one of the fields of the [<Repository.t>] structure:

<<[[Repository.t]] index field>>=
mutable index: Index.t;
@

Opening a repository (with [<Repository.open_()>]),
will read the index from the repository. If there is no index file yet
(for example after [[git init]] and before the first [[git add]]),
then [[ocamlgit]] uses an empty index thanks to the constant below:

<<signature [[Index.empty]]>>=
val empty: t
@
<<constant [[Index.empty]]>>=
let empty = []
@

The function below helps to build an index entry from its subelements:

<<signature [[Index.mk_entry]]>>=
val mk_entry: Fpath.t -> Sha1.t -> Unix.stats -> entry
@
<<function [[Index.mk_entry]]>>=
let mk_entry relpath sha stats =
  { path = relpath;
    id = sha;
    stats = stat_info_of_lstats stats;
  }
@
%old:    stage = 0; (* ?? *)


<<signature [[Index.stat_info_of_lstats]]>>=
val stat_info_of_lstats: Unix.stats -> stat_info
@
<<function [[Index.stat_info_of_lstats]]>>=
let stat_info_of_lstats stats = 
    { ctime = { lsb32 = Int32.of_float stats.Unix.st_ctime; nsec = 0l };
      mtime = { lsb32 = Int32.of_float stats.Unix.st_mtime; nsec = 0l };
      dev = Int32.of_int stats.Unix.st_dev;
      inode = Int32.of_int stats.Unix.st_ino;
      mode = 
        (match stats.Unix.st_kind, stats.Unix.st_perm with
        | Unix.S_REG, p -> 
          if p land 0o100 = 0o100 
          then Exec 
          else Normal
        <<[[Index.stat_info_of_lstats()]] match kind and perm cases>>
        | _ -> failwith ("unsupported file type")
        );
      uid = Int32.of_int stats.Unix.st_uid;
      gid = Int32.of_int stats.Unix.st_gid;
      size = Int32.of_int stats.Unix.st_size;
    }
@
\l nsec is 01? OCaml API limitations?


%\section{Pack files}

% pack objects, pack refs, pack-idx.
% Compression, delta.
% Adv topics, but referenced many times (especially in Networking chapter).

%\section{Networking}

% for git://, ssh://, but also for local.
% Abstracted behind Client interface.
% Will not see commands before chapter X.

%\subsection{[[Client.t]]}

% Will see Client_local.mk_client later and match url cases later too.

% \subsection{[[Server.t]]}



\chapter{Reading from a Repository}
\label{chap:reading}
\t should enforce that read every bytes

%trans:
Now that you know the types of the core data structures and how
they are represented in memory, we can look at the format of
those data structures on the disk. In this chapter, I will
describe the code that reads those data structures from the disk,
with the code of 
[<Repository.read_obj()>], 
[<Repository.read_ref()>], and 
[<Repository.read_index()>].
%
The next chapter will describe the code that writes those data 
structures on the disk.

% Saw init, does not create objects, just create dirs.
% Create also index. Will see later commands adding
% objects and commands reading those objects. 
% This chapter focus on all reading API.

%ocaml: all of this could be just Marshall.from_string

\section{Objects}
\t not called? no [<Repository.read_obj()>]

% repo * sha -> path -> (channel -> IO.input) -> decompress -> deserialize

% FIGURE with 3 rectangles (one for blob, one for tree, one for commit),
% and then header with "blob "\x00, len, and then compressed inner rectangle 
% and inside the content, possibly with fields and values.

<<signature [[Repository.read_obj]]>>=
val read_obj: t -> Sha1.t -> Objects.t
@
<<function [[Repository.read_obj]]>>=
let read_obj r h =
  (* todo: look for packed obj *)
  let path = h |> Hexsha.of_sha |> hexsha_to_filename r in
  path |> UChan.with_open_in (fun (ch : Chan.i) ->
    (* less: check read everything from channel? *)
    (* todo: check if sha consistent? *)
    ch.ic |> IO.input_channel |> Compression.decompress |> Objects.read
  )
@
\l loose vs pack objects

% when reading no need lock, so simply with_file_in.


<<signature [[Objects.read]]>>=
(* assumes input is in decompressed form *)
val read: IO.input -> t
@
<<function [[Objects.read]]>>=
let read ch =
  let str = IO_.read_string_and_stop_char ch ' ' in
  let n = IO_.read_int_and_nullbyte ch in
  let raw = IO.really_nread ch n in
  (* less: assert finished ch? use IO.pos_in? *)
  let ch2 = IO.input_bytes raw in
  (* less: just reuse ch so avoid use of intermediate strings? *)
  match str with
  <<[[Objects.read()]] match str cases>>
  (* less: assert finished ch2? *)
  | str -> failwith (spf "Objects.read: invalid header: %s" str)
@

\subsection{Decompression}

<<signature [[Compression.decompress]]>>=
val decompress: 
  IO.input -> IO.input
@
<<function [[Compression.decompress]]>>=
let decompress ch = 
  Unzip.inflate ch
@
% See appendix for Unzip.inflate().



\subsection{Reading a blob}
\t called? no [<Blob.read()>]?


<<[[Objects.read()]] match str cases>>=
| "blob"   -> Blob   (Blob.read ch2)
@
<<signature [[Blob.read]]>>=
(* assumes have already read the 'blob <size>\000' header from unzipped input *)
val read: IO.input -> t
@
<<function [[Blob.read]]>>=
let read ch =
  IO.read_all ch
@


<<signature [[Repository.read_blob]]>>=
val read_blob: t -> Sha1.t -> Blob.t
@
<<function [[Repository.read_blob]]>>=
let read_blob r h =
  match read_obj r h with
  | Objects.Blob x -> x
  | _ -> failwith "read_blob: was expecting a blob"
@

\subsection{Reading a tree}
\t no [<Tree.read()>] ?

<<[[Objects.read()]] match str cases>>=
| "tree"   -> Tree   (Tree.read ch2)
@

<<signature [[Tree.read]]>>=
(* assumes have already read the 'tree <size>\000' header from unzipped input *)
val read: IO.input -> t
@

<<function [[Tree.read]]>>=
let read ch =
  let rec aux acc =
    try 
      (* todo: how diffentiate no more input from wrong input ?
       * pass size ch and use IO.pos_in ?
       *)
      let e = read_entry ch in
      aux (e::acc)
    with IO.No_more_input ->
      List.rev acc
  in
  aux []
@

<<function [[Tree.read_entry]]>>=
(* todo: should transform some No_more_input exn in something bad,
 * on first one it's ok, but after it means incomplete entry.
 *)
let read_entry ch =
  let perm = IO_.read_string_and_stop_char ch ' ' in
  (* todo: handle escape char in filenames? encode/decode *)
  let name = IO_.read_string_and_stop_char ch '\000' in
  let hash = Sha1.read ch in
  { perm = perm_of_string perm; name = name; id = hash }
@

<<signature [[Sha1.read]]>>=
val read: IO.input -> t
@
<<function [[Sha1.read]]>>=
let read ch =
  let s = IO.really_nread_string ch 20 in
  assert (is_sha s);
  s
@

<<function [[Tree.perm_of_string]]>>=
let perm_of_string = function
  | "44"
  | "100644" -> Normal
  | "100755" -> Exec
  | "120000" -> Link
  | "40000"  -> Dir
  <<[[Tree.perm_of_string()]] match str cases>>
  | x        -> failwith (spf "Tree.perm_of_string: %s is not a valid perm." x)
@


<<signature [[Repository.read_tree]]>>=
val read_tree: t -> Sha1.t -> Tree.t
@
<<function [[Repository.read_tree]]>>=
let read_tree r h =
  match read_obj r h with
  | Objects.Tree x -> x
  | _ -> failwith "read_tree: was expecting a tree"
@

\subsection{Reading a commit}
\t no [<Commit.read()>]?

<<[[Objects.read()]] match str cases>>=
| "commit" -> Commit (Commit.read ch2)
@

<<signature [[Commit.read]]>>=
(* assumes have already read the 'commit <size>\000' hdr from unzipped input *)
val read: IO.input -> t
@

<<function [[Commit.read]]>>=
let read ch =
  let tree = 
    IO_.read_key_space_value_newline ch "tree" Hexsha.read in
  (* todo: read "parent" or "author", because first commit has no parent *)
  let parents, author = 
    let rec loop parents =
      let str = IO_.read_string_and_stop_char ch ' ' in
      match str with
      | "parent" -> 
        let v = Hexsha.read ch in
        let c = IO.read ch in
        if c <> '\n'
        then failwith "Commit.read: missing newline after parent";
        loop (v::parents)
      | "author" ->
        let v = User.read ch in
        let c = IO.read ch in
        if c <> '\n'
        then failwith "Commit.read: missing newline after author";
        List.rev parents, v
      | _ -> failwith (spf "Commit.read: was expecting parent or author not %s"
                         str)
    in
    loop []
  in
  let committer = 
    IO_.read_key_space_value_newline ch "committer" User.read in
  let c = IO.read ch in
  if c <> '\n'
  then failwith "Commit.read: missing newline before message";
  let msg = IO.read_all ch in
  { tree = Hexsha.to_sha tree; 
    parents = parents |> List.map Hexsha.to_sha; 
    author = author; committer = committer;
    message = msg;
  }
@

%crossref: Hexsha.read
% As opposed to Tree, the Commit contains sha in Hexsha form
<<signature [[Hexsha.read]]>>=
val read: IO.input -> t
@
<<function [[Hexsha.read]]>>=
let read ch =
  let s = IO.really_nread_string ch 40 in
  assert (is_hexsha s);
  s
@

%crossref: Hexsha.to_sha
% but in core DS only Sha1.t, so convert


<<signature [[User.read]]>>=
val read: IO.input -> t
@

<<function [[User.read]]>>=
let read ch =
  let name = IO_.read_string_and_stop_char ch '<' in
  let email = IO_.read_string_and_stop_char ch '>' in
  let c = IO.read ch in
  if c <> ' ' then failwith "User.read: wrong format, missing space";

  let seconds = IO_.read_string_and_stop_char ch ' ' in
  let sign = IO.read ch in
  let hours = IO.nread_string ch 2 in
  let mins = IO.nread_string ch 2 in
  (* stricter: *)
  if int_of_string mins <> 0
  then failwith "User.read: timezeone with minutes not supported";

  { name = String.sub name 0 (String.length name - 1);
    email = email;
    date = (Int64.of_string seconds, (sign_of_char sign) (int_of_string hours));
  }
@

<<function [[User.sign_of_char]]>>=
let sign_of_char = function
  | '+' -> (fun x -> x)
  | '-' -> (fun x -> - x)
  | c -> failwith (spf "User.sign_of_string: not a sign, got %c" c)
@

<<signature [[Repository.read_commit]]>>=
val read_commit: t -> Sha1.t -> Commit.t
@
<<function [[Repository.read_commit]]>>=
let read_commit r h =
  match read_obj r h with
  | Objects.Commit x -> x
  | _ -> failwith "read_commit: was expecting a commit"
@

%\section{[[git show]]}
%here?


\section{References}

References use a simpler format, and are stored in {plain text}.

<<signature [[Repository.read_ref]]>>=
val read_ref: t -> Refs.t -> Refs.ref_content
@
<<function [[Repository.read_ref]]>>=
let read_ref r aref =
  (* less: packed refs *)
  let file = ref_to_filename r aref in
  file |> UChan.with_open_in (fun (ch : Chan.i) ->
    ch.ic |> IO.input_channel |> Refs.read
  )
@
\l loose vs pack refs

<<signature [[Refs.read]]>>=
val read: IO.input -> ref_content
@
<<function [[Refs.read]]>>=
let read ch =
  let str = IO.read_all ch in
  (* less: check finish by newline? *)
  match str with
  | _ when str =~ "^ref: \\(.*\\)$" -> OtherRef (Regexp_.matched1 str)
  | _ -> Hash (str |> IO.input_string |> Hexsha.read |> Hexsha.to_sha)
@
%$
%crossref: Regexp_matched1 in appendix

Most of the time, you want to follow a reference until you
get an SHA1 hash.

% useful function, used at many places (not just read_objectish)
<<signature [[Repository.follow_ref]]>>=
val follow_ref: t -> Refs.t -> Refs.t list * Commit.hash option
@
\t type return list of refs on ``path''

<<function [[Repository.follow_ref]]>>=
let rec follow_ref r aref =
  (* less: check if depth > 5? *)
  try (
  let content = read_ref r aref in
  match content with
  | Refs.Hash sha -> [aref], Some sha
  | Refs.OtherRef refname ->
    let (xs, shaopt) = follow_ref r (Refs.Ref refname) in
    aref::xs, shaopt
  ) 
  (* inexistent ref file, can happen at the beginning when have .git/HEAD
   * pointing to an inexistent .git/refs/heads/master
   *)
  with Sys_error _ (* no such file or directory *) -> [aref], None
@

% In some code we assume there is one, otherwise would be internal error
\l but should still be fault tolerant and have nice error msg?
<<signature [[Repository.follow_ref_some]]>>=
val follow_ref_some: t -> Refs.t -> Commit.hash
@
<<function [[Repository.follow_ref_some]]>>=
let follow_ref_some r aref =
  match follow_ref r aref |> snd with
  | Some sha -> sha
  | None -> failwith (spf "could not follow %s" (Refs.string_of_ref aref))
@



%\section{Objectish}

<<signature [[Repository.read_objectish]]>>=
val read_objectish: t -> objectish -> Sha1.t * Objects.t
@
<<function [[Repository.read_objectish]]>>=
let rec read_objectish r objectish =
  match objectish with
  | ObjByRef aref -> 
    (match follow_ref r aref |> snd with
    | None -> failwith (spf "could not resolve %s" (Refs.string_of_ref aref))
    | Some sha -> 
      sha, read_obj r sha
    )
  | ObjByHex hexsha ->
    let sha = Hexsha.to_sha hexsha in
    sha, read_obj r sha
  | ObjByBranch str ->
    read_objectish r (ObjByRef (Refs.Ref ("refs/heads/" ^ str)))
@



\section{Index}

% flat list.
% fast so not compressed.

<<signature [[Repository.read_index]]>>=
val read_index: t -> Index.t
@
<<function [[Repository.read_index]]>>=
let read_index r =
  r.index
@
% initialized when open_ a repo (possibly to Index.empty if no index file)

<<signature [[Index.read]]>>=
val read: IO.input -> t
@
<<function [[Index.read]]>>=
let read ch =
  let header = IO.really_nread_string ch 4 in
  if header <> "DIRC"
  then failwith "Index.read: expecting DIRC header";
  let version = IO.BigEndian.read_i32 ch in
  if version <> 2
  then failwith "Index.read: expecting version 2";
  let entries = read_entries ch in
  (* todo: read_extensions but need know when reach last 20 bytes *)
  (* todo: check hash correctly stored in last 20 bytes *)
  entries
@

<<function [[Index.read_entries]]>>=
let read_entries ch =
  let n = IO.BigEndian.read_i32 ch in
  let rec loop acc n =
    if n = 0 
    then List.rev acc
    else
      let entry = read_entry ch in
      loop (entry :: acc) (n - 1) in
  loop [] n
@

<<function [[Index.read_entry]]>>=
let read_entry (ch : IO.input) : entry =
  let stats = read_stat_info ch in
  let id = Sha1.read ch in
  let stage, len =
    let i = IO.BigEndian.read_ui16 ch in
    (i land 0x3000) lsr 12,
    (i land 0x0FFF)
  in
  if (stage <> 0)
  then failwith (spf "stage is not 0: %d" stage);
  let path = IO.really_nread_string ch len in
  let c = IO.read ch in
  if c <> '\000'
  then failwith "Index.read_entry: expecting null char after name";
  let len = 63 + String.length path in
  let pad = 
    match len mod 8 with
    | 0 -> 0
    | n -> 8-n 
  in
  let _zeros = IO.really_nread ch pad in
  (* less: assert zeros *)
  { stats = stats; id = id; path = Fpath.v path }
@
%old: was using stage

<<function [[Index.read_stat_info]]>>=
let read_stat_info ch =
  let ctime = read_time ch in
  let mtime = read_time ch in
  (* less: unsigned again *)
  let dev = (*IO.BigEndian.*)read_real_i32 ch in
  let inode = (*IO.BigEndian.*)read_real_i32 ch in
  let mode = read_mode ch in
  let uid = (*IO.BigEndian.*)read_real_i32 ch in
  let gid = (*IO.BigEndian.*)read_real_i32 ch in
  let size = (*IO.BigEndian.*)read_real_i32 ch in
  { mtime = mtime; ctime = ctime; dev = dev; inode = inode; mode = mode; uid = uid; gid = gid; size = size }
@


<<function [[Index.read_time]]>>=
let read_time ch =
  (* less: unsigned actually *)
  let lsb32 = (*IO.BigEndian.*)read_real_i32 ch in
  let nsec = (*IO.BigEndian.*)read_real_i32 ch in
  { lsb32 = lsb32; nsec = nsec }
@

<<function [[Index.read_mode]]>>=
let read_mode ch =
  let _zero = IO.BigEndian.read_ui16 ch in
  let n = IO.BigEndian.read_ui16 ch in
  match n lsr 12 with
  | 0b1010 -> Link
  <<[[Index.read_mode()]] match [[n lsr 12]] cases>>
  | 0b1000 ->
    (match n land 0x1FF with
    | 0o755 -> Exec
    | 0o644 -> Normal
    | d     -> failwith (spf "Index.mode: invalid permission (%d)" d)
    )
  | m -> failwith (spf "Index.mode: invalid (%d)" m)
@


\chapter{Writing to a Repository}
\label{chap:writing}

In this chapter, you will see the code of 
[<Repository.add_obj()>], 
[<Repository.write_ref()>], and
[<Repository.write_index()>].
%
Those functions just do the reverse operations of functions
you have seen in Chapter~\ref{chap:reading}.
\l dual.

%ocaml: all of this could be just Marshall.to_string

\section{Objects}

<<signature [[Repository.add_obj]]>>=
val add_obj: t -> Objects.t -> Sha1.t
@
<<function [[Repository.add_obj]]>>=
let add_obj r obj =
  let bytes = 
    IO.output_bytes () |> IO_.with_close_out (Objects.write obj) in
  let sha = Sha1.sha1 (Bytes.to_string bytes) in
  let hexsha = Hexsha.of_sha sha in
  let file = hexsha_to_filename r hexsha in
  <<[[Repository.add_obj()]] create directory if it does not exist>>
  if (Sys.file_exists !!file)
  then sha (* deduplication! nothing to write, can share objects *)
  else begin
    file |> with_file_out_with_lock (fun ch ->
      let ic = IO.input_bytes bytes in
      let oc = IO.output_channel ch in
      Compression.compress ic oc;
      IO.close_out oc;
    );
    sha
  end
@
%old:  let dir = hexsha_to_dirname r hexsha in

%crossref: Hexsha.of_sha again hexsha_to_filename

<<[[Repository.add_obj()]] create directory if it does not exist>>=
let dir = Filename.dirname !!file in
if not (Sys.file_exists dir)
then Unix.mkdir dir dirperm;
@

% should warn if add obj already there?
% No! deduplication! if you add a file that hash to content of already
% existing file, then great

%crossref: with_file_out_with_lock
\t with_file_out_with_lock later

<<signature [[Objects.write]]>>=
(* will not compress, will return unserialized content for sha1 computation *)
val write: t -> bytes IO.output -> unit
@
<<function [[Objects.write]]>>=
let write obj ch =
  let body = 
    IO.output_bytes () |> IO_.with_close_out (fun ch ->
      match obj with
      | Blob x   -> Blob.write x ch
      | Commit x -> Commit.write x ch
      | Tree x   -> Tree.write x ch
      <<[[Objects.write()]] match obj cases>>
    )
  in
  let header = 
    spf "%s %d\000"
      (match obj with
      | Blob _   -> "blob"
      | Commit _ -> "commit"
      | Tree  _  ->  "tree"
      <<[[Objects.write()]] return header, match obj cases>>
      ) 
      (Bytes.length body)
  in
  IO.nwrite_string ch header;
  IO.nwrite ch body
@



% because when write object, write its size.


\subsection{Compression}

<<signature [[Compression.compress]]>>=
val compress: 
  IO.input -> 'a IO.output -> unit
@
<<function [[Compression.compress]]>>=
let compress ic oc =
  Zlib.compress 
    (fun buf -> 
      try IO.input ic buf 0 (Bytes.length buf)
      with IO.No_more_input -> 0
    )
    (fun buf len -> 
      IO.output oc buf 0 len |> ignore)
@
% See appendix for Zlib.compress

% So bench? what overhead over working copy uses git to
% store all past versions?

\subsection{Locking}
\label{sec:lock-writing-file}

% Locking here is different from lock on files.
% Concurrent updates to same .git file are not permitted
% (anyway less a pb with git because objects are immutable,
% but still need to modify reference files! especially HEAD)

<<function [[Repository.with_file_out_with_lock]]>>=
(* todo: see code of _Gitfile.__init__ O_EXCL ... *)
let with_file_out_with_lock f (file : Fpath.t) =
  (* todo: create .lock file and then rename *)
  UChan.with_open_out (fun (chan : Chan.o) -> f chan.oc) file
@
% but really need that for objects?


\subsection{Writing a blob}

<<signature [[Blob.write]]>>=
(* does not write the header, does not compress *)
val write: t -> bytes IO.output -> unit
@
<<function [[Blob.write]]>>=
let write blob ch =
  IO.nwrite_string ch blob
@


\subsection{Writing a tree}
\t no [<Tree.write()>]

<<signature [[Tree.write]]>>=
(* does not write the header, does not compress *)
val write: t -> bytes IO.output -> unit
@
<<function [[Tree.write]]>>=
let write t ch =
  t |> List.iter (write_entry ch)
@

<<function [[Tree.write_entry]]>>=
let write_entry ch e =
  IO.nwrite_string ch (string_of_perm e.perm);
  IO.write ch ' ';
  (* todo: handle escape char in filenames? encode/decode *)
  IO.nwrite_string ch e.name;
  IO.write ch '\000';
  Sha1.write ch e.id
@

<<signature [[Sha1.write]]>>=
val write: 'a IO.output -> t -> unit
@
<<function [[Sha1.write]]>>=
let write ch x =
  IO.nwrite_string ch x
@

<<function [[Tree.string_of_perm]]>>=
let string_of_perm = function
  | Normal -> "100644"
  | Exec   -> "100755"
  | Link   -> "120000"
  | Dir    -> "40000"
  <<[[Tree.string_of_perm()]] match perm cases>>
@


\subsection{Writing a commit}
\t no [<Commit.write()>]?

<<signature [[Commit.write]]>>=
(* does not write the header, does not compress *)
val write: t -> 'a IO.output -> unit
@
<<function [[Commit.write]]>>=
let write commit ch =
  IO.nwrite_string ch "tree ";
  Hexsha.write ch (Hexsha.of_sha commit.tree);
  IO.write ch '\n';
  commit.parents |> List.iter (fun parent ->
    IO.nwrite_string ch "parent ";
    Hexsha.write ch (Hexsha.of_sha parent);
    IO.write ch '\n';
  );
  IO.nwrite_string ch "author ";
  User.write ch commit.author;
  IO.write ch '\n';
  IO.nwrite_string ch "committer ";
  User.write ch commit.committer;
  IO.write ch '\n';

  IO.write ch '\n';
  IO.nwrite_string ch commit.message
@
%crossref: Hexsha.write, Hexsha.of_sha

<<signature [[Hexsha.write]]>>=
val write: 'a IO.output -> t -> unit
@
<<function [[Hexsha.write]]>>=
let write ch x =
  IO.nwrite_string ch x
@

<<signature [[User.write]]>>=
val write: 'a IO.output -> t -> unit
@
<<function [[User.write]]>>=
let write ch user =
  IO.nwrite_string ch (spf "%s <%s> " user.name user.email);
  write_date ch user.date
@

<<function [[User.write_date]]>>=
let write_date ch (date, tz) =
  IO.nwrite_string ch (Int64.to_string date);
  IO.write ch ' ';
  IO.nwrite_string ch (spf "%c%02d%02d" (char_of_sign tz) (abs tz) 0)
@

\section{References}

<<signature [[Repository.write_ref]]>>=
val write_ref: t -> Refs.t -> Refs.ref_content -> unit
@
<<function [[Repository.write_ref]]>>=
(* low-level *)
let write_ref r aref content =
  let file = ref_to_filename r aref in
  file |> with_file_out_with_lock (fun ch ->
    ch |> IO.output_channel |> IO_.with_close_out (Refs.write content))
@
\l check_refname? git-check-ref-format
%    [1] http://www.kernel.org/pub/software/scm/git/docs/git-check-ref-format.html
%crossref: with_file_out_with_lock

<<signature [[Refs.write]]>>=
val write: ref_content -> unit IO.output -> unit
@
<<function [[Refs.write]]>>=
let write content ch =
  match content with
  | Hash h -> 
    IO.nwrite_string ch (Hexsha.of_sha h ^ "\n")
  | OtherRef name ->
    IO.nwrite_string ch ("ref: " ^ name ^ "\n")
@



\section{Index}

% used in init, with empty index.

<<signature [[Repository.write_index]]>>=
val write_index: t -> unit
@
<<function [[Repository.write_index]]>>=
let write_index r =
  let path = index_to_filename r in
  path |> with_file_out_with_lock (fun ch ->
    ch |> IO.output_channel |> IO_.with_close_out (Index.write r.index)
  )
@
%crossref: with_file_out_with_lock


<<signature [[Index.write]]>>=
(* will write the header, and sha checksum at the end *)
val write: t -> unit IO.output -> unit
@
<<function [[Index.write]]>>=
let write idx ch =
  let n = List.length idx in
  let body =
    IO.output_bytes () |> IO_.with_close_out (fun ch ->
      IO.nwrite_string ch "DIRC";
      IO.BigEndian.write_i32 ch 2;
      IO.BigEndian.write_i32 ch n;
      idx |> List.iter (write_entry ch)
    )
  in
  let sha = Sha1.sha1 (Bytes.to_string body) in
  IO.nwrite ch body;
  Sha1.write ch sha
@

<<function [[Index.write_entry]]>>=
let write_entry ch (e : entry) =
  write_stat_info ch e.stats;
  Sha1.write ch e.id;
  let flags = (0 lsl 12 + String.length !!(e.path)) land 0x3FFF in
  IO.BigEndian.write_ui16 ch flags;
  IO.nwrite_string ch !!(e.path);
  let len = 63 + String.length !!(e.path) in
  let pad = 
    match len mod 8 with
    | 0 -> 0
    | n -> 8-n 
  in
  IO.nwrite ch (Bytes.make pad '\000');
  IO.write ch '\000'
@
%old: was using e.stage

<<function [[Index.write_stat_info]]>>=
let write_stat_info ch stats =
  write_time ch stats.ctime;
  write_time ch stats.mtime;
  (*IO.BigEndian.*)write_real_i32 ch stats.dev;
  (*IO.BigEndian.*)write_real_i32 ch stats.inode;
  write_mode ch stats.mode;
  (*IO.BigEndian.*)write_real_i32 ch stats.uid;
  (*IO.BigEndian.*)write_real_i32 ch stats.gid;
  (*IO.BigEndian.*)write_real_i32 ch stats.size;
  ()
@


<<function [[Index.write_mode]]>>=
let write_mode ch mode =
  IO.BigEndian.write_ui16 ch 0;
  let n = 
    match mode with
    | Exec    -> 0b1000__000__111_101_101
    | Normal  -> 0b1000__000__110_100_100
    | Link    -> 0b1010__000__000_000_000
    <<[[Index.write_mode()]] match mode cases>>
  in
  IO.BigEndian.write_ui16 ch n
@


<<function [[Index.write_time]]>>=
let write_time ch time =
  (*IO.BigEndian.*)write_real_i32 ch time.lsb32;
  (*IO.BigEndian.*)write_real_i32 ch time.nsec
@



\chapter{Main Functions}
\label{chap:main}

%trans: %dup: Assembler.nw
I now switch from the bottom-up approach started in Chapter~\ref{chap:core-ds}
to a top-down approach, starting in this chapter with the
main entry point of [[ocamlgit]]: [<Main.main()>].
%
The next chapters will then describe the code of the main Git commands.

%toc: before main(), important type.
% git works with commands, git cmd args
% where each command have own options and actions.

\section{Main commands}
\label{sec:main-commands}

[[ocamlgit]] is a single program, but it consists really of a set
of independent mini-programs: the different Git commands.
%
Each of those mini-programs, 
like [[ocamlgit]] itself, have
a name,
some usage documentation,
and a set of command-line options, hence the following type:

%\subsection{[[Cmd_.t]]}

<<type [[Cmd_.t]]>>=
type t = {
  name: string;
  usage: string;
  options: (Arg.key * Arg.spec * Arg.doc) list;

  (* the command! *)
  f: string list -> unit;
  (* less: man: when do git -help get short help, and with --help man page *)
}
@
%alt: use of 'Term.()' and '$' to not require globals for flags (src: ocaml-git)
% but not worth it. With split cmd_xxx.ml can have different globals in
% those different files.

%cvs: the one who introduced cvs xxx style instead of many programs? 
% (ci/co/...)

The last field of [<Cmd_.t>] is the {callback} function to call
to execute the Git command. It takes as a parameter the list
of command-line arguments that were not flags.

%\subsection{[[Cmds.main_commands]]}

The constant below contains the list of all the main Git commands. 
Each module defines its own [[cmd]] constant:

<<constant [[Cmds.main_commands]]>>=
let main_commands = [
  (* creating *)
  Cmd_init.cmd;
  Cmd_add.cmd;
  Cmd_rm.cmd;
  Cmd_commit.cmd;

  (* branching *)
  Cmd_branch.cmd;
  Cmd_checkout.cmd;
  Cmd_reset.cmd;
  
  (* inspecting *)
  Cmd_show.cmd;
  Cmd_diff.cmd;
  Cmd_log.cmd;
  Cmd_status.cmd;

  (* networking *)
  Cmd_pull.cmd;
  Cmd_push.cmd;
  Cmd_clone.cmd;
]
@
%todo: no merge 
%less: rebase

%chunks:
I will present gradually in the rest of the document the code
of all those commands.

% There is also extra_commands (for debugging) and Cmd_help.cmd (for help).

\section{[[Main.main()]]}

%trans:
I can finally present the entry point of [[ocamlgit]], which will
dispatch one of the Git commands.

<<toplevel [[Main._1]]>>=
let _ =
  main ()
@

<<function [[Main.main]]>>=
let main () =
  <<[[Main.main()]] GC settings>>
  <<[[Main.main()]] sanity check arguments>>
  else begin
    let cmd = 
      try 
        commands |> List.find (fun cmd -> cmd.Cmd_.name = Sys.argv.(1))
      with Not_found ->
        <<[[Main.main()]] print usage and exit>>
    in
    <<[[Main.main()]] execute [[cmd.f]]>>
  end
@


%old:
%<<constant Main.hcommands>>=
%let hcommands = 
%  commands |> List.map (fun cmd -> cmd.Cmd_.name, cmd) |> Hashtbl_.of_list
%@
% useless opti

The final list of commands below contains the main commands 
(see Section~\ref{sec:main-commands} above),
some extra commands to either help debug [[ocamlgit]] 
(see Appendix~\ref{chap:debugging-ocamlgit}) or to
provide advanced features (see Chapter~\ref{chap:advanced-commands}),
and the command to get help %, which I will present soon in
(see Section~\ref{sec:git-help}).

<<constant [[Main.commands]]>>=
let commands = List.flatten [
  Cmds.main_commands;
  Cmds.extra_commands;
  [Cmd_help.cmd];
]
@
%ocaml:
% Cmd_help reference itself main_commands, and ocaml forbids
% mutually recursive dependencies, so here it is.
% Extra is for git help vs git help --all?

%dup: Make.nw?
% Sanity check. obvious but necessary. will not comment

[[ocamlgit]] requires at least one argument: a Git command.
Thus, [[argv]] must contain at least two elements
(remember that [[argv.(0)]] contains the name of the program,
here [["ocamlgit"]]):


<<[[Main.main()]] sanity check arguments>>=
if Array.length Sys.argv < 2
then begin
  <<[[Main.main()]] print usage and exit>>
end
@
% git cmd xxx so at least 2.

<<[[Main.main()]] print usage and exit>>=
UConsole.print (usage ());
exit 1
@
\l split because used from 2 places
\l pr2?

<<function [[Main.usage]]>>=
let usage () =
  spf "usage: ocamlgit <%s> [options]"
    (String.concat "|" (commands |> List.map (fun cmd -> cmd.Cmd_.name)))
@
% See Section~{sec:git-command-line}


The code to sanity check arguments above is necessary but often obvious.
This is why I will usually not comment such code in the rest of this document.

% compute arguments and dispatch command callback.

Executing the command callback requires first to build a new
[[argv]] (without the leading [["ocamlgit"]]), to have a new
usage message specific to the command, and finally to process
the new [[argv]] to separate flags and options from the remaining
arguments of the command:

<<[[Main.main()]] execute [[cmd.f]]>>=
let argv = Array.sub Sys.argv 1 (Array.length Sys.argv -1) in
let usage_msg_cmd = spf "usage: %s %s%s"
  (Filename.basename Sys.argv.(0))
  cmd.Cmd_.name
  cmd.Cmd_.usage
in
let remaining_args = ref [] in
<<[[Main.main()]] parse [[argv]] for cmd options and [[remaining_args]]>>
(* finally! *)
try 
  cmd.Cmd_.f (List.rev !remaining_args)
with 
  | Cmd_.ShowUsage ->
    Arg.usage (Arg.align cmd.Cmd_.options) usage_msg_cmd;
    exit 1
@

The exception below will be used from command callbacks to indicate
that something was wrong with the command-line arguments:

<<exception [[Cmd_.ShowUsage]]>>=
(* Cmd_.f can raise ShowUsage. It will be catched by Main.main *)
exception ShowUsage
@

Processing the new [[argv]] is similar to what most OCaml programs do
and it involves the [[Arg]] module:


<<[[Main.main()]] parse [[argv]] for cmd options and [[remaining_args]]>>=
(try 
 (* todo: look if --help and factorize treatment of usage for subcmds *)
   Arg.parse_argv argv (Arg.align cmd.Cmd_.options) 
     (fun arg -> Stack_.push arg remaining_args) usage_msg_cmd;
 with Arg.Bad str | Arg.Help str->  
   prerr_string str;
   exit 1
);
@




\section{Getting help: [[git help]]}
\label{sec:git-help}

Here is the code of the first Git command, the command to get
help with [[git help]]:
% First command example, simple:

<<constant [[Cmd_help.list_extra]]>>=
let list_extra = ref false
@

<<constant [[Cmd_help.cmd]]>>=
let rec cmd = { Cmd_.
  name = "help";
  usage = "";
  options = ["-a", Arg.Set list_extra, " see all commands"];
  f = (fun _args ->
    let xs = 
      if !list_extra
      then Cmds.main_commands @ Cmds.extra_commands @ [cmd]
      else Cmds.main_commands
    in
    UConsole.print ("Available commands: ");
    xs |> List.iter (fun cmd ->
      UConsole.print (spf "  %s" cmd.Cmd_.name);
    );
  );
}
@
\l also git command --help later

%ocaml:
Note that this command references itself, 
hence the [[rec]] keyword above.
\l not a function but still rec
%crossref:
Moreover, this command also references [<Cmds.main_commands>];
this is why [<Cmd_help.cmd>] could not be part of the list
of main commands earlier in Section~\ref{sec:main-commands}
(OCaml does not allow mutually recursive modules).
\l actually it does, but weird extension, and not for toplevel module/files?

Here is the output of [[git help]]:
\begin{verbatim}
1 $ git help
Available commands: 
  init
  add
  rm
  commit
  branch
  checkout
  reset
  show
  diff
  log
  status
  pull
  push
  clone
\end{verbatim}



\chapter{Creating a Repository}
\label{chap:creating}
\n Initializing? reserved for 'creating empty', so would match only git init

In this chapter, we will explore the different ways to create
a Git repository.
\l Most common is create fresh repo, other is clone.

\section{Initializing a new repository: [[git init]]}
% Creating a fresh repository

The simplest way to create a new repository is to run
the command [[git init]] from a directory, as shown in
Section~\ref{sec:getting-started}.
%trans-dull:
Here is the code describing this command:

<<constant [[Cmd_init.cmd]]>>=
let cmd = { Cmd_.
  name = "init";
  usage = " [directory]";
  options = [
   <<[[Cmd_init.cmd]] command-line options>>
  ];
  f = (fun args ->
    match args with
    | []    -> Repository.init (Fpath.v ".")
    | [dir] -> Repository.init (Fpath.v dir)
    | _ -> raise Cmd_.ShowUsage
  );
}
@

%crossref: Cmd_.ShowUsage

\ifallcode
<<[[Cmd_init.cmd]] command-line options>>=
(* less: -bare, --quiet *)
@
\fi

As I explained in Section~\ref{sec:git-tutorial-init}, initializing
a fresh repository consists mainly in creating a directory
structure under [[.git/]], without any objects in it.

<<signature [[Repository.init]]>>=
val init: Fpath.t -> unit
@
<<function [[Repository.init]]>>=
let init (root : Fpath.t) =
  if not (Sys.file_exists !!root)
  then Unix.mkdir !!root dirperm;

  (* less: bare argument? so no .git/ prefix? *)
  let dirs = [
    ".git";
    ".git/objects";
    ".git/refs";
    ".git/refs/heads";
    ".git/refs/tags";
    ".git/refs/remote";
    ".git/refs/remote/origin";
    ".git/hooks";
    ".git/info";
  ] in
  dirs |> List.iter (fun dir ->
    (* less: exn if already there? *)
    Unix.mkdir !!(root / dir) dirperm;
  );
  <<[[Repository.init()]] create [[.git/HEAD]]>>

  (* less: config file, description, hooks, etc *)
  Sys.chdir !!root;
  let absolute = Sys.getcwd () |> Fpath.v in
  UConsole.print (spf "Initialized empty Git repository in %s" !!(absolute / ".git/"))
@


<<constant [[Repository.dirperm]]>>=
(* rwxr-x--- *)
let dirperm = 0o750
@

[[git init]] also creates the special reference [[HEAD]] stored
in [[.git/HEAD]], and initializes its content with
a reference to the master branch 
%crossref:
(see the content of [<Refs.default_head_content>]).


<<[[Repository.init()]] create [[.git/HEAD]]>>=
let r = {
  worktree = root;
  dotgit = root / ".git";
  index = Index.empty;
} in
add_ref_if_new r Refs.Head Refs.default_head_content |> ignore;
@
\l will see add_ref_if_new later.
%crossref: Index.empty

%crossref:
I will explain the code of [<Repository.add_ref_if_new()>] later
and why it has [[_if_new]] in its name.

%\subsection{Common directory}
% To abstract diff between bare and normal repository

%\subsection{Named files}

\section{Copying an existing repository: [[cp -r]]}

Another way to create a repository is to copy an existing
one with a simple command such as [[cp -r]].
\t well, can just do cp :) simple! DVCS power! distributed!
%
This is also an easy way to create a new branch, even
though it is not an optimal one (space and speed-wise).
\l can also use branch, see later.
You wull see a more efficient way to manage branches
in Chapter~\ref{chap:branching}.

\t actually at FB some people (Ola?) were prefering copy to
% branch cos git was not scaling enough when lots of files
% so switching branch was too slow (but doing cd /other/repo was fast)


\section{Cloning an existing repository: [[git clone]]}

%trans:
Using [[cp -r]] requires to have access to the original repository
through the filesystem, which usually limits yourself
to local repositories on your disk 
(unless you use a distributed filesystem such as NFS).
\l cite NFS? or plan9 import?
A more flexible way to copy an existing repository is to use
the command [[git clone]], which accepts a URL as an argument.
\n URL can be local too actually, even without file://
%
Here is the command to clone the repository containing the
code of [[ocamlgit]] itself:

%meta:
\begin{verbatim}
$ git clone http://github.com/aryx/plan9-ocaml
Cloning into 'plan9-ocaml'...
$ cd plan9-ocaml/version-control/
$ ls
IO_.ml            cmd_checkout.ml  diff.mli          refs.ml
...
\end{verbatim}
\n can also use https (default), but need ssl then?

Cloning a repository does not just copy it; it also keeps
a reference to the remote repository 
(in [[refs/remotes/origin/HEAD]]). This reference will allow
later to {\em push} and {\em pull} updates from the repository
(see Chapter~\ref{chap:exchanging}).

I will describe the code of [[git clone]] later in 
Section~\ref{sec:git-clone}, after I describe
the client/server architecture of Git and the code to
pack objects together in Chapter~\ref{chap:packing}.


%\section{Checking out a repository: [[git checkout]]}
% if cp -a just .git, then can checkout by doing git checkout.

%\section{Fast Import/Export}
%adv topics


\section{Opening a repository}

The Git commands in the following chapters all assume they
are run from an existing repository.
%
Here is the function to open a repository and get a
[<Repository.t>] record:

<<signature [[Repository.open_]]>>=
val open_: Fpath.t -> t
@
% not open cos conflict with ocaml keyword
<<function [[Repository.open_]]>>=
let open_ (root : Fpath.t) = 
  let path = root / ".git" in
  if Sys.file_exists !!path &&
     (Unix.stat !!path).Unix.st_kind = Unix.S_DIR
  then 
    { worktree = root;
      dotgit = path;
      <<[[Repository.open_()]] other fields settings>>
    }
  else failwith (spf "Not a git repository at %s" !!root)
@
%todo: bar repo, 
\l cant used index_to_filename cos no repo yet, sad.

As I explained in Section~\ref{sec:index}, most Git commands
will also need to read or write information in the index,
so opening a repository also reads its index:

<<[[Repository.open_()]] other fields settings>>=
index = 
  (if Sys.file_exists !!(path / "index")
   then 
    (path / "index") |> UChan.with_open_in (fun (ch : Chan.i) ->
      ch.ic |> IO.input_channel |> Index.read)
   else Index.empty
  );
@
%crossref: Index.empty

\ifallcode
<<[[Repository.open_()]] other fields settings>>=
(* less: grafts, hooks *)
@
\fi

% See appendix for IO.xxx, Common.with_file_in

%crossref:
I described before the code of [<Index.read()>] called above.


It is convenient for the user to be able to run a Git command
from anywhere inside the repository, not just from its root.
\l For example in Section~\ref{}, git add from dir1.
However, it is simpler, while implementing the code of the
different Git commands, to assume that every paths are
relative to the root of the repository.
Avoiding variation in data usually simplifies things.
Moreover, some data structures such as the index entries 
must contain relative paths.
%
The function below allows to satisfy both requirements
by converting any filenames given on the command-line
to relative filenames, and to find the root of the
repository:


% Most git commands can operate from the top dir of a object
% or any subdirectory. Convenient, git add foo.txt from
% any dir, no need go back to top.
% But internally simple have canonical representation of
% path and always use relative path to top dir.
% Enter find_root_... helper function used first in many commands.

<<signature [[Repository.find_dotgit_root_and_open]]>>=
val find_root_open_and_adjust_paths: 
 Fpath.t list -> t * Fpath.t list
@
<<function [[Repository.find_dotgit_root_and_open]]>>=
let find_root_open_and_adjust_paths (paths : Fpath.t list) : t * Fpath.t list = 
  (* todo: allow git from different location *)
  let r = open_ (Fpath.v ".") in
  (* todo: support also absolute paths and transform in relpaths *)
  let relpaths = paths |> List.map (fun path ->
    if Filename.is_relative !!path
    then 
      (* todo: may have to adjust if root was not pwd *)
      path
    else failwith (spf "TODO: Not a relative path: %s" !!path)
    )
  in
  r, relpaths
@
\t TODO implement flexible scheme



\chapter{Staging a Diff}
\label{chap:staging}

%trans:
Once you created a repository, you can 
add,
remove, 
modify, or
rename 
files in this repository, as explained in the following sections.
%
In Git, doing those modifications requires two steps:
first you stage your modification, and 
then you commit the modification
%dup: overview/git-concepts/staging-area
(which gives flexibility in the commit process, as explained 
in Section~\ref{sec:staging-area}).
%gitless: staging is not necessary.
% But if modified a b c and want different commits, then can!
% (can even use magit-status and pick each changes!)
This chapter is concerned only with the first part: the staging.
The next chapter will cover the commit.

\section{Adding files: [[git add]]}
% Adding and modifying

%trans-dull:
Here is the code of the command to add a file or set of files
to the staging area:

<<constant [[Cmd_add.cmd]]>>=
let cmd = { Cmd_.
  name = "add";
  usage = " <file>..."; (* less: pathspec? *)
  options = [
    <<[[Cmd_add.cmd]] command-line options>>
  ];
  f = (fun args ->
    match args with
    | [] -> Logs.app (fun m -> m "Nothing specified, nothing added.")
    | xs ->
      let r, relpaths = Repository.find_root_open_and_adjust_paths (Fpath_.of_strings xs) in
      (* less: support directories *)
      add r relpaths
  );
}
@

\ifallcode
<<[[Cmd_add.cmd]] command-line options>>=
(* todo: --interactive, --patch for picking, --force (if ignored) 
 * --all, 
 * --recursive
 *)
@
\fi

%dup: overview/hello.git/staging
Note that you must use [[git add]] both when adding a new file to
the repository and when adding a new version of a file that
was already in the repository.
%(also called a {tracked} file).
%
In some senses, Git does not care whether the file is new 
or not. In both cases, Git just adds the current version
of a file in the staging area.

Adding files to the staging area translates internally in adding
them to the index:

<<function [[Cmd_add.add]]>>=
let add r relpaths = 
  (* this will also add some blobs to the object store *)
  Repository.add_in_index r relpaths
@

% build a series of tree objects if different from last one?
% No, commit does that. Here we just add blobs.

% Note that git add is to add new file to repo but also
% to add existing modified file to the commit!

% if git add foo.txt, then modif, then git add other one
% then 2 objects (and one "stale", git gc can clean it)

\section{Creating a blob from a file}

Adding a set of files in the index consists simply in
iterating over those files, modifying the index, and
finally writing back the modified index on the disk:

<<signature [[Repository.add_in_index]]>>=
val add_in_index: t -> Fpath.t list -> unit
@

% create blob and add object! so 'git add' add object to repo.
% if git add again same file then old object is useless (git gc).

<<function [[Repository.add_in_index]]>>=
let add_in_index (r : t) (relpaths : Fpath.t list) : unit =
  <<[[Repository.add_in_index()]] sanity check [[relpaths]]>>
  relpaths |> List.iter (fun relpath ->
    <<[[Repository.add_in_index()]] adding [[relpath]]>>
  );
  write_index r
@
%old: was called stage() in dulwich
\l sanitize fs_path (win32)

%crossref:
I described before the code of [<Repository.write_index()>] called above.

<<[[Repository.add_in_index()]] sanity check [[relpaths]]>>=
assert (relpaths |> List.for_all (fun p -> Filename.is_relative !!p));
@

Adding a file in the index 
creates first a new blob object with the content of the added file.
Then, [[add_in_index()]] adds the blob to the object store, and finally
adds (or replaces) an entry in the index:

<<[[Repository.add_in_index()]] adding [[relpath]]>>=
let full_path = r.worktree // relpath in
let stat = 
  try Unix.lstat !!full_path 
  with Unix.Unix_error _ ->
    failwith (spf "Repository.add_in_index: %s does not exist anymore"
                !!relpath)
in
let blob = Objects.Blob (content_from_path_and_unix_stat full_path stat) in
let sha = add_obj r blob in
let entry = Index.mk_entry relpath sha stat in
r.index <- Index.add_entry r.index entry;
@

%crossref:
I described before the general function [<Repository.add_obj()>] called above,
and the specific code it uses to write a blob in [<Blob.write()>].
%crossref: Index.mk_entry (meh)

Note that the code above uses [[Unix.lstat()]], and not [[Unix.stat()]] 
to deal with symbolic links (see Section~\ref{sec:symlinks} for
more information on how Git handles symblic links).

Remember from Section~\ref{sec:index} that the index contains
sorted entries, so [[Index.add_entry()]] below must add the new entry
at the right place:

<<signature [[Index.add_entry]]>>=
val add_entry: t -> entry -> t
@
<<function [[Index.add_entry]]>>=
let rec add_entry idx entry =
  match idx with
  | [] -> [entry]
  | x::xs ->
    (match entry.path <=> x.path with
    | Greater -> x::(add_entry xs entry)
    (* replacing old entry, new version of tracked file  *)
    | Equal -> entry::xs
    (* new file (the entries are sorted, no need to go through xs) *)
    | Less -> entry::x::xs
    )
@
%crossref:
The [[<=>]] operator used above is not a standard OCaml operator.
It is inspired by a similar operator in Perl that compares
values. It returns 
[[Equal]] if both values are equal,
[[Sup]] if the first value is superior to the second one, or
[[Inf]] if it is inferior.
I show the code of [[<=>]] in Appendix~\ref{chap:utilities}.

<<function [[Repository.content_from_path_and_unix_stat]]>>=
let content_from_path_and_unix_stat (full_path : Fpath.t) (stat : Unix.stats) : string =
  match stat.Unix.st_kind with
  <<[[Repository.content_from_path_and_unix_stat()]] match kind cases>>
  | Unix.S_REG ->
    full_path |> UChan.with_open_in (fun (ch : Chan.i) ->
      ch.ic |> IO.input_channel |> IO.read_all
    )
  | _ -> failwith (spf "Repository.add_in_index: %s kind not handled" 
                     !!full_path)
@
\n not Blob.read here! even though same function called in the end.

% blob can be a symlink! git allows to store symlinks.

% Order of operation is important. Always in a consistent state.
% Will add index entry only if blob has been added! if failure after
% blob created, no pb!

\section{Removing files: [[git rm]]}

<<constant [[Cmd_rm.cmd]]>>=
let cmd = { Cmd_.
  name = "rm";
  usage = " [options] <file>...";
  options = [
    <<[[Cmd_rm.cmd]] command-line options>>
  ];
  f = (fun args ->
    match args with
    | [] -> raise Cmd_.ShowUsage
    | xs ->
      let r, relpaths = Repository.find_root_open_and_adjust_paths (Fpath_.of_strings xs) in
      rm r relpaths
  );
}
@

\ifallcode
<<[[Cmd_rm.cmd]] command-line options>>=
(* less: -f force, -r recursive, --quiet *)
@
\fi

The code for removing a file or set of files is even simpler. 
We just need to remove some entries from the index and write back the index.
%
Indeed, as you will see in Chapter~\ref{chap:committing}, committing
what was staged consists mainly in creating a set of tree objects
from the flat list of files in the index. 
%
If a file is not anymore in the index, then it will also not 
be part of any of those trees.


<<function [[Cmd_rm.rm]]>>=
let rm r relpaths =
  (* less: not super efficient, could use hashes to speedup things *)
  r.Repository.index <-
    relpaths |> List.fold_left (fun idx relpath ->
          (* todo: -f? remove also file *)
      Index.remove_entry idx relpath
    ) r.Repository.index;
  Repository.write_index r
@
%  (* removing is simpler than adding; no need to add blobs in
%   * the object store, so can just use functions from Index
%   *)

%crossref: Repository.write_index again

[[Index.remove_entry()]] just does the opposite
of [<Index.add_entry()>] in the previous section

<<signature [[Index.remove_entry]]>>=
val remove_entry: t -> Fpath.t -> t
@
<<function [[Index.remove_entry]]>>=
let rec remove_entry idx (name : Fpath.t) =
  match idx with
  | [] -> failwith (spf "The file %s is not in the index" !!name)
  | x::xs ->
    (match name <=> x.path with
    | Greater -> x::(remove_entry xs name)
    | Equal -> xs
    (* the entries are sorted *)
    | Less -> failwith (spf "The file %s is not in the index" !!name)
    )
@

% when rm, we just want to build from index a tree without
% this entry. Simple.

% Does not remove from working tree. Or need rm -f.
% (Otherwise will be listed as untracked, see Section~\ref{x}).

\section{Renaming files: [[git mv]]}

% huge debate. How to track rename of files and dirs.
%cvs: was terrible at renaming

%git: Just add and rm.
% Note that same sha1 when rename, because same content, so no space lost.

% See later how git handle remames in git log foo.txt, to try to
% infer renames.
% Sha1 can be used to quickly detect renames when explore history.
% See Section~{X}.





\chapter{Committing a Diff}
\label{chap:committing}

%trans:
In this chapter, you will see the second step of the commit process:
the commit itself, which will use what was staged in the previous chapter.
%toc: ?

\section{Committing the index: [[git commit]]}
\l snapshotting the index?

%trans-dull:
Here is the code describing the [[git commit]] command:

<<constant [[Cmd_commit.cmd]]>>=
let cmd = { Cmd_.
  name = "commit";
  usage = " [options]"; (* less: <pathspec>... *)
  options = [
    <<[[Cmd_commit.cmd]] command-line options>>
  ];
  f = (fun args ->
    match args with
    | [] -> 
      let r, _ = Repository.find_root_open_and_adjust_paths [] in
      <<[[Cmd_commit.cmd]] compute [[today]]>>
      <<[[Cmd_commit.cmd]] compute [[author]] user>>
      <<[[Cmd_commit.cmd]] compute [[committer]] user>>
      commit r author committer !message
    | _xs -> raise Cmd_.ShowUsage
  );
}
@
%old: was '<author> override author' but does not if no .gitconfig

\ifallcode
<<[[Cmd_commit.cmd]] command-line options>>=
(* less: commit mesg option: --file, --date, --signoff *)
(* less: commit content options: -a, --interactive, --patch *)
(* todo: --amend *)
@
\fi

[[git commit]] accepts a few flags from the command-line
to specify the commit message or author.
\t alternatives is EDITOR or config file
I will present those flags later in this chapter.
%
What matters for now is that in the end [[Cmd_commit.commit()]]
below will be called with the appropriate author, committer, and message.

<<function [[Cmd_commit.commit]]>>=
let commit r author committer message =
  (* todo: imitate git output
   *   [master 0b50159] xxx
   *   1 file changed, 0 insertions(+), 0 deletions(-)
   *   create mode 100644 foobar.txt
   *)
  (* todo: nothing to commit, working directory clean *)
  Repository.commit_index r author committer message
@

%dup: overview/???
As I mentioned previously, committing a Diff consists mainly
internally in transforming the current index in a set of tree objects
as well as a commit object as shown in Figure~\ref{fig:index-to-trees}.

<<signature [[Repository.commit_index]]>>=
val commit_index: 
  t -> User.t (* author *) -> User.t (* committer *) -> string (* msg *) -> unit
@

%crossref:
Most of the heavy work in the code below is done by
[<Index.trees_of_index()>], which I will present in the next section.
%crossref:
Some of the code below deals with commits that merge multiple branches,
which I will describe later in Section~\ref{sec:git-commit-merge}.

<<function [[Repository.commit_index]]>>=
let commit_index r author committer message =
  let aref = Refs.Head in
  let root_tree = Index.trees_of_index r.index 
    (fun t -> add_obj r (Objects.Tree t)) 
  in
  (* todo: execute pre-commit hook *)
  <<[[Repository.commit_index()]] read merge message if needed>>
  (* todo: execute commit-msg hook *)
  let commit = { Commit. parents = []; tree = root_tree; 
                 author = author; committer = committer; message = message } in

  let ok =
    match follow_ref r aref |> snd with
    | None ->
      (* first commit so refs/heads/master does not even exist yet *)
      let sha = add_obj r (Objects.Commit commit) in
      <<[[Repository.commit_index()]] add ref when first commit>>
    | Some old_head ->
      <<[[Repository.commit_index()]] set [[merge_heads]]>>
      let commit = { commit with Commit.parents = old_head :: merge_heads } in
      let sha = add_obj r (Objects.Commit commit) in
      <<[[Repository.commit_index()]] update ref when not first commit>>
  in
  if not ok
  then failwith (spf "%s changed during commit" (Refs.string_of_ref aref));
  (* todo: execute post-commit hook *)
  ()
@
%crossref: add_obj for Tree and Commits
\t explain why pass func instead of calling it from Index directly.
\t to avoid mutual recursive modules. 

\section{Computing the trees from an index}

The algorithm to transform an index in a set of trees operates in two steps:
\begin{enumerate}

\item The algorithm goes though all the files in the index to group them
by directories while populating the local hashtable [[dirs]]

\item The algorithm builds tree objects by going recursively through
the hashtable [[dirs]] and returns the SHA1 hash of the toplevel tree

\end{enumerate}

% FIGURE, flat index to tree.

%trans-dull:
Here is the type and skeleton of [[Index.trees_of_index()]]:

<<signature [[Index.trees_of_index]]>>=
val trees_of_index: t -> (* add_obj *)(Tree.t -> Tree.hash) -> Tree.hash
@
<<function [[Index.trees_of_index]]>>=
let trees_of_index idx add_tree_obj =
  let (dirs: dirs) = Hashtbl.create 11 in
  (* populate dirs *)
  <<[[Index.trees_of_index()]] populate [[dirs]]>>
  (* build trees *)
  <<[[Index.trees_of_index()]] build trees from [[dirs]]>>
@

\subsection{Grouping index files by directories}

%trans-dull:
Here is the type of the hashtbl [[dirs]] grouping files 
by directory:

<<type [[Index.dirs]]>>=
type dirs = (Fpath.t (* full relpath of dir *), dir) Hashtbl.t
@

<<type [[Index.dir]]>>=
type dir = dir_entry list ref
@
<<type [[Index.dir_entry]]>>=
  and dir_entry =
    | Subdir of string (* basename *)
    | File of string (* basename *) * entry
@

%trans-dull:
Here is the code to populate the [[dirs]] hashtable:

<<[[Index.trees_of_index()]] populate [[dirs]]>>=
Hashtbl.add dirs (Fpath.v ".") (ref []);
idx |> List.iter (fun entry ->
  let relpath : Fpath.t = entry.path in
  let (dirpath, base) = Filename.dirname !!relpath, Filename.basename !!relpath in
  let dir = find_dir dirs (Fpath.v dirpath) in
  dir := (File (base, entry))::!dir
);
@

%trans-dull:
Finding the directory of a file uses the function below:

<<function [[Index.add_dir]]>>=
let rec find_dir (dirs : dirs) (dirpath : Fpath.t) : dir =
  try 
    Hashtbl.find dirs dirpath
  with Not_found ->
    let newdir = ref [] in
    Hashtbl.add dirs dirpath newdir;
    <<[[Index.add_dir()]] recurse on parent of [[dirpath]]>>
    newdir
@


% FIGURE for trees.
% It maps relative path of dir to dir content

Note that adding a new directory in [[dirs]] requires also to
recursively add its parent:

<<[[Index.add_dir()]] recurse on parent of [[dirpath]]>>=
let (parent, base) = 
  Filename.dirname !!dirpath, Filename.basename !!dirpath in
(* !recursive call! should stop at some point because "." is in dirs *)
let dir = find_dir dirs (Fpath.v parent) in
dir := Subdir (base)::!dir;
@

The recursion stops because [[dirs]] is initialized with an
entry for [['.']] and [[Filename.dirname]] eventually returns [['.']]
when it reaches the toplevel directory.

\subsection{Building trees from directories}

%trans-dull:
Here is the second step of the [[trees_of_index()]] algorithm,
which builds a set of trees from [[dirs]] recursively starting
from the root directory [['.']].

<<[[Index.trees_of_index()]] build trees from [[dirs]]>>=
build_trees dirs (Fpath.v ".") add_tree_obj
@

<<function [[Index.build_trees]]>>=
let rec build_trees (dirs : dirs) (dirpath : Fpath.t) add_tree_obj =
  let dir = Hashtbl.find dirs dirpath in
  (* entries of a Tree.t must be sorted, but entries of an index too,
   * so we can assume add_dir was called in sorted order
   *)
  let xs = List.rev !dir in
  let tree = 
    xs |> List.map (function
      | File (base, entry) ->
        {Tree.
         name = base; 
         id = entry.id; 
         perm = perm_of_mode entry.stats.mode;
        }
      | Subdir base ->
        (* recurse *)
        let sha = 
          build_trees dirs (dirpath / base) add_tree_obj in
        {Tree. perm = Tree.Dir; name = base; id = sha }
    )
  in
  add_tree_obj tree
@

The function [[add_tree_obj()]] above will not only add a tree object
the repository. It will also return its SHA1.
%
Its value ([[fun t -> add_obj (Tree t)]]) is passed down to
[[build_trees]] from [<Repository.commit_index()>].


%trans-dull:
The code above relies on the helper function below to
convert an [<Index.mode>] to a [<Tree.perm>]:

<<signature [[Index.perm_of_mode]]>>=
val perm_of_mode: mode -> Tree.perm
@
<<function [[Index.perm_of_mode]]>>=
let perm_of_mode mode = 
  match mode with
  | Normal -> Tree.Normal
  | Exec -> Tree.Exec
  | Link -> Tree.Link
  <<[[Index.perm_of_mode()]] match mode cases>>
@


\section{Storing the date, author, and committer}

%trans:
Once [<Repository.commit_index()>] computed the toplevel tree object
from the index, setting the other fields of the commit
object is trivial.

<<[[Cmd_commit.cmd]] command-line options>>=
"--author",    Arg.Set_string author, " <author>";
@
<<constant [[Cmd_commit.author]]>>=
let author = ref ""
@


<<[[Cmd_commit.cmd]] compute [[author]] user>>=
(* todo: read from .git/config or ~/.gitconfig *)
let author = 
  if !author = ""
  then { User.
         name = Unix.getlogin ();
         email = "todo@todo";
         date = today;
       }
  else raise Todo (* need parse author string *)
in
@


<<[[Cmd_commit.cmd]] compute [[today]]>>=
let today = 
  (Int64.of_float (Unix.time ()),
   (* todo: use localtime vs gmtime? *) -7 (* SF *))
in
@




<<[[Cmd_commit.cmd]] command-line options>>=
"--committer", Arg.Set_string committer, " <author>";
@
<<constant [[Cmd_commit.committer]]>>=
let committer = ref ""
@
<<[[Cmd_commit.cmd]] compute [[committer]] user>>=
let committer =
  if !committer = ""
  then author
  else raise Todo
in
@


% Use config for default, see adv topics.

\section{Recording the message}

<<[[Cmd_commit.cmd]] command-line options>>=
"-m",        Arg.Set_string message, " <msg> commit message";
"--message", Arg.Set_string message, " <msg> commit message";
@
<<constant [[Cmd_commit.message]]>>=
let message = ref ""
@
\t EDITOR here?


\section{Updating [[HEAD]] atomically}

%trans:
The last operation of [<Repository.commit_index()>] is to update [[HEAD]]
to point to the newly created commit object.
%
In fact, [[git commit]] does not update [[HEAD]] itself but
the head pointed by [[HEAD]] (e.g., [[.git/refs/heads/master]]),
hence the use of [<Repository.follow_ref()>] in the code of the next sections.
%
Updating this head must be done atomically.
\t why atomically?
%CVS:
\t CVS was first to consider set of files, but it did not have atomic update of
\t multiple files.
\t Here either everything goes, or nothing!
%
To do so, [<Repository.commit_index()>] rely on two different functions
to handle two different situations:
\begin{enumerate}
\item When this is the first commit and [[HEAD]] points to an head
that does not exist yet. In that case it calls [<Repository.add_ref_if_new()>].

\item When there was already an older previous commit.
In that case it calls [<Repository.set_ref_if_same_old()>].
\end{enumerate}

%concurrency:
% need atomic operations for updating the refs, because
% push/pull will modify other repos that may be concurrently
% accessed by another user at the same time.
%why important atomic? because when push, you will write to another
% repo, and you will modify refs possibly? so need atomic?

%torvalds: simple, just need update the ref! no need lock
% on set of files (immutable hashed objects), just lock
% one ref, refs/heads/master (or other branch name)

% Can have pb, in which case just stale objects? (git gc)

<<[[Repository.commit_index()]] add ref when first commit>>=
add_ref_if_new r aref (Refs.Hash sha)
@
<<[[Repository.commit_index()]] update ref when not first commit>>=
set_ref_if_same_old r aref old_head sha
@

Both functions above return a boolean indicating whether the
operation could be done atomically.
%
For example, [<Repository.set_ref_if_same_old()>] will return false
if while modifying the reference, another process modified
it before and the current value is not anymore the old one
read before.

\subsection{Creating a new reference (first commit)}

Creating the first commit and the first head atomically
requires to make sure that while creating the reference file,
nobody else created the same file.
\t race between time read ref and see no sha and time write file
\t not that with_file_out_with_lock not enough.
%, so that the reference is indeed a new reference 
% (hence the name of the function).
%

<<signature [[Repository.add_ref_if_new]]>>=
val add_ref_if_new: t -> Refs.t -> Refs.ref_content -> bool
@
<<function [[Repository.add_ref_if_new]]>>=
let add_ref_if_new r aref refval =
  let (refs, shaopt) = follow_ref r aref in
  if shaopt <> None
  then false
  else begin
    let lastref = List.hd (List.rev refs) in
    let file = ref_to_filename r lastref in
    (* todo: ensure dirname exists *)
    file |> with_file_out_with_lock (fun ch ->
      (* todo: check file does not exist aleady; then return false! *)
      ch |> IO.output_channel |> IO_.with_close_out (Refs.write refval);
      true
    )
  end
@
%crossref: ref_to_filename, follow_ref
%crossref: with_file_out_with_lock 
\ref{sec:lock-writing-file}

%crossref:
I described the code of [<Refs.write()>] before.

\subsection{Updating an existing reference}


<<signature [[Repository.set_ref_if_same_old]]>>=
val set_ref_if_same_old: t -> Refs.t -> Sha1.t -> Sha1.t -> bool
@
<<function [[Repository.set_ref_if_same_old]]>>=
let set_ref_if_same_old r aref _oldh newh =
  let (refs, _) = follow_ref r aref in
  let lastref = List.hd (List.rev refs) in
  let file = ref_to_filename r lastref in
  try 
    file |> with_file_out_with_lock (fun ch ->
      (* TODO generate some IO.No_more_input 
      let prev = read_ref r lastref in
      if prev <> (Refs.Hash oldh)
      then raise Not_found
      else 
      *)
        ch |> IO.output_channel |> IO_.with_close_out 
            (Refs.write (Refs.Hash newh))
    );
    true
  with Not_found -> false
@

\chapter{Branching}
\label{chap:branching}
% branching, aka fork.

In this chapter, you will see the code to manipulate branches.
Git uses the same command, [[git branch]], whose code is below, to 
list,
create, and
delete branches
depending on the command-line arguments.
%
You will also see in this chapter the code of 
[[git checkout]] to switch between branches, and 
[[git reset]] to reset all modifications done while working on the
current branch.

%dup: (but expanded?) intro/motivations
% purpose: parallel development (!= concurrent development)

%gitless: records working version of files, so can easily switch branch!
% no problem if got uncommitted stuff in current dir or untracked file
% that conflicts with tracked file in another branch, it will be saved!
% in gitless, it really is like you had 2 separate dirs with 2
%  separate working versions!

% Again can simply use cp and create another repo :)

% Branch operations are very simple. Just list/create/delete
% entries under refs/.
% cheap
%cvs: was terrible at managing branch. Relied on RCS branch mechanism,
% which was per file with complex encoding 1.1.1.1 and file format
% (forward-deltas on top of reverse-deltas).

% Important in DVCS to have cheap and simple branching (and merging), because
% everybody is a branch! everybody maintains its own fork!

<<constant [[Cmd_branch.cmd]]>>=
let cmd = { Cmd_.
  name = "branch";
  usage = " [options]
   or: ocamlgit branch [options] <branchname>
   or: ocamlgit branch [options] (-d | -D) <branchname>
";
  options = [
    <<[[Cmd_branch.cmd]] command-line options>>
  ];
  f = (fun args ->
    let r, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    <<[[Cmd_branch.cmd]] match args cases>>
    | _ -> raise Cmd_.ShowUsage
  );
}
@
%pijul: use 'fork' and 'delete-branch' as commands instead of 
% abusing branch for everything


\ifallcode
<<[[Cmd_branch.cmd]] match args cases>>=
| [_name;_objectish] ->
  raise Todo
@
\fi

\ifallcode
<<[[Cmd_branch.cmd]] command-line options>>=
(* less: --merged, --no-merged, --all for listing 
 *  --move to rename branch
 *  --force (force creation, deletion, rename)
*)
@
\fi

\section{Listing branches: [[git branch]]}

To list the set of {active} branches, you just need to call
[[git branch]] without any argument:

<<[[Cmd_branch.cmd]] match args cases>>=
| [] -> list_branches r
@

Here is the output of [[git branch]] on a repository with
only two branches. 
[[git branch]] {marks} the current branch with a [[*]] before its name.

\begin{verbatim}
1 $ git branch
  experiment
* master
\end{verbatim}

%trans-dull:
Here is the code of [[list_branches()]]:

<<function [[Cmd_branch.list_branches]]>>=
(* less: remote_flag set with --all to also list remote refs *)
let list_branches r =
  let head_branch = Repository.read_ref r (Refs.Head) in
  let all_refs = Repository.all_refs r in
  all_refs |> List.iter (fun refname ->
    if refname =~ "^refs/heads/\\(.*\\)"
    then 
      let short = Regexp_.matched1 refname in
      let prefix = 
        if (Refs.OtherRef refname = head_branch)
        then "* "
        else "  "
      in
      UConsole.print (spf "%s%s" prefix short)
  )
@
%crossref: Regexp_.matched1 in appendix

%crossref:
I described before the code of [<Repository.read_ref()>].
%
Thanks to the simplicity of how Git stores references on the disk,
getting all the references consists just in walking
the [[.git/refs/]] directory:

<<signature [[Repository.all_refs]]>>=
val all_refs: t -> Refs.refname list
@
<<function [[Repository.all_refs]]>>=
let all_refs (r : t) : Refs.refname list =
  let root = r.dotgit in
  let rootlen = String.length !!root in
  let res = ref [] in
  (root / "refs") |> walk_dir (fun path _dirs files ->
    files |> List.iter (fun file ->
      (* less: replace os.path.sep *)
      let dir = String.sub !!path rootlen (String.length !!path - rootlen) in
      let refname = Fpath.v dir / file in
      Stack_.push !!refname res
    );
   );
  List.rev !res
@

%crossref: walk_dir appendix
The code above relies on the utility function [<Repository.walk_dir()>]
to explore recursively a directory 
(see Appendix~\ref{chap:utilities} for its code).
%
This function takes a callback function and a directory as parameters
and calls the callback for each subdirectories of the directory parameter.
%
The callback is called with three arguments: 
the path of the current subdirectory,
the immediate subdirectories in this subdirectory, and 
the immediate files in this subdirectory.



\section{Creating a branch: [[git branch <name>]]}
\label{sec:create-branch}

To create a new branch, you need to call [[git branch]] with one
argument: the name of the desired branch.

<<[[Cmd_branch.cmd]] match args cases>>=

| [name] ->
  (match () with
  <<[[Cmd_branch.cmd]] when one argument, when flags cases>>
  | _ -> create_branch r name
  )
@

%repeat_code:
Creating a branch simply creates a new reference with the same
SHA1 than the SHA1 of the last commit in the current branch:

<<function [[Cmd_branch.create_branch]]>>=
let create_branch r name (* sha *) =
  let refname = "refs/heads/" ^ name in
  <<[[Cmd_branch.create_branch()]] sanity check refname>>
  let sha = Repository.follow_ref_some r (Refs.Head) in
  let ok = Repository.add_ref_if_new r (Refs.Ref refname) (Refs.Hash sha) in
  if not ok
  then failwith (spf "could not create branch '%s'" name)
@
%crossref: follow_ref_some and add_ref_if_new talked before

% cheap! (ok checkout takes time)
% and then usually checkout!

<<[[Cmd_branch.create_branch()]] sanity check refname>>=
let all_refs = Repository.all_refs r in
if List.mem refname all_refs
(* less: unless -force *)
then failwith (spf "A branch named '%s' already exists." name);
@

\section{Deleting a branch: [[git branch -d <name>]]}

%trans:
Finally, to delete a branch, adds the [[-d]] (or [[-D]]) command-line
flag before the name of the branch:

<<[[Cmd_branch.cmd]] command-line options>>=
"-d",       Arg.Set del_flag, " delete fully merged branch";
"--delete", Arg.Set del_flag, " delete fully merged branch";
@
<<constant [[Cmd_branch.del_flag]]>>=
let del_flag = ref false
@
<<[[Cmd_branch.cmd]] when one argument, when flags cases>>=
| _ when !del_flag  -> delete_branch r name false
@



<<[[Cmd_branch.cmd]] when one argument, when flags cases>>=
| _ when !del_force -> delete_branch r name true
@
<<[[Cmd_branch.cmd]] command-line options>>=
"-D",       Arg.Set del_force, " delete branch (even if not merged)";
@
<<constant [[Cmd_branch.del_force]]>>=
let del_force = ref false
@


<<function [[Cmd_branch.delete_branch]]>>=
let delete_branch r name force =
  let refname = "refs/heads/" ^ name in
  let aref = Refs.Ref refname in
  let sha = Repository.follow_ref_some r aref in
  <<[[Cmd_branch.delete_branch()]] sanity check if branch merged unless force>>
  Repository.del_ref r aref;
  UConsole.print (spf "Deleted branch %s (was %s)" name (Hexsha.of_sha sha))
@

Deleting a branch consists simply in deleting a reference file
under [[.git/refs]]:

<<signature [[Repository.del_ref]]>>=
val del_ref: t -> Refs.t -> unit
@
<<function [[Repository.del_ref]]>>=
let del_ref r aref =
  let file = ref_to_filename r aref in
  Unix.unlink !!file
@

% git gc


<<[[Cmd_branch.delete_branch()]] sanity check if branch merged unless force>>=
if not force
(* todo: detect if fully merged branch! *)    
then ();
@

\section{Checking out a branch: [[git checkout]]}
\label{sec:switch-branch}
\l switching branch

%trans:
To switch to another branch, Git uses another command: [[git checkout]].
%rcs: back from rcs to use checkout?
\n git checkout can also be used to create a branch with -b, but redundant

<<constant [[Cmd_checkout.cmd]]>>=
let cmd = { Cmd_.
  name = "checkout";
  usage = " [options] <branch>
   or: ocamlgit checkout [options] <commitid>
   or: ocamlgit checkout [options]
";
  options = [
   <<[[Cmd_checkout.cmd]] command-line options>>
  ];
  f = (fun args ->
    let r, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    <<[[Cmd_checkout.cmd]] match args cases>>
    | _ -> raise Cmd_.ShowUsage
  );
}
@

\ifallcode
<<[[Cmd_checkout.cmd]] command-line options>>=
 (* less: --detach, --patch?
  * -b create and checkout a branch
  *)
@
\fi

This command has also multiple operation modes depending on the
its command-line arguments.
%
With an argument, [[git checkout]] will switch the current branch:

<<[[Cmd_checkout.cmd]] match args cases>>=
| [str] -> checkout r str
@

This argument can be the name of a branch (e.g., [[git checkout experiment]]),
but also a string denotting a past commit (e.g., [[git checkout 19d977]]).
%
Here is the code below to deal with a branch name as an argument:

<<function [[Cmd_checkout.checkout]]>>=
let checkout r str =
  let all_refs = Repository.all_refs r in
  let refname = "refs/heads/" ^ str in

  match () with
  | _ when List.mem refname all_refs ->
    let commitid = Repository.follow_ref_some r (Refs.Ref refname) in
    let commit = Repository.read_commit r commitid in
    let tree = Repository.read_tree r commit.Commit.tree in

    (* todo: order of operation? set ref before index? reverse? *)
    Repository.write_ref r (Refs.Head) (Refs.OtherRef refname);
    Repository.set_worktree_and_index_to_tree r tree;
    UConsole.print (spf "Switched to branch '%s'" str);
    (* less: if master, then check if up-to-date with origin/master *)

  <<[[Cmd_checkout.checkout()]] cases>>
  | _ -> raise Cmd_.ShowUsage
@

To checkout a branch, the code above first finds the commit
associated with the reference of the branch, 
then reads it from the disk
%crossref:
(see the code of [<Repository.read_commit()>]), and then read its
tree 
(see the code of [<Repository.read_tree()>]).
Then, most of the heavy work is done by 
[<Repository.set_worktree_and_index_to_tree()>], which I will present
in the next section.


% reset_index use for checkout!

% build_index and also set worktree from tree.



<<[[Cmd_checkout.cmd]] match args cases>>=
| [] -> update r
@
<<function [[Cmd_checkout.update]]>>=
(* Your branch is up-to-date with 'origin/master'. *)
let update _r =
  raise Todo
@

\subsection{Computing the index (and work tree) from trees}
\label{sec:index-from-tree}
% opposite of what we saw before for git commit.

<<signature [[Repository.set_worktree_and_index_to_tree]]>>=
val set_worktree_and_index_to_tree:
  t -> Tree.t -> unit
@
<<function [[Repository.set_worktree_and_index_to_tree]]>>=
let set_worktree_and_index_to_tree r tree =
  (* todo: need lock on index? on worktree? *)
  let hcurrent = 
    r.index |> List.map (fun e -> e.Index.path, false) |> Hashtbl_.of_list in
  let new_index = ref [] in
  (* less: honor file mode from config file? *)
  tree |> Tree.walk_tree (read_tree r) (Fpath.v "XXX") (fun relpath entry ->
    let perm = entry.Tree.perm in
    match perm with
    | Tree.Dir -> 
      (* bugfix: need also here to mkdir; doing it below is not enough
       * when a dir has no file but only subdirs
       *)
      let fullpath = r.worktree // relpath in
      if not (Sys.file_exists !!fullpath)
      then Unix.mkdir !!fullpath dirperm;
    | Tree.Normal | Tree.Exec | Tree.Link ->
      (* less: validate_path? *)
      let fullpath = r.worktree // relpath in
      if not (Sys.file_exists (Filename.dirname !!fullpath))
      then Unix.mkdir (Filename.dirname !!fullpath) dirperm;
      let sha = entry.Tree.id in
      let blob = read_blob r sha in
      let stat = build_file_from_blob fullpath blob perm in
      Hashtbl.replace hcurrent relpath true;
      Stack_.push (Index.mk_entry relpath sha stat) new_index;
    <<[[Repository.set_worktree_and_index_to_tree()]] walk tree cases>>
  );
  let index = List.rev !new_index in
  r.index <- index;
  write_index r;
  hcurrent |> Hashtbl.iter (fun file used ->
    if not used
    then 
      (* todo: should check if modified? otherwise lose modif! *)
      let fullpath = r.worktree // file in
      Unix.unlink !!fullpath
  )
  (* less: delete if a dir became empty, just walk_dir? *)
@

\t should also delete file not present in old version but were in
\t  current version

<<signature [[Tree.walk_tree]]>>=
val walk_tree: 
  (hash -> t) -> Fpath.t (* dir *) -> 
  (Fpath.t -> entry -> unit) -> t -> unit
@
<<function [[Tree.walk_tree]]>>=
(* we must visit in sorted order, so the caller of walk_tree can rely on 'f'
 * being called in order (so it can easily create for example sorted 
 * index entries while visiting a tree)
 *)
let rec walk_tree read_tree (dirpath : Fpath.t) f xs =
  xs |> List.iter (fun entry ->
    let relpath = dirpath / entry.name in
    f relpath entry;
    match entry.perm with
    | Dir ->
      walk_tree read_tree relpath f (read_tree entry.id)
    | Normal | Exec | Link -> ()
    <<[[Tree.walk_tree()]] match perm cases>>
  )
@
% there is also walk_trees, later.


\subsection{Creating a file from a blob}

<<function [[Repository.build_file_from_blob]]>>=
let build_file_from_blob (fullpath : Fpath.t) blob perm =
  let oldstat =
    try 
      Some (Unix.lstat !!fullpath)
    with Unix.Unix_error _ -> None
  in
  (match perm with 
  | Tree.Link -> 
    if oldstat <> None
    then Unix.unlink !!fullpath;
    Unix.symlink blob !!fullpath;
  | Tree.Normal | Tree.Exec ->
    (match oldstat with
    (* opti: if same content, no need to write anything *)
    | Some { Unix.st_size = x; _ } when x = String.length blob && 
      (fullpath |> UChan.with_open_in (fun (ch : Chan.i) -> 
        (ch.ic |> IO.input_channel |> IO.read_all ) = blob
       )) ->
      ()
    | _ ->
      fullpath |> UChan.with_open_out (fun (ch : Chan.o) ->
        output_bytes ch.oc (Bytes.of_string blob)
      );
      (* less: honor filemode? *)
      Unix.chmod !!fullpath 
        (match perm with 
        | Tree.Normal -> 0o644
        | Tree.Exec -> 0o755
        | _ -> raise (Impossible "matched before")
        )
    )
  | Tree.Dir -> raise (Impossible "dirs filtered in walk_tree iteration")
  <<[[Repository.build_file_from_blob()]] match perm cases>>
  );
  Unix.lstat !!fullpath
@


%\subsection{[[validate_path()]]}


\section{Resetting a branch: [[git reset]]}

Resetting a branch is useful for example you want to quickly
undo the modifications you have done to your working files.
\t other examples?
%
To do so you must use the [[git reset]] command with
the [[-hard]] command-line flag.
%
Indeed, there are multiple ways to reset a branch, as shown
by the code and flags below:

<<constant [[Cmd_reset.cmd]]>>=
let cmd = { Cmd_.
  name = "reset";
  usage = " [options] ";
  options = [
    <<[[Cmd_reset.cmd]] command-line options>>
  ];
  f = (fun args ->
    let r, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> 
      (match () with
      <<[[Cmd_reset.cmd.f()]] when no args, cases>>
      | _ -> raise Cmd_.ShowUsage
      )
    | _ -> raise Cmd_.ShowUsage
  );
}
@


\ifallcode
<<[[Cmd_reset.cmd]] command-line options>>=
(* less: or: git reset <paths>... *)
(* less: --patch, --quiet, --merge *)
@
\fi

<<[[Cmd_reset.cmd]] command-line options>>=
"--hard", Arg.Set hard, " reset HEAD, index and working tree";
"--soft", Arg.Set soft, " reset only HEAD";
"--mixed", Arg.Set mixed, " reset HEAD and index";
@

<<constant [[Cmd_reset.hard]]>>=
let hard = ref false
@
<<constant [[Cmd_reset.soft]]>>=
let soft = ref false
@
<<constant [[Cmd_reset.mixed]]>>=
let mixed = ref false
@

<<[[Cmd_reset.cmd.f()]] when no args, cases>>=
| _ when !hard -> reset_hard r
@

A hard reset is equivalent to checking out again
the commit of the current branch, and so the code
below can reuse [<Repository.set_worktree_and_index_to_tree()>]
used for the code of [[git checkout]].

<<function [[Cmd_reset.reset_hard]]>>=
let reset_hard r =
  let commitid = Repository.follow_ref_some r (Refs.Head) in
  let commit = Repository.read_commit r commitid in
  let tree = Repository.read_tree r commit.Commit.tree in

  Repository.set_worktree_and_index_to_tree r tree;
  UConsole.print (spf "HEAD is now at %s %s" 
        (String.sub (Hexsha.of_sha commitid) 0 6)
        (String.sub commit.Commit.message 0 40))
@

\t should also reset selectively files or dirs

<<[[Cmd_reset.cmd.f()]] if not hard reset>>=
if !soft || !mixed || not !hard
then begin
  pr2 "only --hard supported";
  raise Cmd_.ShowUsage
end
@

\chapter{Merging}
\label{chap:merging}
% "Integrating changes" in misfit paper

%trans: after fork, of course dual is merge

% for // devel but also concurrent devel. everyone is a branch.

% ??? no code in dulwich for merge? or just do_commit with multiple
% parents? the <<< >>> conflict is not part of git but can be third-party?

% MERGE_HEADS?

% saw merge_tag before in commit, and merge_heads in do_commit.

%torvalds:
% On need for clever merge:
% https://wincent.com/blog/a-look-back-bram-cohen-vs-linus-torvalds:

%"There is no need for fancy metadata, rename tracking and so forth. The
%only thing you need to store is the state of the tree before and after
%each change. What files were renamed? Which ones were copied? Which
%ones were deleted? What lines were added? Which ones were removed?
%Which lines had changes made inside them? Which slabs of text were
%copied from one file to another? You shouldn't have to care about any
%of these questions and you certainly shouldn't have to keep special
%tracking data in order to help you answer them: all the changes to the
%tree (additions, deletes, renames, edits etc) are implicitly encoded
%in the delta between the two states of the tree; you just track what
%is the content.
%
%Git is already very smart, and it can (and will) get smarter about
%figuring out what happened, and where a given line in a given revision
%came from, and it will do so without ever having to embed additional
%meta data in its repositories. Absolutely everything can (and should)
%be inferred.
%
%Git breaks the mould because it thinks about content, not files. It
%doesn't track renames, it tracks content. And it does so at a
%whole-tree level. This is a radical departure from most version
%control systems. It doesn't bother trying to store per-file histories;
%it instead stores the history at the tree level. When you perform a
%diff you are comparing two trees, not two files.
%
%As a result of this fundamental design decision, the structure of a
%Git repository is stunningly simple. It's so simple in fact, that
%you'll be surprised at the sophistication of the things you can do
%with it. But that's the way the best code will always be: simple,
%solid premises out of which complex applications arise.
%
%The other fundamentally smart design decision is how Git does merges.
%The merging algorithms are smart but they don't try to be too smart.
%Unambiguous decisions are made automatically, but when there's doubt
%it's up to the user to decide. This is the way it should be. You don't
%want a machine making those decisions for you. You never will want it.
%That's the fundamental insight in the Git approach to merging: while
%every other version control system is trying to get smarter, Git is
%happily self-described as the "stupid content manager", and it's
%better for it."


%related? history sensitive merging?
%https://tahoe-lafs.org/~zooko/badmerge/simple.html

\section{merging branches: [[git merge]]}
\label{sec:git-merge}

% Pb of history-sensitive merging? If share some patches? Arch better?
% Or just completely forget the pb and do a general 3-way merge from
% base and just care about final state of both branches?

% 3-way merge algorithm? diff3?

\section{Merging two trees}

\section{Merging two files}

\section{[[diff3]] and [[merge]]}
% from diffutils, a bit like diff and patch?

\section{Merging conflicts}
% talked about it in principles

\section{Committing merged branches: [[git commit]]}
\label{sec:git-commit-merge}

<<[[Repository.commit_index()]] read merge message if needed>>=
(* less: Try to read commit message from .git/MERGE_MSG *)
@

<<[[Repository.commit_index()]] set [[merge_heads]]>>=
(* less: merge_heads from .git/MERGE_HEADS *)
let merge_heads = [] in
@

\chapter{Inspecting}
\label{chap:inspecting}

%trans: %toc: log, diff, status. keep track on what's going on.
% but before show, less useful, but simpler, and can be used
% to further inspect output from other commands (e.g. git show after git log
% (or use git log -P to see patch)

\section{Showing the content of an object: [[git show]]}
% can be useful to understand formats

<<constant [[Cmd_show.cmd]]>>=
let cmd = { Cmd_.
  name = "show";
  usage = " <objectish>";
  (* less: --oneline *)
  options = [];
  f = (fun args ->
    let r, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> show r (Repository.ObjByRef (Refs.Head))
    | xs ->
      xs |> List.iter (fun str ->
        show r (Repository.parse_objectish str)
      )
  );
}
@
\l could have shorthex here, or branchname

<<function [[Cmd_show.show]]>>=
let show r objectish =
  let sha, obj = Repository.read_objectish r objectish in
  match obj with
  <<[[Cmd_show.show()]] match obj cases>>
@

\subsection{Showing a blob}

<<[[Cmd_show.show()]] match obj cases>>=
| Objects.Blob x -> 
  Blob.show x
@

<<signature [[Blob.show]]>>=
val show: t -> unit
@
<<function [[Blob.show]]>>=
let show x =
  print_string x
@


\subsection{Showing a tree}

<<[[Cmd_show.show()]] match obj cases>>=
| Objects.Tree x ->
  (* =~ git ls-tree --names-only *)
  UConsole.print (spf "tree %s\n" (Hexsha.of_sha sha));
  Tree.show x
@

<<signature [[Tree.show]]>>=
val show: t -> unit
@
<<function [[Tree.show]]>>=
let show xs =
  xs |> List.iter (fun entry ->
    UConsole.print (spf "%s%s" entry.name
          (match entry.perm with
          | Dir -> "/"
          | _ -> ""
          ))
  )
@
% git adds a '/' suffix when it's a dir

\subsection{Showing a commit}

% So can be used after git log to show the diff!


<<[[Cmd_show.show()]] match obj cases>>=
| Objects.Commit x -> 
  UConsole.print (spf "commit %s" (Hexsha.of_sha sha));
  Commit.show x;
  let tree2 = Repository.read_tree r x.Commit.tree in
  let tree1 = 
    try 
      let parent1 = Repository.read_commit r (List.hd x.Commit.parents) in
      Repository.read_tree r parent1.Commit.tree 
    with Failure _ ->
    (* no parent *)
      []
  in
  let changes = 
    Changes.changes_tree_vs_tree 
      (Repository.read_tree r) 
      (Repository.read_blob r)
      tree1 tree2 
  in
  changes |> List.iter Diff_unified.show_change
@


<<signature [[Commit.show]]>>=
val show: t -> unit
@
<<function [[Commit.show]]>>=
let show x =
  UConsole.print (spf "Author: %s <%s>" x.author.User.name x.author.User.email);
  (* less: date of author or committer? *)
  let date = x.author.User.date in
  UConsole.print (spf "Date:   %s" (User.string_of_date date));
  UConsole.print "";
  UConsole.print ("    " ^ x.message)
  (* showing diff done in caller in Cmd_show.show *)        
@

% print_commit() before
% write_tree_diff in caller.

<<signature [[User.string_of_date]]>>=
(* for show *)
val string_of_date: (int64 * timezone_offset) -> string
@

<<function [[User.string_of_date]]>>=
let string_of_date (date, tz) =
  let f = Int64.to_float date in
  let tm = Unix.localtime f in

  spf "%s %s %d %02d:%02d:%02d %d %c%02d%02d"
    (Date.string_of_day tm.Unix.tm_wday) (Date.string_of_month tm.Unix.tm_mon) 
    tm.Unix.tm_mday 
    tm.Unix.tm_hour tm.Unix.tm_min tm.Unix.tm_sec (tm.Unix.tm_year + 1900)
    (char_of_sign tz) (abs tz) 0
@

<<function [[User.char_of_sign]]>>=
let char_of_sign = function
  | x when x >= 0 -> '+'
  | _ -> '-'
@

\section{Representing changes}

%trans:
% We will see a few commands showing changes (git diff, git status),
% so first introduce changes types.

\subsection{Tree changes}

<<type [[Change.t]]>>=
(* entry below refers only to files (not dirs), and their name
 * are adjusted to show a relative path from the root of the
 * project.
 *)
type t = 
  | Add of entry
  | Del of entry
  | Modify of entry * entry (* before / after *)
  (* less: Rename, Copy *)
  (*| Identical of Tree.entry *)
@

<<type [[Change.entry]]>>=
type entry = {
  (* relative path *)
  path: Fpath.t;
  mode: Index.mode;
  content: content Lazy.t;
}
@
% lazy, subtle, for performance, otherwise operation like git XXX are too
% slow.

<<type [[Change.content]]>>=
type content = string
@

% Note that changes used only for inspecting. Not part of core DS.
% Git store content, not diff (well except in Pack, see later).

%\subsection{Worktree versus index}
%\subsection{Index versus tree}
%\subsection{Tree versus tree}

\subsection{File changes}

<<type [[Diff.diff]]>>=
type diff = (item diff_elem) list
@

<<type [[Diff.diff_elem]]>>=
(* similar to change.ml, but for content of the file *)
type 'item diff_elem = 
  | Added   of 'item
  | Deleted of 'item
  | Equal   of 'item
@

<<type [[Diff.item]]>>=
type item = string
@

% Again diff not part of core DS. Used for inspecting.

\section{Showing file differences: [[git diff]]}

<<constant [[Cmd_diff.cmd]]>>=
let cmd = { Cmd_.
  name = "diff";
  usage = " ";
  options = [];
  f = (fun args ->
    let r, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> diff_worktree_vs_index r
    | _xs -> raise Cmd_.ShowUsage
  );
}
@

<<function [[Cmd_diff.diff_worktree_vs_index]]>>=
let diff_worktree_vs_index r =
  let changes = 
    Changes.changes_worktree_vs_index 
      (Repository.read_blob r)
      r.Repository.worktree 
      r.Repository.index 
  in
  changes |> List.iter Diff_unified.show_change
@

\subsection{Computing tree changes}

% naive version. Want heuristics for rename detection!

<<signature [[Changes.changes_worktree_vs_index]]>>=
(* for git diff and git status *)
val changes_worktree_vs_index:
  (Blob.hash -> Change.content) ->
  Fpath.t -> Index.t -> Change.t list
@
<<function [[Changes.changes_worktree_vs_index]]>>=
(* less: could factorize with Diff_tree.changes_tree_vs_tree? would need
 * to generate flat list of files (but then less opti opportunity
 * in changes_tree_vs_tree when hash for a whole subtree is the same)
 * and then just do set differences to compute new, deleted, and
 * for changes just look intersection and check if same content.
 *)
let changes_worktree_vs_index read_blob worktree index =
  index |> List.map (fun entry ->
    let old_stat = entry.Index.stats in
    let path = worktree // entry.Index.path in
    let new_stat_opt = 
      try Some (Unix.lstat !!path |> Index.stat_info_of_lstats)
      with Unix.Unix_error _ -> None
    in
    match new_stat_opt with
    | None -> 
      [Change.Del { Change.path = entry.Index.path;
                    mode = old_stat.Index.mode;
                    content = lazy (read_blob entry.Index.id);
                  }]
    | Some new_stat ->
      (match () with
      (* useful opti? *)
      | _ when new_stat.Index.mtime = old_stat.Index.mtime -> []
      (* a change of mode is converted in a del/add *)
      | _ when new_stat.Index.mode <> old_stat.Index.mode ->
        [Change.Del { Change.path = entry.Index.path;
                      mode = old_stat.Index.mode;
                      content = lazy (read_blob entry.Index.id)};
         Change.Add { Change.path = entry.Index.path;
                      mode = new_stat.Index.mode;
                      content = lazy 
                        (content_from_path_and_stat_index path new_stat)}
          ]
      | _ -> 
        [Change.Modify (
          { Change.path = entry.Index.path;
            mode = old_stat.Index.mode;
            content = lazy (read_blob entry.Index.id) },
          { Change.path = entry.Index.path;
            mode = new_stat.Index.mode;
            content = lazy 
              (content_from_path_and_stat_index path new_stat) }
        )]
      )
  ) |> List.flatten
@

<<function [[Changes.content_from_path_and_stat_index]]>>=
(* similar to Repository.content_from_path_and_unix_stat *)
let content_from_path_and_stat_index (path : Fpath.t) stat_info =
  match stat_info.Index.mode with
  | Index.Link ->
    Unix.readlink !!path
  | Index.Normal | Index.Exec ->
      path |> UChan.with_open_in (fun (ch : Chan.i) ->
        ch.ic |> IO.input_channel |> IO.read_all
      )
  <<[[Changes.content_from_path_and_stat_index()]] match mode cases>>
@

\subsection{Computing file changes}

% naive version. Want heuristics for block-move detection!

% string below is Change.content
<<signature [[Diffs.diff]]>>=
val diff: string -> string -> Diff.diff
@
% see appendix


\subsection{Showing changes}

<<signature [[Diff_unified.show_change]]>>=
val show_change: Change.t -> unit
@
<<function [[Diff_unified.show_change]]>>=
let show_change change =
  (* less: if mode is gitlink? *)
  let (old_path, old_content), (new_path, new_content) = 
    match change with
    | Change.Add entry ->
      (Fpath.v "dev/null", lazy ""), 
      (Fpath.v "b" // entry.Change.path, entry.Change.content)
    | Change.Del entry ->
      (Fpath.v "a" // entry.Change.path, entry.Change.content), 
      (Fpath.v "dev/null", lazy "")
    | Change.Modify (entry1, entry2) ->
      (Fpath.v "a" // entry1.Change.path, entry1.Change.content), 
      (Fpath.v "b" // entry2.Change.path, entry2.Change.content)
  in
  let diffs = Diffs.diff (Lazy.force old_content) (Lazy.force new_content) in
  if not (diffs |> List.for_all (function Diff.Equal _ -> true | _ -> false))
  then begin
    UConsole.print (spf "diff --git %s %s" !!old_path !!new_path);
    (* less: display change of modes *)
    show_unified_diff diffs
  end
@


<<function [[Diff_unified.show_unified_diff]]>>=
let show_unified_diff diffs =
  (* naive: no contextual:  diffs |> List.iter print *)
  let rec aux context_lines nctx_before nctx_after nold nnew diffs =
    match diffs with
    (* todo: say if 'No newline at end of file' *)
    | [] -> ()
    | x::xs ->
      (match x with
      | Diff.Equal _s ->
        (match () with
        | _ when nctx_after > 0 ->
          print x;
          aux [] 0 (nctx_after - 1) (nold + 1) (nnew + 1) xs
        | _ when nctx_before < nContext ->
          aux (x::context_lines) (nctx_before + 1) 0 (nold + 1) (nnew + 1) xs
        | _ when nctx_before = nContext ->
          let new_context_lines = List_.take nContext (x::context_lines) in
          aux new_context_lines nContext 0 (nold + 1) (nnew + 1) xs
        | _ -> raise (Impossible "")
        )
      | Diff.Deleted _s  ->
        let prevs = List_.take nctx_before context_lines |> List.rev in
        if prevs <> [] then print_header nctx_before nold nnew;
        prevs |> List.iter print;
        print x;
        aux [] 0 nContext (nold + 1) (nnew) xs
      | Diff.Added _s ->
        let prevs = List_.take nctx_before context_lines |> List.rev in
        if prevs <> [] then print_header nctx_before nold nnew;
        prevs |> List.iter print;
        print x;
        aux [] 0 nContext (nold) (nnew+1) xs
      )
  in
  aux [] 0 0 1 1 diffs
@

<<constant [[Diff_unified.nContext]]>>=
let nContext = 3
@

<<function [[Diff_unified.print]]>>=
let print = function
  | Diff.Equal s -> 
    print_string (" " ^ s)
  | Diff.Deleted s -> 
    print_string ("-" ^ s)
  | Diff.Added s -> 
    print_string ("+" ^ s)
@

<<function [[Diff_unified.print_header]]>>=
let print_header nctx_before nold nnew =
  (* todo: should print size of hunk also here, but then
   * need to wait we finished processing this hunk
   *)
  print_string (spf "@@ -%d, +%d, @@\n"
                  (nold - nctx_before) (nnew - nctx_before))
@


\section{Commit history walker}
\l make it a chapter? Walking a Repository?
\n renamed commit history walker so less confusing with object store walker?

% actually a DAG of commits, not a graph of commits.

\t used outside git log? so just put inside git log?

\subsection{Basic walker}

<<signature [[Commit.walk_history]]>>=
val walk_history:  
  (hash -> t) -> (hash -> t -> unit) -> hash ->
  unit
@
<<function [[Commit.walk_history]]>>=
(* less: sort by time? so have a sorted queue of commits *)
let walk_history read_commit f sha =
  (* we are walking a DAG, so we need to remember already processed nodes *)
  let hdone = Hashtbl.create 101 in
  let rec aux sha =
    if Hashtbl.mem hdone sha
    then ()
    else begin
      Hashtbl.add hdone sha true;
      let commit = read_commit sha in
      (* todo: path matching *)
      f sha commit;
      commit.parents |> List.iter aux
    end
  in
  aux sha
(* 
let walk_graph r f =
  let heads = 
    Repository.all_refs r |> Common.map_filter (fun aref ->
      if aref =~ "refs/heads/"
      then Some (Repository.follow_ref_some r (Refs.Ref aref))
      else None
    )
  in
  ...
  heads |> List.iter aux
*)
@

\subsection{Extra features}
\l mv in advanced topics?

\subsubsection{max entries}
% git log -1, -10, useful.

\subsubsection{Reverse walking}
% requires O(n). will call iterator and store result a list.

\subsubsection{Exclude set}

\subsubsection{Time range}

\subsubsection{Path restrictions}

\subsubsection{Topological order}


\section{Showing the commit history: [[git log]]}

<<constant [[Cmd_log.cmd]]>>=
let cmd = { Cmd_.
  name = "log";
  usage = " [options]";
  options = [
    "--name-status", Arg.Set name_status, 
    " print name/status for each changed file";
    (* todo: -1, -10 *)
    (* less: --reverse *)
  ];
  f = (fun args ->
    let r, relpaths = Repository.find_root_open_and_adjust_paths (Fpath_.of_strings args) in
    match relpaths with
    | [] -> log r
    (* todo: git log path *)
    (* less: revision range *)
    | _xs -> raise Cmd_.ShowUsage
  );
}
@

<<function [[Cmd_log.log]]>>=
(* todo: track only selected paths 
 * (and then rename detection to track correctly)
 *)
let log r =
  let start = Repository.follow_ref_some r (Refs.Head) in
  start |> Commit.walk_history (Repository.read_commit r) (fun sha commit ->
    print_commit sha commit;
    <<[[Cmd_log.log()]] if [[--name-status]] flag>>
    end
  )
@


\subsection{Printing a commit}

<<function [[Cmd_log.print_commit]]>>=
let print_commit sha commit =
  UConsole.print (spf "commit: %s" (Hexsha.of_sha sha));
  (match commit.Commit.parents with
  | [] | [_] -> ()
  | _x::xs ->
    UConsole.print (spf "merge: %s" 
          (xs |> List.map Hexsha.of_sha |> String.concat "..."));
  );
  let author = commit.Commit.author in
  UConsole.print (spf "Author: %s <%s>" author.User.name author.User.email);
  let committer = commit.Commit.committer in
  if author <> committer
  then 
    UConsole.print (spf "Committer: %s <%s>" committer.User.name committer.User.email);
  UConsole.print (spf "Date:   %s" (User.string_of_date author.User.date));
  UConsole.print "";
  UConsole.print ("    " ^ commit.Commit.message);
  ()
@

\subsection{Diff summary: [[git log --name-status]]}

<<constant [[Cmd_log.name_status]]>>=
let name_status = ref false
@
<<[[Cmd_log.log()]] if [[--name-status]] flag>>=
if !name_status
then begin
  let tree1 = Repository.read_tree r commit.Commit.tree in
  let tree2 =
    match commit.Commit.parents with
    | [] -> []
    | [sha] -> 
      let commit2 = Repository.read_commit r sha in
      Repository.read_tree r commit2.Commit.tree
    | _x::_y::_xs ->
      failwith "TODO: log: handle merge"
  in
  let changes = Changes.changes_tree_vs_tree
    (Repository.read_tree r)
    (Repository.read_blob r)
    tree2
    tree1
  in
  changes |> List.iter print_change;
  UConsole.print "";
@


<<function [[Cmd_log.print_change]]>>=
let print_change change =
  match change with
  | Change.Add entry ->
    UConsole.print (spf "A       %s" !!(entry.Change.path))
  | Change.Del entry ->
    UConsole.print (spf "D       %s" !!(entry.Change.path))
  | Change.Modify (entry1, _entry2) ->
    UConsole.print (spf "M       %s" !!(entry1.Change.path))
@

\subsection{Comparing trees}


<<signature [[Changes.changes_tree_vs_tree]]>>=
(* for git show commit *)
val changes_tree_vs_tree: 
  (Tree.hash -> Tree.t) ->
  (Blob.hash -> Change.content) ->
  Tree.t -> Tree.t -> Change.t list
@
<<function [[Changes.changes_tree_vs_tree]]>>=
(* see also Cmd_diff.changes_index_vs_worktree
 *     and  Cmd_status.changes_index_vs_HEAD
 *)
let changes_tree_vs_tree read_tree read_blob tree1 tree2 =
  let changes = ref [] in
  let add x = Stack_.push x changes in
  Tree.walk_trees read_tree (Fpath.v "XXX") (fun dirpath entry1_opt entry2_opt ->
    (* if entries are directories, then we would be called again
     * with their individual files, so safe to skip the dir entries.
     *)
    let entry1_opt = skip_tree_and_adjust_path read_blob dirpath entry1_opt in
    let entry2_opt = skip_tree_and_adjust_path read_blob dirpath entry2_opt in
    
    match entry1_opt, entry2_opt with
    | None, None -> ()
    | Some (a, asha), Some (b, bsha) ->
      (match () with
      (* file type changed reported as delete/add (meh) *)
      | _ when a.Change.mode <> b.Change.mode ->
        add (Change.Del a);
        add (Change.Add b);
      | _ when asha <> bsha ->
        add (Change.Modify (a, b))
      | _ -> ()
      )
    | Some (a,_), None -> add (Change.Del a)
    | None, Some (b,_) -> add (Change.Add b)
  ) tree1 tree2 ;
  List.rev !changes
@

<<signature [[Tree.walk_trees]]>>=
val walk_trees:
  (hash -> t) -> Fpath.t (* dir *) ->
  (Fpath.t -> entry option -> entry option -> unit) -> t -> t -> unit
@
<<function [[Tree.walk_trees]]>>=
let rec walk_trees read_tree (dirpath : Fpath.t) f xs ys =
  let g dirpath entry1_opt entry2_opt =
    f dirpath entry1_opt entry2_opt;
    (match entry1_opt, entry2_opt with
    | Some { perm = Dir; name = str; id = sha }, None ->
      walk_trees read_tree (dirpath / str) f
        (read_tree sha) []
    | None, Some { perm = Dir; name = str; id = sha } ->
      walk_trees read_tree (dirpath / str) f
        [] (read_tree sha)
    | Some { perm = Dir; name = str1; id = sha1 },
      Some { perm = Dir; name = str2; id = sha2 } ->
      assert (str1 = str2);
        (* todo: could skip if sha1 = sha2 here, useful opti *)
        walk_trees read_tree (dirpath / str1) f
          (read_tree sha1) (read_tree sha2)
    | None, None -> raise (Impossible "two None in walk_trees.g")
    (* no directories, no need to recurse *)
    | Some _, None
    | None, Some _
    | Some _, Some _
      -> ()
    )
  in
  match xs, ys with
  | [], [] -> ()
  | x::xs, [] ->
    g dirpath (Some x) None;
    walk_trees read_tree dirpath f xs ys
  | [], y::ys ->
    g dirpath None (Some y);
    walk_trees read_tree dirpath f xs ys
  | x::xs, y::ys ->
    (match x.name <=> y.name with
    | Equal -> 
      g dirpath (Some x) (Some y);
      walk_trees read_tree dirpath f xs ys
    | Less -> 
      g dirpath (Some x) None;
      walk_trees read_tree dirpath f xs (y::ys)
    | Greater ->
      g dirpath None (Some y);
      walk_trees read_tree dirpath f (x::xs) ys
    )
@



<<function [[Changes.skip_tree_and_adjust_path]]>>=
let skip_tree_and_adjust_path read_blob dirpath entry_opt =
  match entry_opt with
  | Some { Tree.perm = Tree.Dir; _ } -> None
  | Some { Tree.perm = Tree.Commit; _ } -> failwith "submodule not supported"
  | Some x -> Some ({ Change.
    path = dirpath / x.Tree.name;
    mode = Index.mode_of_perm x.Tree.perm;
    
    (* todo: do that later? once know we will return a change with this entry?
     * make it lazy?
     *)
    content = lazy (read_blob x.Tree.id);
  }, x.Tree.id)
  | None -> None
@

<<signature [[Index.mode_of_perm]]>>=
val mode_of_perm: Tree.perm -> mode
@
<<function [[Index.mode_of_perm]]>>=
let mode_of_perm perm = 
  match perm with
  | Tree.Normal -> Normal
  | Tree.Exec -> Exec
  | Tree.Link -> Link
  <<[[Index.mode_of_perm()]] match perm cases>>
  | Tree.Dir -> failwith "index entry does not support Tree.dir perm"
@


\section{Showing the status of a file: [[git status]]}

<<constant [[Cmd_status.cmd]]>>=
let cmd = { Cmd_.
  name = "status";
  usage = " [options]"; (* less: <pathspec> *)
  options = [
    "--short", Arg.Set short_format, " show status concisely";
    "--long", Arg.Clear short_format, " show status in long format (default)";
    (* less: --branch, --ignored *)
  ];
  f = (fun args ->
    let r, relpaths = Repository.find_root_open_and_adjust_paths (Fpath_.of_strings args) in
    match relpaths with
    | [] -> status r
    | _xs -> raise Cmd_.ShowUsage
  );
}
@

<<function [[Cmd_status.status]]>>=
let status r =
  let st = status_of_repository r in
  if !short_format
  then print_status_short st
  else print_status_long st
@

<<constant [[Cmd_status.short_format]]>>=
let short_format = ref false
@

<<function [[Cmd_status.print_status_short]]>>=
let print_status_short _st =
  raise Todo
@


<<function [[Cmd_status.print_status_long]]>>=
let print_status_long st =
  if st.staged <> []
  then begin
    UConsole.print "Changes to be committed:";
(*  (use "git reset HEAD <file>..." to unstage) *)
    UConsole.print "";
    st.staged |> List.iter print_change_long;
    UConsole.print "";
  end;
  if st.unstaged <> []
  then begin
    UConsole.print "Changes not staged for commit:";
    UConsole.print "";
(*
  (use "git add/rm <file>..." to update what will be committed)
  (use "git checkout -- <file>..." to discard changes in working directory)
*)

    st.unstaged |> List.iter print_change_long;
    UConsole.print "";
  end;
  if st.untracked <> []
  then begin
    UConsole.print "Untracked files:";
(*  (use "git add <file>..." to include in what will be committed) *)
    UConsole.print "";
    st.untracked |> List.iter (fun file ->
      UConsole.print (spf "	%s" !!file)
    );
    UConsole.print "";
  end
@

<<type [[Cmd_status.status]]>>=
type status = {
  (* diff index vs HEAD *)
  staged: Change.t list;
  (* diff worktree vs index *)
  unstaged: Change.t list;
  (* other *)
  untracked: Fpath.t list;
}
@


<<function [[Cmd_status.print_change_long]]>>=
(* very similar to Cmd_log.print_change, but with more indentation *)
let print_change_long change =
  match change with
  | Change.Add entry ->
    UConsole.print (spf "	new file:	%s" !!(entry.Change.path))
  | Change.Del entry ->
    UConsole.print (spf "	deleted:	%s" !!(entry.Change.path))
  | Change.Modify (entry1, _entry2) ->
    UConsole.print (spf "	modified:	%s" !!(entry1.Change.path))
@


<<function [[Cmd_status.status_of_repository]]>>=
let status_of_repository r =
  { staged = changes_index_vs_HEAD r;
    unstaged = 
      Changes.changes_worktree_vs_index 
        (Repository.read_blob r)
        r.Repository.worktree 
        r.Repository.index;
    untracked = untracked r;
  }
@

%pijul: also show current branch name, current conflicts!

\subsection{Listing staged modifications}
%Comparing the index to the [[HEAD]] (

<<function [[Cmd_status.changes_index_vs_HEAD]]>>=
let changes_index_vs_HEAD r =
  let commitid = Repository.follow_ref_some r (Refs.Head) in
  let commit = Repository.read_commit r commitid in
  let treeid = commit.Commit.tree in
  Changes.changes_index_vs_tree (Repository.read_tree r) 
    r.Repository.index
    treeid
@

<<signature [[Changes.changes_index_vs_tree]]>>=
(* for git status (to compare index vs HEAD) *)
val changes_index_vs_tree:
  (Tree.hash -> Tree.t) ->
  Index.t -> Tree.hash -> Change.t list
@
<<function [[Changes.changes_index_vs_tree]]>>=
(* some commonalities with Repository.set_worktree_and_index_to_tree *)
let changes_index_vs_tree read_tree index treeid =
  let tree = read_tree treeid in

  let h_in_index_and_head = Hashtbl.create 101 in
  let hindex = 
    index 
    |> List.map (fun entry -> entry.Index.path, entry)
    |> Hashtbl_.of_list
  in
  let changes = ref [] in

  tree |> Tree.walk_tree read_tree (Fpath.v "XXX") (fun relpath entry_head ->
    let perm = entry_head.Tree.perm in
    match perm with
    | Tree.Dir -> ()
    | Tree.Commit -> failwith "submodule not yet supported"
    | Tree.Normal | Tree.Exec | Tree.Link ->
      try
        let entry_index = Hashtbl.find hindex relpath in
        Hashtbl.add h_in_index_and_head relpath true;
        (* less: if change mode, then report as del/add *)
        if entry_head.Tree.id <> entry_index.Index.id
        then changes |> Stack_.push (Change.Modify (
          { Change.path = relpath; 
            mode = Index.mode_of_perm perm; 
            content = lazy (raise (Impossible "not called")); },
          { Change.path = relpath; 
            mode = entry_index.Index.stats.Index.mode;
            content = lazy (raise (Impossible "not called")); }
        ))
      with Not_found ->
        changes |> Stack_.push (Change.Del { Change.
             path = relpath;
             mode = Index.mode_of_perm perm;
             content = lazy (raise (Impossible "not called"));
                                           });
  );
  index |> List.iter (fun entry ->
    if not (Hashtbl.mem h_in_index_and_head entry.Index.path)
    then changes |> Stack_.push (Change.Add { Change.
             path = entry.Index.path;
             mode = entry.Index.stats.Index.mode;                                            content = lazy (raise (Impossible "not called")); }
    )
  );
  (* less: sort by path *)
  List.rev !changes
@


\subsection{Listing unstaged modifications}
%Comparing the worktree to the index (

\l should also put delete (D) or modified (M) information here


\subsection{Listing untracked files}
% Finding files in worktree and not in the index ()

<<function [[Cmd_status.untracked]]>>=
(* todo: need parse .gitignore *)
let untracked r =
  let h = r.Repository.index 
      |> List.map (fun entry -> entry.Index.path, true) 
      |> Hashtbl_.of_list 
  in
  let res = ref [] in
  r.Repository.worktree |> Repository.walk_dir (fun dir _dirs files ->
    files |> List.iter (fun file ->
      let path = dir / file in
      let path = 
        if !!path =~ "^\\./\\(.*\\)"
        then Fpath.v (Regexp_.matched1 !!path)
        else path
      in
      if not (Hashtbl.mem h path)
      then Stack_.push path res
    );
  );
  List.rev !res
@

% what about .ignore?


\section{Archeology}
\label{sec:archeology}

\t original advantage of VCS, to go back if messed things up in time.
\t Undo power!

\subsection{Checking out an old version}

<<[[Cmd_checkout.checkout()]] cases>>=
| _ when Hexsha.is_hexsha str ->
  let commitid = Hexsha.to_sha str in
  let commit = Repository.read_commit r commitid in
  let treeid = commit.Commit.tree in
  let tree = Repository.read_tree r treeid in
  (* todo: order of operation? set ref before index? reverse? *)
  Repository.write_ref r (Refs.Head) (Refs.Hash commitid);
  Repository.set_worktree_and_index_to_tree r tree;
  UConsole.print (spf "Note: checking out '%s'." str);
  UConsole.print ("You are in 'detached HEAD' state");
@

% convenient to go back! but then can not modify that! 

%gitless: shows that as a misfit, detached.
% but can create branch from that point at least

\subsection{Showing an old version of a file}

% git show /path/:@?? ^ ? or different command?

% Just get commit, tree and follow path until blob.


\subsection{Showing differences between past versions}
% git show sha1?

%cvs: not easy in CVS to "display all changes made by a user in his last
% commit (src: prcs paper). Because internally CVS still uses RCS and
% so a commit is a group of single-file RCS operations.

\subsection{Showing the history of a file or directory: [[git log <path>]]}

% Format of git does not make this fast, as opposed to CVS.
% More reliable when rename?


\chapter{Packing}
\label{chap:packing}
\n kinda an opti (was in adv topics), but referenced too much in Exchanging

% Complex code.

%https://git-scm.com/book/en/v2/Git-Internals-Packfiles

\section{[[Pack.t]]}

\subsection{Pack data}

\subsection{Pack Index}

\subsubsection{Index pack v1}


\subsubsection{Index pack v2}

\section{IO}

\subsection{Reading a pack}

\subsection{Writing a pack}

\section{Modifications to previous functions and data structures}

\subsection{Object Store}

% pack dir

% loose vs pack objects

\subsection{Refs}

% packed refs
% peeled refs??

\section{Delta}

%\subsection{Unpacked Object}

% Diff discussed in OASA vol II section 6.7 


\section{Pack commands}

\subsection{[[git pack-objects]]}


\subsection{[[git repack]]}

\subsection{[[git fetch-pack]]}

% similar to git pull, but will not update the references.
\t but then lost? graph walker will not find them back?


\subsection{[[git receive-pack]]}


\chapter{Exchanging}
\label{chap:exchanging}
% Collaborating?
% Sharing and updating

%trans: most commands useful for single developer.
% but VCS really shine when multiple developers, to help
% collaborate. Saw merge that alleviate need for locks
% and enable multiple people to work on same files and reconcile their work.

% In centralized, when you commit it also "publish" to central repo
% for other to see. In distributed, commit and publish are decoupled.
% You commit and then you push somewhere.


% Pulling requires merging. When you diverge on master from the remote,
% then pulling is similar to merging where master and origin/master
% are 2 different branches.
% See my little experiment:
% master/home/pad/tmp/t2 $ git log --graph --oneline --decorate --all
% *   4960dcf (HEAD, master) Merge branch 'master' of /home/pad/tmp/t1
% |\  
% | * 1d0c911 (origin/master, origin/HEAD) log3
% * |   764e0b2 merge
% |\ \  
% | |/  
% | * 1d6cb05 log2
% * | 54b0dbb t2log1
% |/  
% * 60b5161 log1

%master/home/pad/tmp/t1 $ git log --graph --oneline --decorate --all
%*   4960dcf (HEAD, master) Merge branch 'master' of /home/pad/tmp/t1
%|\  
%| * 1d0c911 log3
%* |   764e0b2 merge
%|\ \  
%| |/  
%| * 1d6cb05 log2
%* | 54b0dbb t2log1
%|/  
%* 60b5161 log1

% Note that usually pull from a repo that has more stuff than you,
% but it's not always the case, so the code below must handle both cases
% (e.g., compute top_commons)

% Note that sha1 allow global namespace! can safely pull commits
% from someone else, can know if same because sha1!!

\section{Client/server architecture}

<<type [[Client.t]]>>=
type t = {
  (* path to remote (e.g., /path/other/repo, or git://github.com/foo/bar) 
   * Fpath.t or Uri.t (TODO: use variant and enforce?)
  *)
  url: string;
  (* less: more parameters:
   *  - determine_refs_wanted. for now grabs everything from remote HEAD 
   *  - return set of remote refs, not just the one for HEAD
   * Note that fetch will modify the target repository by side effect.
   *)
  fetch: Repository.t -> Commit.hash;
  (* less: progress *)
}
@
\t will get send method too?

% Repo param of fetch is dst repo, not remote repo.

<<signature [[Clients.client_of_url]]>>=
val client_of_url: string -> Client.t
@
<<function [[Clients.client_of_url]]>>=
(* old: was called get_transport_and_path (and xxx_from_url) in dulwich *)
let client_of_url url =
  match url with
  <<[[Clients.client_of_url()]] match url cases>>
  | s -> 
    if Sys.file_exists s
    then Client_local.mk_client (Fpath.v s)
    else failwith (spf "remote repository URL not supported: %s" url)
@

\section{Pulling updates from another repository: [[git pull]]}

% saw get_transport_and_path before in core DS and its default
% implem to LocalGitClient

% why return path and client, could embed path information
% in client already.

% determine_wants is about which refs to fetch. Get all remote_refs
% as arguments and returned the sha of the one to fetch (usually
% the one for HEAD)

\t this assumes no merge needed?

% Flow is to set the starting refs you want to fetch from,
% then compute common commits and missing commits by walking graph
% of commits on target repo and comparing to commits from source repo.
% find all missing objects needed by those commits.


<<constant [[Cmd_pull.cmd]]>>=
let cmd = { Cmd_.
  name = "pull";
  usage = " [options] [<url repository>]";
  options = [
  ];
  f = (fun args ->
    let dst, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> 
      failwith "TODO: use remote information in config file"
    | [url] -> 
      pull dst url
    | _ -> raise Cmd_.ShowUsage
  );
}
@

<<function [[Cmd_pull.pull]]>>=
(* =~ git fetch + git merge *)
let pull dst url =
  (* todo: detect if clean repo? status is empty? *)
  let client = Clients.client_of_url url in

  (* less: allow to grab from multiple heads, not just HEAD *)
  let remote_HEAD_sha = client.Client.fetch dst in
  
  (* detect if need merge, if current HEAD not parent of new HEAD *)
  let current_HEAD_sha = Repository.follow_ref_some dst (Refs.Head) in
  let ancestors_remote_HEAD = 
    Commit.collect_ancestors (Repository.read_commit dst) [remote_HEAD_sha]
      (Hashtbl.create 101)
  in
  (match () with
  | _ when remote_HEAD_sha = current_HEAD_sha -> ()
  | _ when Hashtbl.mem ancestors_remote_HEAD current_HEAD_sha ->
    (* easy case *)
    UConsole.print (spf "fast forward to %s" (Hexsha.of_sha remote_HEAD_sha));
    Repository.set_ref dst (Refs.Head) remote_HEAD_sha;
    let commit = Repository.read_commit dst remote_HEAD_sha in
    let tree = Repository.read_tree dst (commit.Commit.tree) in
    Repository.set_worktree_and_index_to_tree dst tree
  | _ -> failwith "TODO: git pull need merge"
  )
@

<<signature [[Repository.set_ref]]>>=
(* better than write_ref, will follow symbolic ref *)
val set_ref: t -> Refs.t -> Commit.hash -> unit
@
<<function [[Repository.set_ref]]>>=
let set_ref r aref newh =
  let (refs, _) = follow_ref r aref in
  let lastref = List.hd (List.rev refs) in
  let file = ref_to_filename r lastref in
  file |> with_file_out_with_lock (fun ch ->
    ch |> IO.output_channel |> IO_.with_close_out 
        (Refs.write (Refs.Hash newh))
  )
@

<<signature [[Client_local.mk_client]]>>=
val mk_client: Fpath.t -> Client.t
@
<<function [[Client_local.mk_client]]>>=
let mk_client (path : Fpath.t) =
  { Client.
    url = !!path;
    fetch = (fun dst ->
      let src = Repository.open_ path in
      fetch_objects src dst;
      (* less: all_refs *)
      Repository.follow_ref_some src Refs.Head
   );
  }
@


\subsection{Fetching objects locally}

% will see fetching remote later in Networking chapter.

%python: fetch will return an iterator over objects?
% so no huge memory consumption? Hmm but in PackObjectStore.add_objects
% it calls len() on it so this should trigger the computation of the
% whole list.
%ocaml: again, no need this to be in BaseRepo, can be in localGitClient

% Note that graph walker is for the target! pass so dource can know
% which one the target needs. So it's also a kind of determine_wants
% but for objects this time.

%python: iterate so add_objects can add one by one the elt, no need
% to store huge list of objects in memory.

% [[haves]] are just the top commits starting from heads in dst repo
% that the src repo has (should really be called top_commons_commits).
% Because of ack(), the graph walker does not go through the whole
% history.
% If src repo has strictly more stuff than dst, then
% [[haves]] will be the dst heads, the "frontline".


<<function [[Client_local.fetch_objects]]>>=
let fetch_objects src dst =
  (* less: determine_wants from pull command *)
  let top_wanted_commits = [Repository.follow_ref_some src Refs.Head] in
  (* less: shallows? unshallows? *)
  let top_common_commits = find_top_common_commits src dst in
  iter_missing_objects top_common_commits top_wanted_commits src 
    (fun sha1 obj_opt ->
    (* less: opti: copy raw files directly without unmarshalling/marshalling *)
    let obj = 
      match obj_opt with
      | None -> Repository.read_obj src sha1
      | Some obj -> obj
    in
    (* todo: count objects progress *)
    (* pr2 (spf "adding %s" (Hexsha.of_sha sha1)); *)
    let sha2 = Repository.add_obj dst obj in
    assert (sha1 = sha2)
  )
@



\subsubsection{Find top common commits}


% ack() will tell graph walker that there is no need to explore
% the parents of sha. So this will not iterate over the whole graph,
% just enough to find the commot frontline.

<<function [[Client_local.find_top_common_commits]]>>=
(* find the common frontline *)
let find_top_common_commits src dst =
  let top_commons = Hashtbl.create 101 in
  let walker = mk_graph_walker dst in

  let rec loop_while_sha commit_sha_opt =
    commit_sha_opt |> Option.iter (fun commit_sha ->
      if Repository.has_obj src commit_sha
      then begin
        Hashtbl.add top_commons commit_sha true;
        walker.ack commit_sha;
      end;
      loop_while_sha (walker.next ())
    )
  in
  loop_while_sha (walker.next ());
  top_commons |> Hashtbl_.to_list |> List.map fst
@

<<signature [[Repository.has_obj]]>>=
val has_obj: t -> Sha1.t -> bool
@
<<function [[Repository.has_obj]]>>=
let has_obj r h =
  let path = h |> Hexsha.of_sha |> hexsha_to_filename r in
  Sys.file_exists !!path
@



% see graphwalker in next section

%\subsubsection{Determine the references wanted}
% will see some refinements later where can ask only HEAD.


\subsubsection{Find missing objects}

% haves below are set of top commits.
% wants are also set of (starting) commits (comes from refs)


\t why need ancestors of haves? they are already set of commits
% in common and so they must have all the parents too.
\l not slow to each time you fetch read and compute all
\l  the shas of all the past commits?

% put objects_to_send in triple. First is sha, second is useless?
% and third is whether this is a leaf. This is important to avoid
% reading blob objects.

<<function [[Client_local.iter_missing_objects]]>>=
let iter_missing_objects top_common_commits top_wanted_commits src f =
  (* less: split_commits_and_tags? *)
  let all_common_commits = 
    Commit.collect_ancestors (Repository.read_commit src) top_common_commits 
      (Hashtbl.create 101) in
  (* bugfix: do not forget Hashtbl.copy because collect_ancestors modify 
   * the second parameter by side effect
   *)
  let missing_commits = 
    Commit.collect_ancestors (Repository.read_commit src) top_wanted_commits 
      (Hashtbl.copy all_common_commits)
  in

  (* let's iterate over all common commits *)
  
  let dst_have_sha = Hashtbl.create 101 in
  (* less: start from second returned result from collect_ancestors?
   * common_commits different from all_ancestors in VCS.nw? 
   *)
  (* expensive loop below? so use parallel threads? *)
  all_common_commits |> Hashtbl.iter (fun commit_sha _true ->
    Hashtbl.add dst_have_sha commit_sha true;
    let commit = Repository.read_commit src commit_sha in
    collect_filetree (Repository.read_tree src) commit.Commit.tree dst_have_sha
  );

  (* and now let's iterate over all missing commits *)

  (* less: tags handling *)
  let rec missing sha is_blob = 
    if Hashtbl.mem dst_have_sha sha
    then ()
    else begin
      Hashtbl.add dst_have_sha sha true;
      (if is_blob
       then f sha None
       else begin
        let obj = Repository.read_obj src sha in
        f sha (Some obj);
        (match obj with
        | Objects.Commit commit ->
          missing commit.Commit.tree false
        | Objects.Tree tree ->
          tree |> List.iter (fun entry ->
            if entry.Tree.perm = Tree.Commit
            then failwith "submodule not supported";
            (* bugfix: it's <>, not = *)
            missing entry.Tree.id (entry.Tree.perm <> Tree.Dir)
          )
        | Objects.Blob _ ->
          raise (Impossible "is_blob guard")
        )
       end
      );
    end
  in
  missing_commits |> Hashtbl.iter (fun commit_sha _true ->
    missing commit_sha false
  )
@
\t LP split

<<function [[Client_local.collect_filetree]]>>=
let rec collect_filetree read_tree treeid have_sha =
  let tree = read_tree treeid in
  tree |> List.iter (fun entry ->
    let sha = entry.Tree.id in
    if not (Hashtbl.mem have_sha sha) then begin
      Hashtbl.add have_sha sha true;
      match entry.Tree.perm with
      | Tree.Normal | Tree.Exec | Tree.Link -> ()
      | Tree.Dir ->  collect_filetree read_tree sha have_sha
      | Tree.Commit -> failwith "submodule not supported yet"
    end
  )
@


<<signature [[Commit.collect_ancestors]]>>=
val collect_ancestors: 
  (hash -> t) ->  hash list -> hash Hashtbl_.set -> 
  hash Hashtbl_.set
@
<<function [[Commit.collect_ancestors]]>>=
(* similar to walk_history but with exposed hdone hash *)
let collect_ancestors read_commit top_commits hdone =
  let hcommits = Hashtbl.create 101 in
  let rec aux sha =
    if Hashtbl.mem hdone sha
    then ()
    else begin
      Hashtbl.add hdone sha true;
      Hashtbl.add hcommits sha true;
      let commit = read_commit sha in
      commit.parents |> List.iter aux
    end
  in
  top_commits |> List.iter aux;
  hcommits
@

\subsubsection{Iterating over objects}


\subsubsection{Adding Objects}

%\subsubsection{Shallow requests}
% advanced topic? related to graft? related to git clone --depth?


\subsection{Fetching references}

\subsubsection{Refspecs}

%https://git-scm.com/book/en/v2/Git-Internals-The-Refspec

\subsubsection{Selecting the refs}

\subsubsection{Parsing ref tuples}

\subsection{Fetching objects in a pack}
\n now that Packing chapter is before exchanging, easier to talk about pack here

%\subsection{Diff statistics}
% nice that git pull after updating also display diffstat for each 
% updated file and the create/delete.

\section{Object store walker}

% used to explore target graph, not source graph.
% To know which (top) commits have in common with source.

\t diff with graph walker? history walker vs object walker!

<<type [[Client_local.graph_walker]]>>=
(* will start from the heads and iterate over the ancestry of heads
 * until the caller ack that some top commits are already known and
 * do not need to be iterated furthermore.
 *)
type graph_walker = {
  next: unit -> Commit.hash option;
  ack: Commit.hash -> unit;
}
@

<<function [[Client_local.ml_graph_walker]]>>=
let (mk_graph_walker: Repository.t -> graph_walker) = fun r ->
  (* less: start just from HEAD? *)
  let heads = 
    Repository.all_refs r |> List.filter_map (fun aref ->
      if aref =~ "refs/heads/"
      then Some (Repository.follow_ref_some r (Refs.Ref aref))
      else None
    )
  in
  let todos = ref heads in
  let todos_next_round = ref [] in
  let last_round = ref None in
  let hdone = Hashtbl.create 101 in

  { next = (fun () ->
    todos := !todos_next_round @ !todos;
    todos_next_round := [];
    match !todos with
    | [] -> None
    | x::xs ->
      todos := xs;
      Hashtbl.add hdone x true;
      last_round := Some x;
      let commit = Repository.read_commit r x in
      let parents = commit.Commit.parents in
      parents |> List.iter (fun parent ->
        if Hashtbl.mem hdone parent
        then ()
        else todos_next_round := parent::!todos_next_round;
      );
      Some x
    );

    ack = (fun commit_sha ->
      (* less: do weird loop where recurse also over parents as in dulwich? *)
      match !last_round with
      | None -> raise (Impossible "ack always after at least one next");
      | Some x ->
        if x <> commit_sha
        then raise (Impossible "'ack(x)' should follow 'x = next()'");
        (* skip those one then because parent already in common *)
        todos_next_round := []
    );
  }
@


% subtle. Will iterate over the graph from the heads,
% which can be long, but while doing so, it can be instructed to 
% skip some ancestors because the src repo already has them (via ack()),
% which is then faster.


% Why record also parents of commit? because if later ack this
% commit, then we need to filter its parents from the todos.


\section{Pushing changes to another repository: [[git push]]}

% Not really needed. The other guy can just pull from yours.
% In fact restrictions about pushing where can only push
% to a bare repository (unless --force?)

<<constant [[Cmd_push.cmd]]>>=
let cmd = { Cmd_.
  name = "push";
  usage = " [options] [<url repository>]";
  options = [
    (* less: --all, --force, --progress *)
  ];
  f = (fun args ->
    let src, _ = Repository.find_root_open_and_adjust_paths [] in
    match args with
    | [] -> 
      failwith "TODO: use remote information in config file"
    | [url] -> 
      push src url
    | _ -> raise Cmd_.ShowUsage
  );
}
@

<<function [[Cmd_push.push]]>>=
(* =~ git fetch + git merge but inverting dst and src  *)
let push src_repo (url_dst : string) =
  let url = src_repo.Repository.worktree in
  let dst = Repository.open_ (Fpath.v url_dst) in
  (* todo: detect if clean repo? status is empty? *)
  let client = Clients.client_of_url !!url in


  (* less: allow to grab from multiple heads, not just HEAD *)
  let remote_HEAD_sha = client.Client.fetch dst in
  
  (* detect if need merge, if current HEAD not parent of new HEAD *)
  let current_HEAD_sha = Repository.follow_ref_some dst (Refs.Head) in
  let ancestors_remote_HEAD = 
    Commit.collect_ancestors (Repository.read_commit dst) [remote_HEAD_sha]
      (Hashtbl.create 101)
  in
  (match () with
  | _ when current_HEAD_sha = remote_HEAD_sha -> ()
  | _ when Hashtbl.mem ancestors_remote_HEAD current_HEAD_sha ->
    (* easy case *)
    UConsole.print (spf "fast forward to %s" (Hexsha.of_sha remote_HEAD_sha));
    Repository.set_ref dst (Refs.Head) remote_HEAD_sha;
    let commit = Repository.read_commit dst remote_HEAD_sha in
    let tree = Repository.read_tree dst (commit.Commit.tree) in
    Repository.set_worktree_and_index_to_tree dst tree
  | _ -> failwith "TODO: git pull need merge"
  )
@

\subsection{Sending objects locally}
% dummy protocol?

\subsection{Sending objects in a pack}



\section{Cloning a repository: [[git clone]]}
\label{sec:git-clone}

% In the end, quite similar to git pull; we just pull everything.

<<constant [[Cmd_clone.cmd]]>>=
let cmd = { Cmd_.
  name = "clone";
  usage = " [options] <repo> [<dir>]";
  options = [
    (* less: --bare, --progress, --depth *)
  ];
  f = (fun args ->
    match args with
    | [url]     -> clone url (Fpath.v ".")
    | [url;dst] -> clone url (Fpath.v dst)
    | _ -> raise Cmd_.ShowUsage
  );
}
@

<<function [[Cmd_clone.clone]]>>=
(* =~ git pull from scratch (itself =~ git fetch + git merge) *)
let clone url (path_dst : Fpath.t) =
  let client = Clients.client_of_url url in
  
  Repository.init path_dst;
  let dst = Repository.open_ path_dst in

  (* less: allow to grab from different head? *)
  let remote_HEAD_sha = client.Client.fetch dst in
  Repository.set_ref dst (Refs.Head) remote_HEAD_sha;

  (* =~ reset index *)
  let commit = Repository.read_commit dst remote_HEAD_sha in
  let tree = Repository.read_tree dst (commit.Commit.tree) in
  Repository.set_worktree_and_index_to_tree dst tree
@


\subsection{Fetching objects}

% determine_wants is about the refs, not the objects.

\subsection{Importing references}

\t clone should import refs, not just HEAD



\chapter{Networking}
\label{chap:networking}

% We should not need that code below. Should mount fs with NFS or sshfs
% or a plan9 fileserver or whatever and then simply use LocalGitClient!
%CVS NEWS file says though that 
% "It uses reliable transport protocols (TCP/IP) for remote repository
%  access, not NFS.  NFS is unusable over long distances (and sometimes
%  over short distances)"

% Distributed VCS! 
% for pull and push you can pass a URL!


% ssh and http in adv topics.
% in this chapter we will focus on git://


<<[[Clients.client_of_url()]] match url cases>>=
(* less: should use URL parsing library *)
| s when s =~ "^git://" -> 
  Client_git.mk_client url
@

\section{[[git://]] protocol}

% smart vs dumb protocol.

%https://github.com/blog/809-git-dumb-http-transport-to-be-turned-off-in-90-days


%https://opensource.googleblog.com/2018/05/introducing-git-protocol-version-2.html

% pkt line. Show example of session


\subsection{Reading packets}

\subsection{Writing packets}

\section{Capabilities}
\l adv topics? or hard to avoid because first _connect return
\l  refs and capabilities

% see Adv topics.


\section{[[git://]] client}

%\subsection{Local client}
% seen before, can be used for NFS too!

%\subsection{[[git://]]}

<<signature [[Client_git.mk_client]]>>=
val mk_client: string (* Fpath.t or Uri.t like git:// *) -> Client.t
@
<<function [[Client_git.mk_client]]>>=
let mk_client _url =
  raise Todo
@


\subsection{Fetching remote objects}

% so pass the target graph walker and way to write on target to
% client fetch_pack

\subsection{Fetching pack files}


% pack_data is target add_pack f.write()

%flow:
%  get remote refs, determine wants, tell wants, get objects and pack_data


% ask git-upload-pack service!

\subsubsection{[[read_pkt_refs()]]}

\subsubsection{[[_handle_upload_pack_head()]]}


\subsubsection{[[_handle_upload_pack_tail()]]}


\subsection{Sending pack files}


\section{[[git://]] server}


%\subsection{[[TCPGitServer]]}

%\subsection{[[FileSystemBackend]]}

%\subsection{[[Handler]]}

\subsection{[[git-upload-pack]]}
% when pull


\subsection{[[git-receive-pack]]}
% when push

\chapter{Algorithms}
\label{chap:algorithms}

%pad: (** are my comments **)

\section{SHA1}
\label{sec:sha1-algo}

% outside scope of this book. Complex cryptography.
%for more information on SHA1:
% http://www-cs-students.stanford.edu/~blynn/gitmagic/ch08.html

\subsection{Overview}

% SHA1 is many things: hashing, and secure.
% For hashing, simple, ex: str -> int32 by adding (Knuth gives famous
% hash func?) (and then usually used with modulo to access hashtbl array bucket)
% Secure because hard to reverse (but simple hash can?)
% and cant produce alternate doc with same sig (message digest).
% Secure, but Git does not really care about that. Really care about
% hashing with almost 0 collision.

% Wikipedia says SHA1 follows the principles used for 
% MD4 and MD5 by Ronald Rivest.
% I can explain how it works, but not really why it works.
% Out of scope of this book.

% The MD4 Message Digest Algorithm - Ronald L. Rivest
% CRYPTO 90, Springer Verlag
% Define motivations (but old one), and design goals (good one),
% and implem, but does not explain why it works. Still the algorithm
% is simpler and use less weird constants, so maybe more intuitive to
% see why it works and why it's hard to reverse.

\subsection{32 bits operators}

% OCaml int 31 bits by default, so need Int32

<<[[Sha1.sha1()]] operator shortcuts for Int32>>=
let ( lor )  = Int32.logor in
let ( lxor ) = Int32.logxor in
let ( land ) = Int32.logand in
let ( ++ )   = Int32.add in
let lnot     = Int32.lognot in
let sr       = Int32.shift_right in
let sl       = Int32.shift_left in
let cls n x = (sl x n) lor (Int32.shift_right_logical x (32 - n)) in
@

% simple algo: first pads input parameter to get multiple of 64, then
% for each block of 64 bytes, store numbers in array of 16 elements,
% and update h0/h1/h2/h3/h4 components of final SHA1 number.
% Finally combine those h0/... to form the final 20 bytes number.

\subsection{Entry point: [[sha1()]]}

<<function [[Sha1.sha1]]>>=
(* sha-1 digest. Based on pseudo-code of RFC 3174.
   Slow and ugly but does the job. *)
let sha1 s =
  <<function [[sha_1_pad]]>>
  let ( &&& ) = ( land ) in
  (* Operations on int32 *)
  <<[[Sha1.sha1()]] operator shortcuts for Int32>>
  (* Start *)
  let m = sha_1_pad s in
  let w = Array.make 16 0l in

  (* components of the 20 bytes SHA1 (5 * 4 bytes (Int32 with 'l' suffix)) *)
  let h0 = ref 0x67452301l in
  let h1 = ref 0xEFCDAB89l in
  let h2 = ref 0x98BADCFEl in
  let h3 = ref 0x10325476l in
  let h4 = ref 0xC3D2E1F0l in

  let a = ref 0l in
  let b = ref 0l in
  let c = ref 0l in
  let d = ref 0l in
  let e = ref 0l in

  (* For each block *)
  for i = 0 to ((Bytes.length m) / 64) - 1 do
    (* Fill w *)
    <<[[Sha1.sha1()]] fill [[w]] for each block [[i]]>>
    (* Loop *)
    a := !h0; b := !h1; c := !h2; d := !h3; e := !h4;
    <<[[Sha1.sha1()]] loop from 0 to 79 for each block [[i]]>>
    (* Update *)
    h0 := !h0 ++ !a;
    h1 := !h1 ++ !b;
    h2 := !h2 ++ !c;
    h3 := !h3 ++ !d;
    h4 := !h4 ++ !e
  done;

  (* the result hash number of 20 bytes *)
  let h = Bytes.create 20 in
  <<function [[i2s]]>>
  i2s h 0 !h0;
  i2s h 4 !h1;
  i2s h 8 !h2;
  i2s h 12 !h3;
  i2s h 16 !h4;
  Bytes.unsafe_to_string h
@

\subsection{Endianess}

% most significant bit first (big-endian)
<<function [[i2s]]>>=
let i2s h k i =
  Bytes.set h k       (Char.unsafe_chr ((Int32.to_int (sr i 24)) &&& 0xFF));
  Bytes.set h (k + 1) (Char.unsafe_chr ((Int32.to_int (sr i 16)) &&& 0xFF));
  Bytes.set h (k + 2) (Char.unsafe_chr ((Int32.to_int (sr i 8))  &&& 0xFF));
  Bytes.set h (k + 3) (Char.unsafe_chr ((Int32.to_int i)         &&& 0xFF));
in
@
\l could reuse one of function used in assembler or linker that does same

%trans:
% and now the details:

\subsection{Filling blocks}

<<[[Sha1.sha1()]] fill [[w]] for each block [[i]]>>=
let base = i * 64 in
for j = 0 to 15 do
  let k = base + (j * 4) in
  w.(j) <- sl (Int32.of_int (Char.code @@ Bytes.get m k)) 24 lor
           sl (Int32.of_int (Char.code @@ Bytes.get m (k + 1))) 16 lor
           sl (Int32.of_int (Char.code @@ Bytes.get m (k + 2))) 8 lor
           (Int32.of_int (Char.code @@ Bytes.get m (k + 3)))
done;
@

\subsection{Looping over blocks}

<<[[Sha1.sha1()]] loop from 0 to 79 for each block [[i]]>>=
for t = 0 to 79 do
  let f, k =
    if t <= 19 then (!b land !c) lor ((lnot !b) land !d), 0x5A827999l else
    if t <= 39 then !b lxor !c lxor !d, 0x6ED9EBA1l else
    if t <= 59 then
      (!b land !c) lor (!b land !d) lor (!c land !d), 0x8F1BBCDCl
    else
    !b lxor !c lxor !d, 0xCA62C1D6l
  in
  let s = t &&& 0xF in
  if (t >= 16) then begin
    w.(s) <- cls 1 begin
        w.((s + 13) &&& 0xF) lxor
        w.((s + 8) &&& 0xF) lxor
        w.((s + 2) &&& 0xF) lxor
        w.(s)
      end
  end;
  let temp = (cls 5 !a) ++ f ++ !e ++ w.(s) ++ k in
  e := !d;
  d := !c;
  c := cls 30 !b;
  b := !a;
  a := temp;
done;
@
% why 0 to 79? why magical 79?

\subsection{Padding}

<<function [[sha_1_pad]]>>=
let sha_1_pad s =
  let len = String.length s in
  let blen = 8 * len in
  let rem = len mod 64 in
  let mlen = if rem > 55 then len + 128 - rem else len + 64 - rem in
  let m = Bytes.create mlen in
  Bytes.blit_string s 0 m 0 len;
  Bytes.fill m len (mlen - len) '\x00';
  Bytes.set m len '\x80';
  if Sys.word_size > 32 then begin
    Bytes.set m (mlen - 8) (Char.unsafe_chr (blen lsr 56 land 0xFF));
    Bytes.set m (mlen - 7) (Char.unsafe_chr (blen lsr 48 land 0xFF));
    Bytes.set m (mlen - 6) (Char.unsafe_chr (blen lsr 40 land 0xFF));
    Bytes.set m (mlen - 5) (Char.unsafe_chr (blen lsr 32 land 0xFF));
  end;
  Bytes.set m (mlen - 4) (Char.unsafe_chr (blen lsr 24 land 0xFF));
  Bytes.set m (mlen - 3) (Char.unsafe_chr (blen lsr 16 land 0xFF));
  Bytes.set m (mlen - 2) (Char.unsafe_chr (blen lsr 8 land 0xFF));
  Bytes.set m (mlen - 1) (Char.unsafe_chr (blen land 0xFF));
  m
in
@

\section{Unzip}

% entry point:
<<signature [[Unzip.inflate]]>>=
val inflate : ?header:bool -> IO.input -> IO.input
(** wrap an input using "inflate" decompression algorithm. raises [Error] if
  an error occurs (this can only be caused by malformed input data). *)
@
% opposite of deflate.
\t remove ?header everywhere? useful?

% alternative: IO.input -> string? IO.input -> unit output -> unit?
% Maybe, but input -> input is nice because can put inflate in the
% middle like in a pipe. Transparent! A single like and hop
% you handle compressed input instead of regular input.

% So deflate should be 'a output -> 'a output? no, because
% need also input for deflate.
% You have a flow of (uncompressed) data, and you want to output
% a flow of compressed data in the pipe.

\subsection{Overview}

%https://en.wikipedia.org/wiki/DEFLATE
%RFC 1951 for deflate file format (great)
%RFC 1950 for zlib format which adds adler-32 checksum for data corruption
% detection. zlib stream.
%http://zlib.net/feldspar.html great article on DEFLATE: 

% Deflate is a Mix of Huffman encoding with LZ77 sliding-window compression.
% Deflate is a very well engineered and optimized algorithm.

%https://www.cs.duke.edu/courses/spring03/cps296.5/papers/ziv_lempel_1977_universal_algorithm.pdf
% implemented in ocaml by Gazanaire (and used in decompress later)

% More efficient than 'compress' (which uses LZW)
% https://en.wikipedia.org/wiki/Lempel%E2%80%93Ziv%E2%80%93Welch
% Used by gzip, zlib library, GIF, PNG, and of course DOS pkzip.
% http://stackoverflow.com/questions/20762094/how-are-zlib-gzip-and-zip-related-what-do-they-have-in-common-and-how-are-they/20765054#20765054

% A nice implem in Python? covers also bzip2. Decompressor only.
% http://www.paul.sladen.org/projects/pyflate/

% See also plan9 libflate/

% FIGURE with Head, Block, CData, and final block and end-of-block markers


\subsection{Data structures}

% huffman encoding
<<type [[Unzip.huffman]]>>=
type huffman =
  (* Leaf *)
  | Found of int (** 0..288 *)
  (* Node *)
  | NeedBit of huffman * huffman
  <<[[Unzip.huffman]] cases>>
[@@warning "-37"]
@

% Alphabet is 0-288 (0-255 + 256 for end of block + 257..288 for lz77 backref)
% but 257..288 is not enough range to encode big distance, so need extra
% bits, and again specialized encoding so frequent distances take less space.
% In fact the 257..288 encodes the length of the backref, not the distance.
% The distance encoding can even use another huffman tree! wow.

% sliding window compression (lz77), decoded input.
<<type [[Unzip.window]]>>=
type window = {
  mutable wbuffer : bytes;
  mutable wpos : int;
  <<[[Unzip.window]] other fields>>
}
@

<<constant [[Unzip.window_size]]>>=
let window_size = 1 lsl 15
@
% 32K
<<constant [[Unzip.buffer_size]]>>=
let buffer_size = 1 lsl 16
@
\l why double? cos will need to blit when reach buffer_size?
\t apparently not, so why? alternative is circular buffer and more tedious
\t  to use with index?
%FIGURE

<<function [[Unzip.window_create]]>>=
let window_create () = {
    wbuffer = Bytes.create buffer_size;
    wpos = 0;
    <<[[Unzip.window_create()]] set other fields>>
  }
@
%old: was taking a size argument, but it was unused


% automata zstream
<<type [[Unzip.state]]>>=
type state =
  | Head

  | Block
  | CData

  | Done
  <<[[Unzip.state]] other cases>>
[@@warning "-37"]
@

% zlib stream
<<type [[Unzip.t]]>>=
type t = {
  mutable zstate    : state;

  mutable zhuffman  : huffman;
  zwindow  : window;

  (* input *)
  zinput   : IO.input;

  (* output *)
  mutable zoutput   : bytes;
  mutable zoutpos   : int;
  mutable zneeded   : int;

  <<[[Unzip.t]] other fields>>
}
@
% How large will be zoutput? depends how call inflate_data
% If user read_all unzipped_input, then inflate_data will
% be called with buffer of 1024 bytes in turn.
% FIGURE?

<<[[Unzip.t]] other fields>>=
mutable zfinal    : bool;
@
% final block (will do different things when read end-of-block if it
% is end-of-_final_-block


% So it's a stream. Alternatives? Hard to know the final
% size of the unzipped document; it is not stored in the zipped
% document so better to gradually write into an output buffer.
% But then will get called piece by piece so important between
% 2 calls of nread to remember in which state we were!

\subsection{Error management}

<<type [[Unzip.error_msg]]>>=
type error_msg =
  | Invalid_huffman
  | Invalid_data
  | Invalid_crc
  | Truncated_data
  | Unsupported_dictionary
@

<<exception [[Unzip.Error]]>>=
exception Error of error_msg
@
% classic Leroy style error management (except miss the [[ppf]] error printer)

<<function [[Unzip.error]]>>=
let error msg = raise (Error msg)
@

\subsection{IO helpers}

\subsubsection{Input bits helpers}

% Could use IO.in_bits type that encapsulate this.

<<[[Unzip.t]] other fields>>=
(** usually a byte, but can contained more *)
mutable zbits     : int;
(** unread (not consumed) bits in zbits (usually 0..8, but can be more) *)
mutable znbits    : int;
@
\l could use byte type? (char)

<<function [[Unzip.reset_bits]]>>=
let reset_bits z =
  z.zbits <- 0;
  z.znbits <- 0
@


<<function [[Unzip.get_bit]]>>=
let get_bit z =
  if z.znbits = 0 then begin
    z.znbits <- 8;
    z.zbits <- IO.read_byte z.zinput;
  end;
  let b = z.zbits land 1 = 1 in
  z.znbits <- z.znbits - 1;
  z.zbits <- z.zbits lsr 1;
  b
@
\l again could just call get_bits z 1?

<<function [[Unzip.get_bits]]>>=
let get_bits z n =
  while z.znbits < n do
    z.zbits <- z.zbits lor ((IO.read_byte z.zinput) lsl z.znbits);
    z.znbits <- z.znbits + 8;
  done;
  let b = z.zbits land (1 lsl n - 1) in
  z.znbits <- z.znbits - n;
  z.zbits <- z.zbits lsr n;
  b
@
\l could sanity check n < Int.bit_size

% get_rev_bits later


\subsubsection{Output helpers}

<<function [[Unzip.add_bytes]]>>=
let add_bytes z s p l =
  <<[[Unzip.add_bytes()]] add bytes to window>>
  Bytes.unsafe_blit s p z.zoutput z.zoutpos l;
  z.zneeded <- z.zneeded - l;
  z.zoutpos <- z.zoutpos + l
@
% how know enough space? zneeded can become negative here?
% no because should be guarded with code looking for zneeded before
% and computing a min len.

% will see window stuff later.


\l remove this? useless specialization? true that called many times
\l  when get a char that is < 256 (after huffman decoding)
<<function [[Unzip.add_char]]>>=
let add_char z c =
  <<[[Unzip.add_char()]] add character to window>>
  Bytes.unsafe_set z.zoutput z.zoutpos c;
  z.zneeded <- z.zneeded - 1;
  z.zoutpos <- z.zoutpos + 1
@
\l why not call add_bytes with 1?
\l could use safe version. No need optimize those Bytes.set

\subsection{Huffman trees}

<<function [[Unzip.apply_huffman]]>>=
let rec apply_huffman z = function
  | Found n -> n
  | NeedBit (a,b) -> apply_huffman z (if get_bit z then b else a)
 <<[[Unzip.apply_huffman()]] other cases>>
@

%\subsubsection{Building an huffman tree}

<<constant [[Unzip.fixed_huffman]]>>=
let fixed_huffman = 
  make_huffman (Array.init 288 (fun n ->
    if n <= 143 then 8
    else if n <= 255 then 9
    else if n <= 279 then 7
    else 8
  )) 0 288 10
@
% longer codelengths for chars between 144 and 255, because less used
% chars? and then use less bits for lz77 length/distance

% See deflate article, if put rules on how to build huffman tree, then
% an huffman tree can be encoded by just giving the codelengths for each
% character of the alphabet.

% pos is usually 0. Not 0 only for some calls for dynamic huffman.
<<function [[Unzip.make_huffman]]>>=
let make_huffman lengths pos nlengths maxbits =

  let counts = Array.make maxbits 0 in
  for i = 0 to nlengths - 1 do
    let p = Array.unsafe_get lengths (i + pos) in
    <<[[Unzip.make_huffman()]] sanity check codelength [[p]]>>
    Array.unsafe_set counts p (Array.unsafe_get counts p + 1);
  done;

  let code = ref 0 in
  let tmp = Array.make maxbits 0 in
  for i = 1 to maxbits - 2 do
    code := (!code + Array.unsafe_get counts i) lsl 1;
    Array.unsafe_set tmp i !code;
  done;

  let bits = Hashtbl.create 0 in
  for i = 0 to nlengths - 1 do
    let l = Array.unsafe_get lengths (i + pos) in
    if l <> 0 then begin
      let n = Array.unsafe_get tmp (l - 1) in
      Array.unsafe_set tmp (l - 1) (n + 1);
      Hashtbl.add bits (n,l) i;
    end;
  done;

  <<function [[Unzip.tree_make]]>>
    (NeedBit (tree_make 0 1, tree_make 1 1))
@
\t need more LP split, not trivial
\t replace those unsafe_get
%opti: tree_compress (NeedBit ...)

<<function [[Unzip.tree_make]]>>=
let rec tree_make v l =
  <<[[Unzip.tree_make()]] sanity check [[l]]>>
  try
    Found (Hashtbl.find bits (v,l))
  with
    Not_found ->
      NeedBit (tree_make (v lsl 1) (l + 1) , tree_make (v lsl 1 lor 1) (l + 1))
in
@

<<[[Unzip.tree_make()]] sanity check [[l]]>>=
if l > maxbits then error Invalid_huffman;
@

<<[[Unzip.make_huffman()]] sanity check codelength [[p]]>>=
if p >= maxbits then error Invalid_huffman;
@
\subsection{Sliding window back references (LZ77)}

<<[[Unzip.add_bytes()]] add bytes to window>>=
window_add_bytes z.zwindow s p l;
@

<<function [[Unzip.window_add_bytes]]>>=
let window_add_bytes w s p len =
  <<[[Unzip.window_add_bytes()]] slide window if reached end of buffer>>
  Bytes.unsafe_blit s p w.wbuffer w.wpos len;
  w.wpos <- w.wpos + len
@

\l remove this? useless specialization?
<<[[Unzip.add_char()]] add character to window>>=
window_add_char z.zwindow c;
@
<<function [[Unzip.window_add_char]]>>=
let window_add_char w c =
  <<[[Unzip.window_add_char()]] slide window if reached end of buffer>>
  Bytes.unsafe_set w.wbuffer w.wpos c;
  w.wpos <- w.wpos + 1
@


<<[[Unzip.window_add_char()]] slide window if reached end of buffer>>=
if w.wpos = buffer_size 
then window_slide w;
@
<<[[Unzip.window_add_bytes()]] slide window if reached end of buffer>>=
if w.wpos + len > buffer_size 
then window_slide w;
@

<<function [[Unzip.window_slide]]>>=
let window_slide w = 
  <<[[Unzip.window_slide()]] update crc before blit>>
  let b = Bytes.create buffer_size in
  w.wpos <- w.wpos - window_size;
  Bytes.unsafe_blit w.wbuffer window_size b 0 w.wpos;
  w.wbuffer <- b
@
\t why need 64K buffer then? if create new buffer each time anyway?

% FIGURE
% wpos not necessarily = buffer_size. Can be a bit before because
% of add_bytes that can take many bytes (len)

% inflate_loop (when in Block and n > 256) -> <>
<<function [[Unzip.window_available]]>>=
let window_available w =
  w.wpos
@

\subsection{Entry point: [[inflate()]]}

%trans: now ready finally for full algorithm.

% inflate means decompress

<<function [[Unzip.inflate]]>>=
let inflate ?(header=true) ch =
  let z = inflate_init ~header ch in
  let tmp = Bytes.create 1 in
  (* read input close *)
  IO.create_in
    (* special case of ~input for 1 byte *)
    (*~read:*)(fun() ->
      let l = inflate_data z tmp 0 1 in
      if l = 1 
      then Bytes.unsafe_get tmp 0 
      else raise IO.No_more_input
    )
    (*~input:*)(fun buf_dst pos_in_buf len ->
      let n = inflate_data z buf_dst pos_in_buf len in
      if n = 0 
      then raise IO.No_more_input;
      n
    )
    (*~close:*)(fun () ->
      IO.close_in ch
    )
@
% IO.create_in use a growing byte buffer!
%pad: renamed param of ~input to buf_dst and pos_in_buf, clearer than s and pos

<<signature [[Unzip.inflate_init]]>>=
val inflate_init : ?header:bool -> IO.input -> t
@
<<function [[Unzip.inflate_init]]>>=
let inflate_init ?(header=true) ch = 
  {
    zstate = (if header then Head else Block);
    zinput = ch;
    zfinal = false;

    zoutput = Bytes.empty;
    zoutpos = 0;
    zneeded = 0;

    zhuffman = fixed_huffman;
    zhuffdist = None;

    zwindow = window_create ();

    zbits = 0;
    znbits = 0;

    zlen = 0;
    zdist = 0;
    zlengths = Array.make 19 (-1);
  }
@
%old:    zwindow = window_create (1 lsl 15) but argument was not used and
% anyway he should have used window_size instead of this hardcoded constant

% when zoutput get changed? when call inflate_data and given a buf_dst

<<signature [[Unzip.inflate_data]]>>=
val inflate_data : t -> bytes -> int -> int -> int
@
<<function [[Unzip.inflate_data]]>>=
let inflate_data z buf_dst pos_in_buf len =
  <<[[Unzip.inflate_data()]] sanity check parameters>>
  z.zneeded <- len;
  z.zoutpos <- pos_in_buf;
  z.zoutput <- buf_dst;
  try
    if len > 0 
    then inflate_loop z;
    len - z.zneeded
  with IO.No_more_input -> error Truncated_data
@
%pad: renamed param of ~input to buf_dst and pos_in_buf, clearer than s and pos

% return number of characters consumed, at the end
% zneeded should be 0 so we should return len (unless found
% end of block earlier than len)

<<[[Unzip.inflate_data()]] sanity check parameters>>=
if pos_in_buf < 0 || len < 0 || pos_in_buf + len > Bytes.length buf_dst 
then invalid_arg "inflate_data";
@

\subsection{[[inflate_loop()]]}

<<function [[Unzip.inflate_loop]]>>=
let rec inflate_loop z =
  match z.zstate with
  <<[[Unzip.inflate_loop()]] match state cases>>
@

\subsubsection{Head}

% See RFC1950 and zlib stream format
<<[[Unzip.inflate_loop()]] match state cases>>=
| Head ->
  let cmf = IO.read_byte z.zinput in
  <<[[Unzip.inflate_loop()]] when in Head state, sanity check [[cmf]]>>
  let flg = IO.read_byte z.zinput in
  <<[[Unzip.inflate_loop()]] when in Head state, sanity check [[flg]]>>
  z.zstate <- Block;
  inflate_loop z
@
%  (*let fcheck = flg land 31 in*)
%  (*let flevel = flg lsr 6 in*)

% cmf compression mode and flag?

<<[[Unzip.inflate_loop()]] when in Head state, sanity check [[cmf]]>>=
let cm     = cmf land 15 in
let cinfo  = cmf lsr 4 in
if cm <> 8 || cinfo <> 7 
then error Invalid_data;
@
% see RFC 1950? 
% cm for 'compression method'
% https://stackoverflow.com/questions/20762094/how-are-zlib-gzip-and-zip-related-what-do-they-have-in-common-and-how-are-they/20765054#20765054
% cm = 8 is for deflate format
% cinfo = 7 = window size? (32K)?

<<[[Unzip.inflate_loop()]] when in Head state, sanity check [[flg]]>>=
let fdict = flg land 32 <> 0 in
if (cmf lsl 8 + flg) mod 31 <> 0 
then error Invalid_data;
if fdict 
then error Unsupported_dictionary;
@
% see RFC 1950?

\subsubsection{Block}

<<[[Unzip.inflate_loop()]] match state cases>>=
| Block ->
  z.zfinal <- get_bit z;
  let btype = get_bits z 2 in
  (match btype with
  <<[[Unzip.inflate_loop()]] when in Block state, match block type cases>>
  | _ ->
    error Invalid_data
  )
@
% final block, useful when reach end of block in CData

% get_bit first call will set z.bits buffer.

<<[[Unzip.inflate_loop()]] when in Block state, match block type cases>>=
| 1 -> (* fixed Huffman *)
  if !debug then print_string "Unzip: Fixed Huffman\n";
  z.zhuffman <- fixed_huffman;
  z.zhuffdist <- None;
  z.zstate <- CData;
  inflate_loop z
@


\subsubsection{CData}

<<[[Unzip.inflate_loop()]] match state cases>>=
| CData ->
  (match apply_huffman z z.zhuffman with
  <<[[Unzip.inflate_loop()]] when in CData state, match apply huffman cases>>
  )
@
% So first compression here, huffman for alphabet encoding

<<[[Unzip.inflate_loop()]] when in CData state, match apply huffman cases>>=
| n when n < 256 ->
  add_char z (Char.unsafe_chr n);
  if z.zneeded > 0  
  then inflate_loop z
@
% byte as-is

<<[[Unzip.inflate_loop()]] when in CData state, match apply huffman cases>>=
| 256 ->
  z.zstate <- if z.zfinal then Crc else Block;
  inflate_loop z
@
% end of block character

% lz77 backref. more complex.
<<[[Unzip.inflate_loop()]] when in CData state, match apply huffman cases>>=
| n ->
  let n = n - 257 in
  <<[[Unzip.inflate_loop()]] when in CData state, when backref, compute zlen>>
  <<[[Unzip.inflate_loop()]] when in CData state, when backref, compute zdist>>

  if z.zdist > window_available z.zwindow 
  then error Invalid_data;
  z.zstate <- Dist;
  inflate_loop z
@
% So second compression here, lz77 sliding window backref
%opti:  z.zstate <- (if z.zdist = 1 then DistOne else Dist);

<<[[Unzip.t]] other fields>>=
mutable zlen      : int;
@
<<[[Unzip.t]] other fields>>=
mutable zdist     : int;
@

\paragraph{[[zlen]]}

<<[[Unzip.inflate_loop()]] when in CData state, when backref, compute zlen>>=
let extra_bits = Array.unsafe_get len_extra_bits_tbl n in
if extra_bits = -1 
then error Invalid_data;
z.zlen <- (Array.unsafe_get len_base_val_tbl n) + (get_bits z extra_bits);
@

<<constant [[Unzip.len_extra_bits_tbl]]>>=
let len_extra_bits_tbl = [|0;0;0;0;0;0;0;0;1;1;1;1;2;2;2;2;3;3;3;3;4;4;4;4;5;5;5;5;0;-1;-1|]
@

<<constant [[Unzip.len_base_val_tbl]]>>=
let len_base_val_tbl = [|3;4;5;6;7;8;9;10;11;13;15;17;19;23;27;31;35;43;51;59;67;83;99;115;131;163;195;227;258|]
@

\paragraph{[[zdist]]}

<<[[Unzip.inflate_loop()]] when in CData state, when backref, compute zdist>>=
let dist_code = 
  match z.zhuffdist with 
  | None -> get_rev_bits z 5 
  <<[[Unzip.inflate_loop()]] compute [[dist_code]], match [[zhuffdist]] cases>>
in
let extra_bits = Array.unsafe_get dist_extra_bits_tbl dist_code in
if extra_bits = -1 
then error Invalid_data;
z.zdist <- (Array.unsafe_get dist_base_val_tbl dist_code) + (get_bits z extra_bits);
@

% for distance
<<function [[Unzip.get_rev_bits]]>>=
let rec get_rev_bits z n =
  if n = 0 then
    0
  else if get_bit z then
    (1 lsl (n - 1)) lor (get_rev_bits z (n-1))
  else
    get_rev_bits z (n-1)
@

<<constant [[Unzip.dist_extra_bits_tbl]]>>=
let dist_extra_bits_tbl = [|0;0;0;0;1;1;2;2;3;3;4;4;5;5;6;6;7;7;8;8;9;9;10;10;11;11;12;12;13;13;-1;-1|]
@

<<constant [[Unzip.dist_base_val_tbl]]>>=
let dist_base_val_tbl = [|1;2;3;4;5;7;9;13;17;25;33;49;65;97;129;193;257;385;513;769;1025;1537;2049;3073;4097;6145;8193;12289;16385;24577|]
@

\subsubsection{Dist}

<<[[Unzip.state]] other cases>>=
| Dist
@

<<[[Unzip.inflate_loop()]] match state cases>>=
| Dist ->
  while z.zlen > 0 && z.zneeded > 0 do
    let len = min z.zneeded (min z.zlen z.zdist) in
    add_dist z z.zdist len;
    z.zlen <- z.zlen - len;
  done;
  if z.zlen = 0 
  then z.zstate <- CData;
  if z.zneeded > 0 
  then inflate_loop z
@
% The loop is because zlen can be more than what is available in
% the sliding window when they use the trick of repeating sequence.

<<function [[Unzip.add_dist]]>>=
let add_dist z d l =
  add_bytes z z.zwindow.wbuffer (z.zwindow.wpos - d) l
@
% finally.



\subsubsection{CRC}

% when end of final block
<<[[Unzip.state]] other cases>>=
| Crc
@

<<[[Unzip.inflate_loop()]] match state cases>>=
| Crc ->
  <<[[Unzip.inflate_loop()]] when in Crc state, check adler32 checksum>>
  z.zstate <- Done;
  inflate_loop z
@

\subsubsection{Done}

<<[[Unzip.inflate_loop()]] match state cases>>=
| Done ->
  ()
@
% end of inflate_loop, so return to inflate_data which
% returns len - z.needed

\subsection{Advanced features}

\subsubsection{Adler32 CRC}

% Communication? Redundancy Check?

%A painless guide to CRC error detection algorithms
%http://www.zlib.net/crc_v3.txt

% Part of zlib, not deflate.

% faster than CRC32 algorithm and low probability of undetected errors
<<type [[Unzip.adler32]]>>=
type adler32 = {
  mutable a1 : int;
  mutable a2 : int;
}
@

<<[[Unzip.window]] other fields>>=
wcrc : adler32;
@
% See Appendix 9 of RFC 1950

<<[[Unzip.window_create()]] set other fields>>=
wcrc = adler32_create();
@

<<function [[Unzip.adler32_create]]>>=
let adler32_create() = {
  a1 = 1;
  a2 = 0;
}
@

<<[[Unzip.window_slide()]] update crc before blit>>=
adler32_update w.wcrc w.wbuffer 0 window_size;
@

% libflate contains more optimized code where some loops
% are probably unfolded.

<<function [[Unzip.adler32_update]]>>=
let adler32_update a s p l =
  let p = ref p in
  for _i = 0 to l - 1 do
    let c = int_of_char (Bytes.unsafe_get s !p) in
    a.a1 <- (a.a1 + c) mod 65521;
    a.a2 <- (a.a2 + a.a1) mod 65521;
    incr p;
  done
@
% let base = 65521 largest primer smaller than 65536

% Logic behind those 2 numbers? Proof that it works better than other CRC?

<<[[Unzip.inflate_loop()]] when in Crc state, check adler32 checksum>>=
let calc = window_checksum z.zwindow in
let crc = adler32_read z.zinput in
if calc <> crc 
then error Invalid_crc;
@

<<function [[Unzip.window_checksum]]>>=
let window_checksum w =
  adler32_update w.wcrc w.wbuffer 0 w.wpos;
  w.wcrc
@


% IO in zlib stream
<<function [[Unzip.adler32_read]]>>=
let adler32_read ch =
  let a2a = IO.read_byte ch in
  let a2b = IO.read_byte ch in
  let a1a = IO.read_byte ch in
  let a1b = IO.read_byte ch in
  {
    a1 = (a1a lsl 8) lor a1b;
    a2 = (a2a lsl 8) lor a2b;
  }
@


\subsubsection{No compression block type}

<<[[Unzip.inflate_loop()]] when in Block state, match block type cases>>=
| 0 -> (* no compression *)
  if !debug then print_string "Unzip: no compression\n";
  z.zlen <- IO.LittleEndian.read_ui16 z.zinput;
  let nlen = IO.LittleEndian.read_ui16 z.zinput in
  if nlen <> 0xffff - z.zlen 
  then error Invalid_data;
  z.zstate <- Flat;
  inflate_loop z;
  reset_bits z
@

% compressed already compressed? will lose space, so better
% acknowledge that sometimes better not do anything

% when no compression, means no huffman, means no end of block
% special alphabet. So how knows end of block? because Flat block
% specifies its length first, as 16 bits, so means also limits
% size of Flag block to 64K.

<<[[Unzip.state]] other cases>>=
| Flat
@

% uncompressed block
<<[[Unzip.inflate_loop()]] match state cases>>=
| Flat ->
  let rlen = min z.zlen z.zneeded in
  let str = IO.nread z.zinput rlen in
  let len = Bytes.length str in
  z.zlen <- z.zlen - len;
  add_bytes z str 0 len;
  if z.zlen = 0 
  then z.zstate <- (if z.zfinal then Crc else Block);
  if z.zneeded > 0 
  then inflate_loop z
@

\subsubsection{Specialized huffman tree}

% Maybe more complex part of DEFLATE, the way the huffman tree is encoded.

% Dynamic Huffman vs static huffman.
% This format is often used. 

<<[[Unzip.inflate_loop()]] when in Block state, match block type cases>>=
| 2 -> (* dynamic Huffman *)
  if !debug then print_string "Unzip: Dynamic Huffman\n";
  let hlit = get_bits z 5 + 257 in
  let hdist = get_bits z 5 + 1 in
  let hclen = get_bits z 4 + 4 in
  for i = 0 to hclen - 1 do
    Array.unsafe_set z.zlengths (Array.unsafe_get code_lengths_pos i) (get_bits z 3);
  done;
  for i = hclen to 18 do
    Array.unsafe_set z.zlengths (Array.unsafe_get code_lengths_pos i) 0;
  done;
  z.zhuffman <- make_huffman z.zlengths 0 19 8;
  let lengths = Array.make (hlit + hdist) 0 in
  inflate_lengths z lengths (hlit + hdist);
  z.zhuffdist <- Some (make_huffman lengths hlit hdist 16);
  z.zhuffman <- make_huffman lengths 0 hlit 16;      
  z.zstate <- CData;
  inflate_loop z
@

<<[[Unzip.t]] other fields>>=
zlengths : int array;
@

<<[[Unzip.t]] other fields>>=
mutable zhuffdist : huffman option;
@

<<[[Unzip.inflate_loop()]] compute [[dist_code]], match [[zhuffdist]] cases>>=
| Some h -> 
  apply_huffman z h
@

<<constant [[Unzip.code_lengths_pos]]>>=
let code_lengths_pos = [|16;17;18;0;8;7;9;6;10;5;11;4;12;3;13;2;14;1;15|]
@

<<function [[Unzip.inflate_lengths]]>>=
let inflate_lengths z a max =
  let i = ref 0 in
  let prev = ref 0 in
  while !i < max do
    match apply_huffman z z.zhuffman with
    | n when n <= 15 ->
      prev := n;
      Array.unsafe_set a !i n;
      incr i
    | 16 ->
      let n = 3 + get_bits z 2 in
      if !i + n > max then error Invalid_data;
      for _k = 0 to n - 1 do
        Array.unsafe_set a !i !prev;
        incr i;
      done;
    | 17 ->
      let n = 3 + get_bits z 3 in
      i := !i + n;
      if !i > max then error Invalid_data;
    | 18 ->
      let n = 11 + get_bits z 7 in
      i := !i + n;
      if !i > max then error Invalid_data;
    | _ ->
      error Invalid_data
  done
@

\subsection{Optimizations}

\subsubsection{[[NeedBits]]}

<<[[Unzip.huffman]] cases>>=
(* Opti *)
| NeedBits of int * huffman array
@
<<[[Unzip.apply_huffman()]] other cases>>=
| NeedBits (n,t) -> apply_huffman z (Array.unsafe_get t (get_bits z n))
@

<<function [[Unzip.tree_compress]]>>=
(*
let rec _tree_compress t =
  match tree_depth t with
  | 0 -> t
  | 1 ->
    (match t with
    | NeedBit (a,b) -> NeedBit (tree_compress a,tree_compress b)
    | _ -> assert false)
  | d ->
    let size = 1 lsl d in
    let tbl = Array.make size (Found (-1)) in
    tree_walk tbl 0 0 d t;
    NeedBits (d,tbl)

and _tree_walk tbl p cd d = function
  | NeedBit (a,b) when d > 0 ->
    tree_walk tbl p (cd + 1) (d-1) a;
    tree_walk tbl (p lor (1 lsl cd)) (cd + 1) (d-1) b;
  | t ->
    Array.set tbl p (tree_compress t)
*)
@

<<function [[Unzip.tree_depth]]>>=
(*
let rec tree_depth = function
  | Found _ -> 0
  | NeedBit (a,b) ->
    1 + min (tree_depth a) (tree_depth b)
  | NeedBits _ -> assert false
*)
@
% so NeedBits used only after tree_compress pass

\subsubsection{[[DistOne]]}

<<[[Unzip.state]] other cases>>=
| DistOne
@
% optimization?

<<[[Unzip.inflate_loop()]] match state cases>>=
| DistOne ->
  if !debug then print_string "Unzip: DistOne\n";
  let len = min z.zlen z.zneeded in
  add_dist_one z len;
  z.zlen <- z.zlen - len;
  if z.zlen = 0 
  then z.zstate <- CData;
  if z.zneeded > 0 
  then inflate_loop z
@

<<function [[Unzip.add_dist_one]]>>=
let add_dist_one z n =
  let c = window_get_last_char z.zwindow in
  let s = Bytes.make n c in
  add_bytes z s 0 n
@

<<function [[Unzip.window_get_last_char]]>>=
let window_get_last_char w =
  Bytes.unsafe_get w.wbuffer (w.wpos - 1)
@




\section{Zip}

\subsection{Entry point: [[deflate()]]}

<<function [[Zip.deflate]]>>=
TODO lpize zip.ml, and also port to OCaml zip algorithm
@


% entry point:
<<signature [[Zlib.compress]]>>=
val compress:
  ?level: int -> ?header: bool -> 
  (bytes -> int) -> (bytes -> int -> unit) -> unit
@

<<function [[Zlib.compress]]>>=
let compress ?(level = 6) ?(header = true) refill flush =
  let inbuf = Bytes.create buffer_size
  and outbuf = Bytes.create buffer_size in
  let zs = deflate_init level header in
  let rec compr inpos inavail =
    if inavail = 0 then begin
      let incount = refill inbuf in
      if incount = 0 then compr_finish() else compr 0 incount
    end else begin
      let (_, used_in, used_out) =
        deflate zs inbuf inpos inavail outbuf 0 buffer_size Z_NO_FLUSH in
      flush outbuf used_out;
      compr (inpos + used_in) (inavail - used_in)
    end
  and compr_finish () =
    let (finished, _, used_out) =
       deflate zs inbuf 0 0 outbuf 0 buffer_size Z_FINISH in
    flush outbuf used_out;
    if not finished then compr_finish()
  in
    compr 0 0;
    deflate_end zs
@


<<exception [[Zlib.Error]]>>=
exception Error of string * string
@

<<toplevel [[Zlib._1]]>>=
let _ =
  Callback.register_exception "Zlib.Error" (Error("",""))
@

<<type [[Zlib.flush_command]]>>=
type flush_command =
    Z_NO_FLUSH
  | Z_SYNC_FLUSH
  | Z_FULL_FLUSH
  | Z_FINISH
@

<<constant [[Zlib.buffer_size]]>>=
let buffer_size = 1024
@




<<signature [[Zlib.compress_direct]]>>=
val compress_direct:
  ?level: int -> ?header: bool -> (bytes -> int -> unit) ->
  (bytes -> int -> int -> unit) * (unit -> unit)
@
<<function [[Zlib.compress_direct]]>>=
let compress_direct  ?(level = 6) ?(header = true) flush =
  let outbuf = Bytes.create buffer_size in
  let zs = deflate_init level header in
  let rec compr inbuf inpos inavail =
    if inavail = 0 then ()
    else begin
      let (_, used_in, used_out) =
        deflate zs inbuf inpos inavail outbuf 0 buffer_size Z_NO_FLUSH in
      flush outbuf used_out;
      compr inbuf (inpos + used_in) (inavail - used_in)
    end
  and compr_finish () =
    let (finished, _, used_out) =
      deflate zs (Bytes.unsafe_of_string "") 0 0
                 outbuf 0 buffer_size Z_FINISH in
    flush outbuf used_out;
    if not finished then compr_finish()
  in
  compr, compr_finish
@



<<signature [[Zlib.uncompress]]>>=
val uncompress:
  ?header: bool -> (bytes -> int) -> (bytes -> int -> unit) -> unit
@

<<function [[Zlib.uncompress]]>>=
let uncompress ?(header = true) refill flush =
  let inbuf = Bytes.create buffer_size
  and outbuf = Bytes.create buffer_size in
  let zs = inflate_init header in
  let rec uncompr inpos inavail =
    if inavail = 0 then begin
      let incount = refill inbuf in
      if incount = 0 then uncompr_finish true else uncompr 0 incount
    end else begin
      let (finished, used_in, used_out) =
        inflate zs inbuf inpos inavail outbuf 0 buffer_size Z_SYNC_FLUSH in
      flush outbuf used_out;
      if not finished then uncompr (inpos + used_in) (inavail - used_in)
    end
  and uncompr_finish first_finish =
    (* Gotcha: if there is no header, inflate requires an extra "dummy" byte
       after the compressed stream in order to complete decompression
       and return finished = true. *)
    let dummy_byte = if first_finish && not header then 1 else 0 in
    let (finished, _, used_out) =
       inflate zs inbuf 0 dummy_byte outbuf 0 buffer_size Z_SYNC_FLUSH in
    flush outbuf used_out;
    if not finished then uncompr_finish false
  in
    uncompr 0 0;
    inflate_end zs
@


\section{Diff}
\label{sec:diff-algo}

\subsection{Overview}

% Basic edit distance algo (see Gusfield book)
% \cite{James and McIlroy - 1976}
% \cite{Myers - 1985}
%   https://blog.jcoglan.com/2017/02/12/the-myers-diff-algorithm-part-1/
% patience diff
%  https://blog.jcoglan.com/2017/09/19/the-patience-diff-algorithm/

%rcs:
% Compute efficient detla for RCS!

\subsection{Data structures}

% Saw Diff.diff with Equal | Deleted | Added in chapter X.

\subsection{Entry point: [[Diffs.diff()]]}

<<signature [[Diff_basic.diff]]>>=
val diff: string array -> string array -> Diff.diff
@
<<signature [[Diff_myers.diff]]>>=
val diff: string array -> string array -> Diff.diff
@


<<function [[Diffs.diff]]>>=
let diff str1 str2 =
  let xs = split_lines str1 in
  let ys = split_lines str2 in
  Diff_myers.diff (Array.of_list xs) (Array.of_list ys)
@

<<function [[Diffs.split_lines]]>>=
let split_lines str =
  (* alt: let xs = Str.full_split (Str.regexp "\n") str in *)
  let rec aux start = 
    try
      let idx = String.index_from str start '\n' in
      let line = String.sub str start (idx - start + 1) in
      line::aux (idx + 1)
    with Not_found ->
      if start = String.length str
      then []
      else [String.sub str start (String.length str - start)]
  in
  aux 0
@


\subsection{Edit distance basic algorithm (O($n^2$) in space/time)}

<<function [[Diff_basic.diff]]>>=
let diff arr1 arr2 =
  (* opti: string to int *)

  let mat = matrix_distance arr1 arr2 in
  let trace = traceback_transcript arr1 arr2 mat in
  List.rev trace

  (* opti: get back string from int *)
(*
  let arr1, arr2, revh = hash_strings arr1 arr2 in
  |> List.map (function 
      | Diff.Added i   -> Diff.Added   (revh.(i))
      | Diff.Deleted i -> Diff.Deleted (revh.(i))
      | Diff.Equal i   -> Diff.Equal   (revh.(i))
  )
*)
@

% See comment in diff_basic.ml prelude for some comments

<<function [[Diff_basic.matrix_distance]]>>=
let matrix_distance arr1 arr2 = 
  let n = Array.length arr1 in
  let m = Array.length arr2 in 
  (* this can be big ... *)
  let mat = Array.make_matrix (n+1) (m+1) 0 in
  let t i j = 
    if Array.get arr1 (i-1) = Array.get arr2 (j-1)
    then 0
    else 1 
  in
  let min3 a b c = min (min a b) c in

  begin
    for i = 0 to n do
      mat.(i).(0) <- i
    done;
    for j = 0 to m do
      mat.(0).(j) <- j;
    done;
    (* this can be long ... *)
    for i = 1 to n do
      for j = 1 to m do
        mat.(i).(j) <- 
          min3 (mat.(i).(j-1) + 1) 
               (mat.(i-1).(j) + 1) 
               (mat.(i-1).(j-1) + t i j)
      done
    done;
    mat
  end
@

<<function [[Diff_basic.traceback_transcript]]>>=
(* extract the traceback from the matrice (Gusfield P221) *)
let traceback_transcript arr1 arr2 mat =
  let n = Array.length arr1 in
  let m = Array.length arr2 in 
  let get_orig_arr arr i = arr.(i-1) in
  (* you need Figure 11.3 P222 of Gusfield book to understand the code below *)
  let rec aux i j =
    let x = mat.(i).(j) in
    match () with
    | _ when i = 0 && j = 0 -> []
    | _ when i = 0 -> (Diff.Added (get_orig_arr arr2 j))::aux (i) (j-1)
    | _ when j = 0 -> (Diff.Deleted (get_orig_arr arr1 i))::aux (i-1) (j)
    | _ when x = mat.(i-1).(j) + 1 -> 
      (Diff.Deleted (get_orig_arr arr1 i))::aux (i-1) (j)
    | _ when x = mat.(i).(j-1) + 1 -> 
      (Diff.Added (get_orig_arr arr2 j))::aux (i) (j-1)
    | _ -> 
      if x = mat.(i-1).(j-1)
      then Diff.Equal (get_orig_arr arr1 (i))::aux (i-1) (j-1)
      else (Diff.Deleted (get_orig_arr arr1 i))::
           (Diff.Added (get_orig_arr arr2 j))::
           aux (i-1) (j-1)
  in
  aux n m
@

\subsection{Myers algorithm (O($n$) in space in best-case)}

% Good if edit distance is small (most use cases of diff).
% Rely on special property of edit distance matrix, see Myers paper.
% Diagonal!

<<function [[Diff_myers.lcs]]>>=
let lcs a b =
  let n = Array.length a in
  let m = Array.length b in
  let mn = m + n in
  let sz = 2 * mn + 1 in

  let vd = Array.make sz 0 in
  let vl = Array.make sz 0 in
  let vr = Array.make sz [] in

  let get v i = v.(i + mn) in
  let set v i x = v.(i + mn) <- x in
  <<function [[Diff_myers.finish]]>>
  if mn = 0 
  then []
  else
    (* For d <- 0 to mn Do *)
    let rec dloop d =
      assert (d <= mn);
      (* For k <- -d to d in steps of 2 Do *)
      <<function [[Diff_myers.kloop]]>>
      in kloop (-d)
    in dloop 0
@

<<function [[Diff_myers.kloop]]>>=
let rec kloop k =
  if k > d 
  then dloop (d + 1)
  else
    let x, l, r =
      if k = -d || (k <> d && get vd (k - 1) < get vd (k + 1)) 
      then get vd (k + 1), get vl (k + 1), get vr (k + 1)
      else get vd (k - 1) + 1, get vl (k - 1), get vr (k - 1)
    in
    let x, y, l, r =
      <<function [[Diff_myers.xyloop]]>>
      xyloop x (x - k) l r
    in
    set vd k x;
    set vl k l;
    set vr k r;
    if x >= n && y >= m 
    then
      (* Stop *)
      finish ()
    else
      kloop (k + 2)
@

<<function [[Diff_myers.xyloop]]>>=
let rec xyloop x y l r =
  if x < n && y < m && equal a.(x) b.(y)
  then xyloop (x + 1) (y + 1) (l + 1) (`Common(x, y, a.(x))::r)
  else x, y, l, r
in 
@
<<function [[Diff_myers.finish]]>>=
let finish () =
  let rec loop i maxl r =
    match () with
    | _ when i > mn -> List.rev r
    | _ when get vl i > maxl -> loop (i + 1) (get vl i) (get vr i)
    | _ -> loop (i + 1) maxl r
  in loop (- mn) 0 []
in
@

% This is to extra back from just a `Common the Added and Deleted.
<<function [[Diff_myers.diff]]>>=
let diff a b =
  let append_map g arr from to_ init =
    let rec loop i init =
      if i >= to_ 
      then init
      else loop (i + 1) (g i (arr.(i)):: init)
    in loop from init
  in
  let added   _i x = Diff.Added x in
  let removed _i x = Diff.Deleted x in
  let rec loop cs apos bpos init =
    match cs with
    | [] ->
        init
        |> append_map removed a apos (Array.length a)
        |> append_map added   b bpos (Array.length b)
    | `Common (aoff, boff, x) :: rest ->
        init
        |> append_map removed a apos aoff
        |> append_map added   b bpos boff
        |> (fun y -> (Diff.Equal x)::y)
        |> loop rest (aoff + 1) (boff + 1)
  in loop (lcs a b) 0 0 [] |> List.rev
@


\section{Diff3}
\label{sec:diff3-algo}
% aka merge

\subsection{Overview}

% No paper really explaining diff3 algorithm. There is the diffutils manual
% and some comments in the source code according to Pierce's Diff3 
% formalization paper.


% https://blog.jcoglan.com/2017/05/08/merging-with-diff3/

% see example from Pierce paper.
% had to change A to 1 7 8 2 3 6  because if put 1 4 5 2 3 6
% then Diff_myers output a different result than the one they show
% in their paper (there are indeed 2 possible lcs)

\subsection{Data structures}
% types

\subsection{Entry point: [[diff3()]]}

<<function [[Diff3.diff3]]>>=
TODO
@

\subsection{Displaying merging conflicts}



\chapter{Advanced Features TODO}
\label{chap:advanced-features}


\section{Tracking symbolic links}
\label{sec:symlinks}

<<[[Tree.perm]] cases>>=
| Link
@
% Symlink actually

<<[[Index.mode]] cases>>=
| Link
@

<<[[Index.stat_info_of_lstats()]] match kind and perm cases>>=
| Unix.S_LNK, _ -> Link
@

<<[[Repository.content_from_path_and_unix_stat()]] match kind cases>>=
| Unix.S_LNK ->
  Unix.readlink !!full_path
@

% see also use of lstat() before, not stat()

\section{Splitting a large repository: submodules}

%S_IFGITLINK = 0o160000
% hack to encode submodule?

<<[[Tree.perm]] cases>>=
| Commit (* ?? submodule? *)
@

<<[[Tree.perm_of_string()]] match str cases>>=
| "160000" -> Commit
@
<<[[Tree.string_of_perm()]] match perm cases>>=
| Commit -> "160000"
@


<<[[Repository.set_worktree_and_index_to_tree()]] walk tree cases>>=
| Tree.Commit -> failwith "submodule not yet supported"
@

<<[[Tree.walk_tree()]] match perm cases>>=
| Commit ->
  failwith "submodule not supported yet"
@

<<[[Repository.build_file_from_blob()]] match perm cases>>=
| Tree.Commit -> failwith "submodule not yet supported"
@


<<[[Index.mode]] cases>>=
| Gitlink (*?? submodule? *)
@

<<[[Index.read_mode()]] match [[n lsr 12]] cases>>=
| 0b1110 -> Gitlink
@
<<[[Index.write_mode()]] match mode cases>>=
| Gitlink -> 0b1110__000__000_000_000 
@

<<[[Changes.content_from_path_and_stat_index()]] match mode cases>>=
| Index.Gitlink -> failwith "submodule not supported"
@


<<[[Index.perm_of_mode()]] match mode cases>>=
| Gitlink -> Tree.Commit (* sure? *)
@
% when compute trees_of_index

<<[[Index.mode_of_perm()]] match perm cases>>=
| Tree.Commit -> Gitlink
@



\section{Configuration file: [[.git/config]]}
\label{sec:gitconfig}

% ex of use:
%config = self.get_config()
%honor_filemode = config.get_boolean(
%    'core', 'filemode', os.name != "nt")

\subsection{Initialization}

\subsection{[[Config.t]]}

\subsection{Reading a configuration file}

\subsection{Writing a configuration file}

\subsection{Stacked configurations: [[~/.gitconfig]] and [[.git/config]]}

\section{Commit rules and checks: [[.git/hooks/]]}

%self.hooks['pre-commit'] = PreCommitShellHook(self.controldir())
%self.hooks['commit-msg'] = CommitMsgShellHook(self.controldir())
%self.hooks['post-commit'] = PostCommitShellHook(self.controldir())


\section{Ignoring files: [[.gitignore]]}

%For details for the matching rules, see https://git-scm.com/docs/gitignore

% Seems unused though ... many os.walk do not filter files based
% on information in .ignore I think.


\section{Archeology: Grafts}

% I used this feature to represent the full history of Linux from 0.01 to 2.6!

\subsection{Reading a graft file}

\subsection{Writing a graft file}

\subsection{Using a graft file}


%\section{Advanced diff capabilities}
\section{Rename detection}

% useful to have git log tracking a file through rename

%\subsection{Refactorings}
% Nice feature of darcs is token rename patch! So do CEs
% when merge another branch!



\chapter{Advanced Commands TODO}
\label{chap:advanced-commands}

\section{Tagging a commit with a name}
\label{sec:tags}

% Why need tags? Why not simply refs?
% Because refs just point to something but can not have meta-data.
% If you dont want to give any comment about a version and that
% its name is enough, then you just need a ref. Otherwise
% you need a ref to an object (container) containing itself
% ref to a version and metadata: The tag.

% As opposed to a ref (or branch), it always refer to the same commit!
% Just a name to a commit. Also can have a description text.

% Can do tags by abusing refs/tags/xxx. In fact in pfff seems like
% github did that to create tags ...

\subsection{[[Tag.t]]}

<<[[Objects.t]] cases>>=
(*  | Tag of Tag.t *)
@

<<[[Repository.objectish]] cases>>=
(* ObjByTag *)
@

\subsection{Reading a tag}

<<[[Objects.read()]] match str cases>>=
(* "tag" -> Tag (Tag.read raw) *)
@

\subsection{Writing a tag}

<<[[Objects.write()]] match obj cases>>=
@
<<[[Objects.write()]] return header, match obj cases>>=
@

<<[[Cmd_show.show()]] match obj cases>>=
@

\subsection{[[git tag]]}

% to create, list, delete

\subsection{[[git clone]] and tags}
% should import tags

\subsection{[[git pull]] and tags}
% should split_commit_and_tags (see dulwich)

\section{Reference history}
%Storing past versions of the heads: the reflog

% Saw commit history with git log.
% Can have also reference history! with git reflog.

% quite simple, just an history of the content of a ref.
% So very meta, refs allow to access the history of files,
% and the refs themselves have an history.
% so .git/logs/HEAD will contain the different values of HEAD
% so when you switch branch, when you commit, etc., all of that
% will generate different entries there.

% but code of dulwich does not maintain reflog. When you
% update a ref, it should update the reflog of this ref!

\subsection{[[git reflog]]}

\section{Stash}
% again, just a ref?

\subsection{[[git stash]]}
% pretty useful in the end

\section{Developer commands}
% To help develop, to help debug

%trans:
% not only manage changes, go to past versions.
% Can also help debug issues. Can help developer develop!

%\subsection{Identifying the version of a buggy program}
% Useful to get version from binary version!
% RCS had this with $Id$ and ident program.
% Git does not support $Id: as in CVS.
% Alternative?? 
% No $Log:, but anyway can use git log.
% other useful keywords?

\subsection{Finding the diff causing a regression: [[git bisect]]}
% great tool, I should use it more, but requires discipline
% and good commits with good hooks

% How goes when multiple paths between 2 versions (diamond)?

\subsection{Reverting a change: [[git revert]]}
% 

%dup: inspecting/archeology?
\t Undo power

\subsection{Finding the author of some code: [[git blame]]}
% aka annotate

% great tool again. See who, why, and also see related changes!
% Can infer what to do by looking at past commit
% (see my facebook experience!)

% related: git log <path>

%\chapter{Development Support}
% Tags
% Hooks
 
\subsection{Finding code: [[git grep]]}
% pretty useful

\subsection{Creating an archive: [[git archive]]}
% create tarball from git repo
%bootstrap:
% can greate ocamlgit-0.1.tgz so no need git to get ocamlgit

\section{Advanced merging commands}

\subsection{Rebase: [[git rebase]]}

% Cite GitFlow blob controversy?

\subsection{Cherry-pick: [[git cherry-pick]]}

%:darcs: %pijul: better for that
% src: https://pijul.org/manual/why_pijul.html
% when cherry picking git changes the commit. 
% It does not have the same parent and so not
% same commit id, and so later this can cause pb because git
% has no way to know when merging that this patch is common.


\section{Plumbing commands}
% original git is plumbing vs porcelain

\subsection{[[git fetch]]}

\subsection{[[git symbolic-ref]]}

\subsection{[[git rev-list]]}
% 'git log' used to be a shell script calling git rev-list

\subsection{[[git diff-tree]]}

\subsection{[[git commit-tree]]}
%? to commit without author and commiter??

\subsection{[[git ls-tree]]}
% pretty simple.

\subsection{[[git remote add]]}

\subsection{[[git ls-remote]]}

\section{Miscellaneous commands}


\subsection{[[git filter-branch]]}
% useful?

% http://manishearth.github.io/blog/2017/03/05/understanding-git-filter-branch


\chapter{Advanced Networking TODO}
\label{chap:advanced-networking}

\section{Other clients}

\subsection{[[ssh://]]}

<<[[Clients.client_of_url()]] match url cases>>=
| s when s =~ "^ssh://" -> 
  failwith "ssh not supported"
@

\subsection{[[http://]]}

<<[[Clients.client_of_url()]] match url cases>>=
| s when s =~ "^http://" -> 
  failwith "http not supported"
@


\section{Other servers}

%\subsection{[[git daemon]]}

%\subsection{[[git web-daemon]]}

\subsection{[[http://]]}
% git smart http protocol

% also cgit? nice web interface to explore repo?

\section{Other client/server capabilities}

\subsection{Report status}
% mv in Debugging appendix?

\subsection{Quiet}

\subsection{Thin pack}

\subsection{Side band 64k}



\chapter{Advanced Topics TODO}
\label{chap:advanced-topics}

\section{Bytes versus ASCII versus UTF-8}
% Encoding.

% Git doc says git is agnostic to encoding. Just treat filenames
% and file content as bytes. But for commit messages, assume utf8,
% if not then have to specify an encoding commit tag?

% Why need speak about encoding early?
% Can not just use bytes everywhere? filenames mentionned in
% tree objects are utf8? the content of blob might be utf8 but we do not care.


\section{Reliability and signals}

% First, immutable object store and order of operation (a la ext2fs?)
% leaves state of repo in consistent state always!
% Only tricky part is update references! and done via lock to be atomic.

% What if C-c in middle of operations?
% Handled by atomic ref update?

%\section{Advanced features}
% now in separate chapter

\section{Optimizations}

%\subsection{LRU cache}
% Needs that for?

\section{Fast import and export}
% another opti? why need that?
% to collaborate with other VCS? like import SVN in git?

% another way to clone a repo?
%$ git fast-export --all | (cd /empty/repository && git fast-import)

\section{Alternates}

\t ??? related to pack files?

%\section{Peeled}
% seems related to tags, so move with Tags?
%https://stackoverflow.com/questions/26492303/what-does-peel-mean-in-git

\section{Other repository format}

\subsection{Bare repository}

% convenient when want to have a centralized repo and
% people push to it. If non-bare repo then git refuses to push
% because the index and worktree would be inconsistent.

% when git init --bare

% when objects/ directly at root, not under hidden_path (controldir).

\subsection{[[.git]] file}
% linked working tree? see docstring of commondir()


\section{Security}

% Ownership?
% Less an issue with git because distribute VCS, so anybody
% can have own copy of entire repo (not just of work tree).
% So no need special admin of RCS/foo.c,v 

%rcs: rely on unix permission (give foo.c,v to a group) and
% can have additional access (restriction list)

% How protect who can modify a repo?
%sccs: could even limit to certain dirs or files what someone could modify

\chapter{Conclusion}
\label{chap:conclusion}






\appendix

\chapter{Debugging}
\label{chap:debugging-ocamlgit}

<<constant [[Cmds.extra_commands]]>>=
let extra_commands = [
  Cmd_test.cmd;
  Cmd_dump.cmd;
]
@

\section{[[ocamlgit dump]]}
% ocamlgit specific, so I specify ocamlgit
% but there is a git dump-index though.

<<constant [[Cmd_dump.cmd]]>>=
let cmd = { Cmd_.
  name = "dump";
  usage = " <file>";
  options = [
    "-raw", Arg.Set raw, " do not pretty print";
    "-index", Arg.Set index, " pretty print index content";
  ];
  f = (fun args ->
    match args with
    | [file] -> dump file
    | _ -> failwith (spf "dump command [%s] not supported"
                       (String.concat ";" args))
  );
}
@
\l git dump pack

<<constant [[Cmd_dump.raw]]>>=
let raw = ref false
@

<<constant [[Cmd_dump.index]]>>=
let index = ref false
@


<<function [[Cmd_dump.dump]]>>=
let dump file =
  if !index
  then dump_index file
  else dump_object file
@

<<function [[Cmd_dump.dump_index]]>>=
(* =~ dulwich dump-index, =~ git ls-files --stage *)
let dump_index file =
  let chan = open_in file in
  let input = IO.input_channel chan in
  let index = Index.read input in
  let v = Dump.vof_index index in
  UConsole.print (OCaml.string_of_v v)
@

<<signature [[Dump.vof_index]]>>=
val vof_index: Index.t -> OCaml.v
@
<<constant [[Dump.vof_index]]>>=
let vof_index = Index.vof_t
@



<<function [[Cmd_dump.dump_object]]>>=
(* =~ git cat-file -p *)
let dump_object file =
  let chan = open_in file in
  let input = IO.input_channel chan in
  let unzipped = Unzip.inflate input in
  
  try
    if !raw
    then 
      let str = IO.read_all unzipped in 
      Logs.app (fun m -> m "%s" str)
    else begin
      let obj = Objects.read unzipped in
      let v = Dump.vof_obj obj in
      UConsole.print (OCaml.string_of_v v)
    end
  with Unzip.Error _err ->
    failwith "unzip error"
@



<<signature [[Dump.vof_obj]]>>=
val vof_obj: Objects.t -> OCaml.v
@
<<constant [[Dump.vof_obj]]>>=
let vof_obj = Objects.vof_t
@


\section{[[ocamlgit test]]}

<<constant [[Cmd_test.cmd]]>>=
let cmd = { Cmd_.
  name = "test";
  usage = " ";
  options = [];
  f = (fun args ->
    match args with
    | ["sha1"; str] -> test_sha1 str
    | ["sha1"] -> test_sha1 "what is up, doc?"

    | ["diff";file1;file2] -> test_diff file1 file2
    | ["diff"] -> 
      failwith "missing arguments to diff (diff <file1> <file2>)"

    | ["diff3";file1;file2;file3] -> test_diff3 file1 file2 file3
    | ["diff3"] -> 
      failwith "missing arguments to diff3 (diff3 <orig> <filea> <fileb>)"

    | ["unzip"; file] -> test_unzip file
    | ["zip"; file] -> test_zip file

    | ["unzip_all_objects"] -> test_unzip_all_objects ()

    | _ -> failwith (spf "test command [%s] not supported"
                       (String.concat ";" args))
  );
}
@

<<function [[Cmd_test.test_sha1]]>>=
(* see https://git-scm.com/book/en/v2/Git-Internals-Git-Objects *)
let test_sha1 content =
  let header = spf "blob %d\000" (String.length content) in
  let store = header ^ content in

  let sha = Sha1.sha1 store in
  UConsole.print (spf "len = %d, raw = %s" (String.length sha) sha);
  let hexsha = Hexsha.of_sha sha in
  UConsole.print (spf "len = %d, str = %s" (String.length hexsha) hexsha);
  ()
@


\chapter{Profiling}
\label{chap:profiling-ocamlgit}

<<[[Main.main()]] GC settings>>=
Gc.set {(Gc.get ()) with Gc.stack_limit = 1000 * 1024 * 1024};
@

\chapter{Error Management}
\label{chap:error}
% centralize all errors? have a error.ml?

\chapter{Utilities}
\label{chap:utilities}

\section{Common functions}

% |>
% now standard actually

% pr2

% <=>

\section{File utilities}

% Common.with_file_in

\section{Directory utilities}

% all_refs | ?? -> <>
<<signature [[Repository.walk_dir]]>>=
val walk_dir: 
  (Fpath.t (* dir *) -> string (* subdir *) list -> string (* file *) list -> unit) ->
  Fpath.t ->
  unit
@
<<function [[Repository.walk_dir]]>>=
(* inspired from os.path.walk in Python *)
let rec walk_dir f (dir : Fpath.t) : unit =
  dir |> with_opendir (fun handle ->
    let dirs = ref [] in
    let files = ref [] in
    try 
      while true do
        let s = Unix.readdir handle in
        (* git specific here *)
        if s <> "." && s <> ".." && s <> ".git" then begin
          let path : Fpath.t = dir / s in
          let st = Unix.lstat !!path in
          (match st.Unix.st_kind with
          | Unix.S_DIR -> Stack_.push s dirs
          | _ -> Stack_.push s files
          )
        end
      done
    with End_of_file ->
      let dirs = List.rev !dirs in
      let files = List.rev !files in
      f dir dirs files;
      dirs |> List.iter (fun s ->
        walk_dir f (dir / s)
      )
  )
@

<<function [[Repository.with_opendir]]>>=
(* less: use finalize *)
let with_opendir f (dir : Fpath.t) =
  let handle = Unix.opendir !!dir in
  let res = f handle in
  Unix.closedir handle;
  res
@

\section{Generalized IO}

% IO.input_channel (channel vs IO)

% See IO.ml toplevel comment. in_channel and out_channel not
% super flexible, not general. Lack also binary IO functions
% like stuff to output or input little-endian or big-endian int.
% Enter IO.ml!

\section{Binary IO}

% Not lex/yacc here for git but low-level bytes reading.

% IO.ml and a few addons in IO_.ml

<<signature [[IO_.with_close_out]]>>=
val with_close_out: ('a IO.output -> unit) -> 'a IO.output -> 'a
@
<<function [[IO_.with_close_out]]>>=
let with_close_out f ch =
  f ch;
  let res = IO.close_out ch in
  res
@

<<signature [[IO_.read_string_and_stop_char]]>>=
val read_string_and_stop_char: 
  IO.input -> char -> string
@
<<function [[IO_.read_string_and_stop_char]]>>=
let read_string_and_stop_char ch stop_char =
  let b = Buffer.create 8 in
  let rec loop() =
    let c = IO.read ch in
    if c <> stop_char then begin
      Buffer.add_char b c;
      loop();
    end;
  in
  loop();
  Buffer.contents b
@

<<signature [[IO_.read_int_and_nullbyte]]>>=
val read_int_and_nullbyte: 
  IO.input -> int
@
<<function [[IO_.read_int_and_nullbyte]]>>=
let read_int_and_nullbyte ch =
  let str = IO.read_c_string ch in
  int_of_string str
@

<<signature [[IO_.read_key_space_value_newline]]>>=
val read_key_space_value_newline: 
  IO.input -> string (* key *) -> (IO.input -> 'a) -> 'a
@
<<function [[IO_.read_key_space_value_newline]]>>=
let read_key_space_value_newline ch k f =
  let str = read_string_and_stop_char ch ' ' in
  if str <> k
  then failwith (spf 
    "read_key_space_value_newline: wrong key got %s (expecting %s)"
    str k);
  let v = f ch in
  let c = IO.read ch in
  if c <> '\n'
  then failwith "read_key_space_value_newline: wrong format, no newline";
  v
@


\chapter{Extra Code}

%\ifallcode
#include "VCS_extra.nw"
%\fi

%\chapter{Changelog}
%\label{sec:changelog}

% code via mk loc = 6157 LOC (but miss advanced features of dulwich/git)
% orig VCS.nw = 6318, just lpized and few comments, 75 pages pdf
% now: =~ XX LOC so added XX LOE (Lines of explanations)
% dulwich: =~ 16 000 LOC 

\chapter*{Glossary}
\addcontentsline{toc}{chapter}{Glossary}
\label{sec:glossary}

\begin{verbatim}
VCS = Version Control System
DVCS = Distributed Version Control System
SHA1 = Secure Hash Algorithm 1
URL = Uniform Resource Locator
\end{verbatim}

\chapter*{Indexes}
\addcontentsline{toc}{chapter}{Index}

%src: wc.nw in noweb source
Here is a list of the identifiers used, and where they appear.
Underlined entries indicate the place of definition.
This index is generated automatically.

%\twocolumn does not work
\nowebindex

%\chapter{References} 
\addcontentsline{toc}{chapter}{References}

\bibliography{../docs/latex/Principia}
\bibliographystyle{alpha}

%******************************************************************************
% Postlude
%******************************************************************************

\end{document}
